"""
AI ë²•ë¥  ì—°êµ¬ ë„ìš°ë¯¸ - íŒë¡€, ìœ ê¶Œí•´ì„, ë²•ë ¹ ì¢…í•© ê²€ìƒ‰ ì„œë¹„ìŠ¤ + PDF ë²ˆì—­
ë²•ì œì²˜ API + ChatGPTë¥¼ í™œìš©í•œ ë²•ë¥  ìë£Œ ê²€ìƒ‰ ë° ë¶„ì„
PDF ë¬¸ì„œ ë²ˆì—­ ê¸°ëŠ¥ (PDFMathTranslate ìŠ¤íƒ€ì¼)

ì‹¤í–‰ ë°©ë²•:
streamlit run app.py
"""

import streamlit as st
import requests
import json
import time
import os
from datetime import datetime
from typing import Dict, List, Optional, Any
import asyncio
import nest_asyncio
import aiohttp
import pandas as pd
from dotenv import load_dotenv
from openai import OpenAI
import logging
from enum import Enum
import re
import io
import base64

# PDF ìƒì„± ëª¨ë“ˆ (ì„ íƒì  import)
try:
    from reportlab.lib.pagesizes import A4
    from reportlab.pdfbase import pdfmetrics
    from reportlab.pdfbase.ttfonts import TTFont
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.lib.units import mm
    REPORTLAB_AVAILABLE = True
except ImportError:
    REPORTLAB_AVAILABLE = False

# PDF ë²ˆì—­ ëª¨ë“ˆ (ì„ íƒì  import)
try:
    from pdf_translator import PDFTranslator, translate_pdf_file
    PDF_TRANSLATOR_AVAILABLE = True
except ImportError:
    PDF_TRANSLATOR_AVAILABLE = False

# Streamlit í™˜ê²½ì—ì„œ asyncio ì´ë²¤íŠ¸ ë£¨í”„ ì¶©ëŒ ë°©ì§€
nest_asyncio.apply()

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ===== í˜ì´ì§€ ì„¤ì • =====
st.set_page_config(
    page_title="AI ë²•ë¥  ë„ìš°ë¯¸ & PDF ë²ˆì—­",
    page_icon="âš–ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ===== ì»¤ìŠ¤í…€ CSS =====
st.markdown("""
<style>
    .chat-message {
        padding: 1.5rem;
        border-radius: 15px;
        margin-bottom: 1rem;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }

    .user-message {
        background-color: #e8f4f8;
        margin-left: 20%;
    }

    .assistant-message {
        background-color: #f0f2f6;
        margin-right: 20%;
    }

    .legal-opinion {
        background-color: #ffffff;
        border: 2px solid #e0e0e0;
        padding: 2rem;
        border-radius: 10px;
        margin: 1rem 0;
    }

    .search-result {
        background-color: #f8f9fa;
        border-left: 4px solid #1976d2;
        padding: 1rem;
        margin: 0.5rem 0;
        border-radius: 5px;
    }

    .api-status-ok { color: #388e3c; font-weight: bold; }
    .api-status-error { color: #d32f2f; font-weight: bold; }

    .category-header {
        background-color: #1976d2;
        color: white;
        padding: 0.5rem 1rem;
        border-radius: 5px;
        margin: 1rem 0 0.5rem 0;
    }

    .pdf-upload-area {
        border: 2px dashed #ccc;
        border-radius: 10px;
        padding: 2rem;
        text-align: center;
        background-color: #fafafa;
        margin: 1rem 0;
    }

    .pdf-preview {
        border: 1px solid #e0e0e0;
        border-radius: 5px;
        padding: 1rem;
        margin: 1rem 0;
        background-color: #fff;
    }

    .translation-progress {
        padding: 1rem;
        background-color: #e3f2fd;
        border-radius: 5px;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# ===== ì„œë¹„ìŠ¤ ìœ í˜• Enum =====
class ServiceType(Enum):
    INFO = "ë²•ë¥  ì •ë³´ ì œê³µ"
    CONTRACT = "ê³„ì•½ì„œ ê²€í† "
    OPINION = "ë²•ë¥ ìë¬¸ì˜ê²¬ì„œ"
    RESEARCH = "ë²•ë¥  ì—°êµ¬"

# ===== ë¦¬ìŠ¤í¬ ë ˆë²¨ =====
class RiskLevel(Enum):
    HIGH = ("ğŸ”´ High", "ì¦‰ì‹œ ì¤‘ë‹¨/ì „ë©´ ì¬ê²€í†  í•„ìš”")
    MEDIUM = ("ğŸŸ  Medium", "ìˆ˜ì • í˜‘ìƒ í•„ìˆ˜")
    LOW = ("ğŸŸ¡ Low", "ë¬¸êµ¬ ëª…í™•í™” ê¶Œì¥")

# ===== ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” =====
def init_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    defaults = {
        'chat_history': [],
        'current_service': None,
        'fact_sheet': {},
        'case_documents': [],
        'law_api_key': '',
        'openai_api_key': '',
        'api_keys_set': False,
        'search_results': None
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

init_session_state()

# ===== API í‚¤ ê´€ë¦¬ í•¨ìˆ˜ =====
def get_law_api_key() -> str:
    """ë²•ì œì²˜ API í‚¤ ê°€ì ¸ì˜¤ê¸°"""
    # 1. ì„¸ì…˜ì—ì„œ í™•ì¸
    if st.session_state.law_api_key:
        return st.session_state.law_api_key
    # 2. Streamlit secrets í™•ì¸
    try:
        if hasattr(st, 'secrets') and 'LAW_API_KEY' in st.secrets:
            return st.secrets['LAW_API_KEY']
    except Exception:
        pass
    # 3. í™˜ê²½ë³€ìˆ˜ í™•ì¸
    return os.getenv('LAW_API_KEY', '')

def get_openai_api_key() -> str:
    """OpenAI API í‚¤ ê°€ì ¸ì˜¤ê¸°"""
    # 1. ì„¸ì…˜ì—ì„œ í™•ì¸
    if st.session_state.openai_api_key:
        return st.session_state.openai_api_key
    # 2. Streamlit secrets í™•ì¸
    try:
        if hasattr(st, 'secrets') and 'OPENAI_API_KEY' in st.secrets:
            return st.secrets['OPENAI_API_KEY']
    except Exception:
        pass
    # 3. í™˜ê²½ë³€ìˆ˜ í™•ì¸
    return os.getenv('OPENAI_API_KEY', '')

def get_openai_client():
    """OpenAI í´ë¼ì´ì–¸íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
    api_key = get_openai_api_key()
    if api_key:
        # API í‚¤ í˜•ì‹ ê²€ì¦ (sk-ë¡œ ì‹œì‘í•´ì•¼ í•¨)
        if not api_key.startswith('sk-'):
            logger.warning(f"ì˜ëª»ëœ OpenAI API í‚¤ í˜•ì‹: {api_key[:20]}... (sk-ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤)")
            return None
        return OpenAI(api_key=api_key)
    return None

# ===== AI ë³€í˜¸ì‚¬ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ =====
AI_LAWYER_SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ í•œêµ­ì˜ ì „ë¬¸ ë²•ë¥ ìë¬¸ì˜ê²¬ì„œ ì‘ì„± ì „ë¬¸ê°€ì´ì ê°€ìƒì˜ ë³€í˜¸ì‚¬ì…ë‹ˆë‹¤.
ì‹¤ì œ ë³€í˜¸ì‚¬ì˜ ì‚¬ê³  ë°©ì‹(ì‚¬ì‹¤ê´€ê³„ íŒŒì•… â†’ Issue-Spotting â†’ ë²•ë¦¬ ê²€í†  â†’ ìœ„í—˜ì¸¡ì • â†’ ì „ëµ ìˆ˜ë¦½)ì„ ì™„ë²½íˆ êµ¬í˜„í•©ë‹ˆë‹¤.

í•µì‹¬ ì›ì¹™:
1. ì¦ê±° ìš°ì„ ì£¼ì˜: êµ¬ë‘ ì§„ìˆ ë§Œìœ¼ë¡œ íŒë‹¨í•˜ì§€ ì•Šê³  ë¬¼ì  ì¦ë¹™ í™•ë³´ ìµœìš°ì„ 
2. ê·¼ê±° ê¸°ë°˜ ë¶„ì„: ëª¨ë“  ë²•ì  ì£¼ì¥ì€ ì¶œì²˜(ë²•ë ¹Â·íŒë¡€Â·í–‰ì •í•´ì„) ëª…ì‹œ
3. ì‚¬ìš©ì ì¤‘ì‹¬ ì ‘ê·¼: ëª¨ë“  ìŸì ì„ ì˜ë¢°ì¸ ê´€ì ì—ì„œ ìœ ë¦¬/ë¶ˆë¦¬ë¡œ í‰ê°€
4. IRAC ë°©ë²•ë¡ : Issue â†’ Rule â†’ Application â†’ Conclusion êµ¬ì¡°
5. ë¦¬ìŠ¤í¬ ê³„ì¸µí™”: High/Medium/Low ë“±ê¸‰í™”
6. ì‹¤í–‰ê°€ëŠ¥í•œ í•´ê²°ì±…: ìµœì†Œ 2ê°€ì§€ ì´ìƒì˜ ëŒ€ì•ˆ ì œì‹œ

í•„ìˆ˜ ê³ ì§€: âš–ï¸ ë³¸ ë‚´ìš©ì€ AIê°€ ì‘ì„±í•œ ì°¸ê³ ìë£Œì´ë©°, ë²•ë¥ ìë¬¸ì´ ì•„ë‹™ë‹ˆë‹¤.
êµ¬ì²´ì ì¸ ì‚¬ì•ˆì— ëŒ€í•´ì„œëŠ” ë°˜ë“œì‹œ ë³€í˜¸ì‚¬ ë“± ì „ë¬¸ê°€ì˜ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.
"""

# ===== ë²•ë¥  AI ì—”ì§„ í´ë˜ìŠ¤ =====
class LegalAIEngine:
    """AI ë²•ë¥  ì—°êµ¬ ì—”ì§„ - ë²•ì œì²˜ API ì „ì²´ ì—°ë™"""

    def __init__(self):
        self.law_api_key = get_law_api_key()
        self.api_endpoints = {
            'search': 'https://www.law.go.kr/DRF/lawSearch.do',
            'service': 'https://www.law.go.kr/DRF/lawService.do'
        }

        # ê¸°ë³¸ ë²•ë¥  ë°ì´í„° target ì½”ë“œ
        self.basic_targets = {
            'law': {'name': 'í˜„í–‰ë²•ë ¹(ê³µí¬ì¼)', 'key': 'law'},
            'eflaw': {'name': 'í˜„í–‰ë²•ë ¹(ì‹œí–‰ì¼)', 'key': 'eflaw'},
            'prec': {'name': 'íŒë¡€', 'key': 'prec'},
            'admrul': {'name': 'í–‰ì •ê·œì¹™', 'key': 'admrul'},
            'ordin': {'name': 'ìì¹˜ë²•ê·œ', 'key': 'ordin'},
            'detc': {'name': 'í—Œì¬ê²°ì •ë¡€', 'key': 'detc'},
            'expc': {'name': 'ë²•ë ¹í•´ì„ë¡€', 'key': 'expc'},
            'decc': {'name': 'í–‰ì •ì‹¬íŒë¡€', 'key': 'decc'},
            'trty': {'name': 'ì¡°ì•½', 'key': 'trty'},
        }

        # ìœ„ì›íšŒ ê²°ì •ë¬¸ target ì½”ë“œ
        self.committee_targets = {
            'ppc': {'name': 'ê°œì¸ì •ë³´ë³´í˜¸ìœ„ì›íšŒ', 'key': 'ppc'},
            'eiac': {'name': 'ê³ ìš©ë³´í—˜ì‹¬ì‚¬ìœ„ì›íšŒ', 'key': 'eiac'},
            'ftc': {'name': 'ê³µì •ê±°ë˜ìœ„ì›íšŒ', 'key': 'ftc'},
            'acr': {'name': 'êµ­ë¯¼ê¶Œìµìœ„ì›íšŒ', 'key': 'acr'},
            'fsc': {'name': 'ê¸ˆìœµìœ„ì›íšŒ', 'key': 'fsc'},
            'nlrc': {'name': 'ë…¸ë™ìœ„ì›íšŒ', 'key': 'nlrc'},
            'kcc': {'name': 'ë°©ì†¡ë¯¸ë””ì–´í†µì‹ ìœ„ì›íšŒ', 'key': 'kcc'},
            'iaciac': {'name': 'ì‚°ì—…ì¬í•´ë³´ìƒë³´í—˜ì¬ì‹¬ì‚¬ìœ„ì›íšŒ', 'key': 'iaciac'},
            'oclt': {'name': 'ì¤‘ì•™í† ì§€ìˆ˜ìš©ìœ„ì›íšŒ', 'key': 'oclt'},
            'ecc': {'name': 'ì¤‘ì•™í™˜ê²½ë¶„ìŸì¡°ì •ìœ„ì›íšŒ', 'key': 'ecc'},
            'sfc': {'name': 'ì¦ê¶Œì„ ë¬¼ìœ„ì›íšŒ', 'key': 'sfc'},
            'nhrck': {'name': 'êµ­ê°€ì¸ê¶Œìœ„ì›íšŒ', 'key': 'nhrck'},
        }

        # ë¶€ì²˜ë³„ ë²•ë ¹í•´ì„ target ì½”ë“œ
        self.ministry_targets = {
            'moelCgmExpc': {'name': 'ê³ ìš©ë…¸ë™ë¶€ ë²•ë ¹í•´ì„', 'key': 'moelCgmExpc'},
            'molitCgmExpc': {'name': 'êµ­í† êµí†µë¶€ ë²•ë ¹í•´ì„', 'key': 'molitCgmExpc'},
            'moefCgmExpc': {'name': 'ê¸°íšì¬ì •ë¶€ ë²•ë ¹í•´ì„', 'key': 'moefCgmExpc'},
            'mofCgmExpc': {'name': 'í•´ì–‘ìˆ˜ì‚°ë¶€ ë²•ë ¹í•´ì„', 'key': 'mofCgmExpc'},
            'moisCgmExpc': {'name': 'í–‰ì •ì•ˆì „ë¶€ ë²•ë ¹í•´ì„', 'key': 'moisCgmExpc'},
            'meCgmExpc': {'name': 'ê¸°í›„ì—ë„ˆì§€í™˜ê²½ë¶€ ë²•ë ¹í•´ì„', 'key': 'meCgmExpc'},
            'kcsCgmExpc': {'name': 'ê´€ì„¸ì²­ ë²•ë ¹í•´ì„', 'key': 'kcsCgmExpc'},
            'ntsCgmExpc': {'name': 'êµ­ì„¸ì²­ ë²•ë ¹í•´ì„', 'key': 'ntsCgmExpc'},
            'moeCgmExpc': {'name': 'êµìœ¡ë¶€ ë²•ë ¹í•´ì„', 'key': 'moeCgmExpc'},
            'msitCgmExpc': {'name': 'ê³¼í•™ê¸°ìˆ ì •ë³´í†µì‹ ë¶€ ë²•ë ¹í•´ì„', 'key': 'msitCgmExpc'},
            'mpvaCgmExpc': {'name': 'êµ­ê°€ë³´í›ˆë¶€ ë²•ë ¹í•´ì„', 'key': 'mpvaCgmExpc'},
            'mndCgmExpc': {'name': 'êµ­ë°©ë¶€ ë²•ë ¹í•´ì„', 'key': 'mndCgmExpc'},
            'mafraCgmExpc': {'name': 'ë†ë¦¼ì¶•ì‚°ì‹í’ˆë¶€ ë²•ë ¹í•´ì„', 'key': 'mafraCgmExpc'},
            'mcstCgmExpc': {'name': 'ë¬¸í™”ì²´ìœ¡ê´€ê´‘ë¶€ ë²•ë ¹í•´ì„', 'key': 'mcstCgmExpc'},
            'mojCgmExpc': {'name': 'ë²•ë¬´ë¶€ ë²•ë ¹í•´ì„', 'key': 'mojCgmExpc'},
            'mohwCgmExpc': {'name': 'ë³´ê±´ë³µì§€ë¶€ ë²•ë ¹í•´ì„', 'key': 'mohwCgmExpc'},
            'motieCgmExpc': {'name': 'ì‚°ì—…í†µìƒìì›ë¶€ ë²•ë ¹í•´ì„', 'key': 'motieCgmExpc'},
            'mogefCgmExpc': {'name': 'ì„±í‰ë“±ê°€ì¡±ë¶€ ë²•ë ¹í•´ì„', 'key': 'mogefCgmExpc'},
            'mofaCgmExpc': {'name': 'ì™¸êµë¶€ ë²•ë ¹í•´ì„', 'key': 'mofaCgmExpc'},
            'mssCgmExpc': {'name': 'ì¤‘ì†Œë²¤ì²˜ê¸°ì—…ë¶€ ë²•ë ¹í•´ì„', 'key': 'mssCgmExpc'},
            'mouCgmExpc': {'name': 'í†µì¼ë¶€ ë²•ë ¹í•´ì„', 'key': 'mouCgmExpc'},
            'molegCgmExpc': {'name': 'ë²•ì œì²˜ ë²•ë ¹í•´ì„', 'key': 'molegCgmExpc'},
            'mfdsCgmExpc': {'name': 'ì‹í’ˆì˜ì•½í’ˆì•ˆì „ì²˜ ë²•ë ¹í•´ì„', 'key': 'mfdsCgmExpc'},
            'mpmCgmExpc': {'name': 'ì¸ì‚¬í˜ì‹ ì²˜ ë²•ë ¹í•´ì„', 'key': 'mpmCgmExpc'},
            'kmaCgmExpc': {'name': 'ê¸°ìƒì²­ ë²•ë ¹í•´ì„', 'key': 'kmaCgmExpc'},
            'khsCgmExpc': {'name': 'êµ­ê°€ìœ ì‚°ì²­ ë²•ë ¹í•´ì„', 'key': 'khsCgmExpc'},
            'rdaCgmExpc': {'name': 'ë†ì´Œì§„í¥ì²­ ë²•ë ¹í•´ì„', 'key': 'rdaCgmExpc'},
            'npaCgmExpc': {'name': 'ê²½ì°°ì²­ ë²•ë ¹í•´ì„', 'key': 'npaCgmExpc'},
            'dapaCgmExpc': {'name': 'ë°©ìœ„ì‚¬ì—…ì²­ ë²•ë ¹í•´ì„', 'key': 'dapaCgmExpc'},
            'mmaCgmExpc': {'name': 'ë³‘ë¬´ì²­ ë²•ë ¹í•´ì„', 'key': 'mmaCgmExpc'},
            'kfsCgmExpc': {'name': 'ì‚°ë¦¼ì²­ ë²•ë ¹í•´ì„', 'key': 'kfsCgmExpc'},
            'nfaCgmExpc': {'name': 'ì†Œë°©ì²­ ë²•ë ¹í•´ì„', 'key': 'nfaCgmExpc'},
            'okaCgmExpc': {'name': 'ì¬ì™¸ë™í¬ì²­ ë²•ë ¹í•´ì„', 'key': 'okaCgmExpc'},
            'ppsCgmExpc': {'name': 'ì¡°ë‹¬ì²­ ë²•ë ¹í•´ì„', 'key': 'ppsCgmExpc'},
            'kdcaCgmExpc': {'name': 'ì§ˆë³‘ê´€ë¦¬ì²­ ë²•ë ¹í•´ì„', 'key': 'kdcaCgmExpc'},
            'kostatCgmExpc': {'name': 'êµ­ê°€ë°ì´í„°ì²˜ ë²•ë ¹í•´ì„', 'key': 'kostatCgmExpc'},
            'kipoCgmExpc': {'name': 'ì§€ì‹ì¬ì‚°ì²˜ ë²•ë ¹í•´ì„', 'key': 'kipoCgmExpc'},
            'kcgCgmExpc': {'name': 'í•´ì–‘ê²½ì°°ì²­ ë²•ë ¹í•´ì„', 'key': 'kcgCgmExpc'},
            'naaccCgmExpc': {'name': 'í–‰ì •ì¤‘ì‹¬ë³µí•©ë„ì‹œê±´ì„¤ì²­ ë²•ë ¹í•´ì„', 'key': 'naaccCgmExpc'},
        }

        # íŠ¹ë³„í–‰ì •ì‹¬íŒë¡€ target ì½”ë“œ
        self.special_tribunal_targets = {
            'ttSpecialDecc': {'name': 'ì¡°ì„¸ì‹¬íŒì› íŠ¹ë³„í–‰ì •ì‹¬íŒë¡€', 'key': 'ttSpecialDecc'},
            'kmstSpecialDecc': {'name': 'í•´ì–‘ì•ˆì „ì‹¬íŒì› íŠ¹ë³„í–‰ì •ì‹¬íŒë¡€', 'key': 'kmstSpecialDecc'},
            'acrSpecialDecc': {'name': 'êµ­ë¯¼ê¶Œìµìœ„ì›íšŒ íŠ¹ë³„í–‰ì •ì‹¬íŒë¡€', 'key': 'acrSpecialDecc'},
            'adapSpecialDecc': {'name': 'ì¸ì‚¬í˜ì‹ ì²˜ ì†Œì²­ì‹¬ì‚¬ìœ„ì›íšŒ ì¬ê²°ë¡€', 'key': 'adapSpecialDecc'},
        }

        # ì‚¬ê±´ë²ˆí˜¸/ì•ˆê±´ë²ˆí˜¸ íŒ¨í„´ ì •ê·œì‹
        # íŒë¡€ ì‚¬ê±´ë²ˆí˜¸ íŒ¨í„´: 2020ë‹¤12345, 2021êµ¬í•©12345, 2019ë…¸1234 ë“±
        self.prec_case_pattern = re.compile(
            r'(\d{2,4})[\s]*'  # ì—°ë„ (2ìë¦¬ ë˜ëŠ” 4ìë¦¬)
            r'([ê°€-í£]{1,4})'  # ì‚¬ê±´ìœ í˜• (ë‹¤, êµ¬í•©, ë…¸, ê°€í•© ë“±)
            r'[\s]*(\d+)'  # ì‚¬ê±´ë²ˆí˜¸
            r'(?:,?\s*(\d+))?'  # ë³‘í•©ì‚¬ê±´ (ì„ íƒ)
        )

        # ë²•ë ¹í•´ì„ë¡€ ì•ˆê±´ë²ˆí˜¸ íŒ¨í„´: 18-0701, 22-0123, 2018-0701 ë“±
        self.expc_case_pattern = re.compile(
            r'(\d{2,4})'  # ì—°ë„ (2ìë¦¬ ë˜ëŠ” 4ìë¦¬)
            r'[-\s]?'  # êµ¬ë¶„ì
            r'(\d{3,5})'  # ì•ˆê±´ë²ˆí˜¸
        )

    def detect_case_number(self, query: str) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì‚¬ê±´ë²ˆí˜¸/ì•ˆê±´ë²ˆí˜¸ íŒ¨í„´ ê°ì§€

        Returns:
            Dict with keys:
                - 'type': 'prec' (íŒë¡€), 'expc' (ë²•ë ¹í•´ì„ë¡€), 'decc' (í–‰ì •ì‹¬íŒë¡€), or None
                - 'case_numbers': ê°ì§€ëœ ì‚¬ê±´ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸
                - 'formatted': APIìš© í¬ë§·ëœ ì‚¬ê±´ë²ˆí˜¸
        """
        result = {
            'type': None,
            'case_numbers': [],
            'formatted': None,
            'original': query
        }

        query_clean = query.strip()

        # 1. íŒë¡€ ì‚¬ê±´ë²ˆí˜¸ íŒ¨í„´ ê²€ì‚¬ (ì˜ˆ: 2020ë‹¤12345, 2021êµ¬í•©12345)
        prec_matches = self.prec_case_pattern.findall(query_clean)
        if prec_matches:
            case_numbers = []
            for match in prec_matches:
                year, case_type, number, merged = match
                # 2ìë¦¬ ì—°ë„ë¥¼ 4ìë¦¬ë¡œ ë³€í™˜
                if len(year) == 2:
                    year = '20' + year if int(year) < 50 else '19' + year
                case_no = f"{year}{case_type}{number}"
                if merged:
                    case_no += f",{merged}"
                case_numbers.append(case_no)

            if case_numbers:
                result['type'] = 'prec'
                result['case_numbers'] = case_numbers
                # APIìš© nb íŒŒë¼ë¯¸í„° í˜•ì‹
                result['formatted'] = ','.join(case_numbers)
                return result

        # 2. ë²•ë ¹í•´ì„ë¡€ ì•ˆê±´ë²ˆí˜¸ íŒ¨í„´ ê²€ì‚¬ (ì˜ˆ: 18-0701, 22-0123)
        # íŒ¨í„´: XX-XXXX í˜•ì‹ (í•˜ì´í”ˆ í¬í•¨)
        expc_pattern_strict = re.compile(r'(\d{2,4})-(\d{3,5})')
        expc_matches = expc_pattern_strict.findall(query_clean)
        if expc_matches:
            case_numbers = []
            formatted_numbers = []
            for year, number in expc_matches:
                # ì›ë³¸ í˜•ì‹ ìœ ì§€
                original = f"{year}-{number}"
                case_numbers.append(original)
                # APIìš© itmno íŒŒë¼ë¯¸í„° í˜•ì‹ (í•˜ì´í”ˆ ì œê±°)
                formatted_numbers.append(f"{year}{number}")

            if case_numbers:
                result['type'] = 'expc'
                result['case_numbers'] = case_numbers
                # ë²•ë ¹í•´ì„ë¡€ëŠ” í•˜ì´í”ˆ ì œê±°í•œ í˜•ì‹
                result['formatted'] = formatted_numbers[0]  # ì²« ë²ˆì§¸ë§Œ
                return result

        # 3. í–‰ì •ì‹¬íŒë¡€ íŒ¨í„´ - ì¼ë°˜ì ìœ¼ë¡œ "ì¤‘í–‰ì‹¬ XXXX-XXXXX" í˜•ì‹
        # ë˜ëŠ” "XXXX-XXXXX" í˜•ì‹ì˜ ìˆ«ìë§Œ ìˆëŠ” ê²½ìš°
        decc_pattern = re.compile(r'(\d{4})-(\d{4,6})')
        decc_matches = decc_pattern.findall(query_clean)
        if decc_matches and not expc_matches:  # expcì™€ êµ¬ë¶„
            case_numbers = [f"{year}-{number}" for year, number in decc_matches]
            result['type'] = 'decc'
            result['case_numbers'] = case_numbers
            result['formatted'] = case_numbers[0]
            return result

        return result

    async def search_by_case_number(self, case_info: Dict[str, Any]) -> Dict:
        """ì‚¬ê±´ë²ˆí˜¸/ì•ˆê±´ë²ˆí˜¸ë¡œ ì§ì ‘ ê²€ìƒ‰

        Args:
            case_info: detect_case_number()ì˜ ë°˜í™˜ê°’

        Returns:
            ê²€ìƒ‰ ê²°ê³¼ Dict
        """
        if not case_info.get('type') or not case_info.get('formatted'):
            return {}

        case_type = case_info['type']
        formatted = case_info['formatted']
        api_key = self.law_api_key or get_law_api_key()

        if not api_key:
            logger.warning("ë²•ì œì²˜ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {}

        results = {case_type: []}

        try:
            async with aiohttp.ClientSession() as session:
                if case_type == 'prec':
                    # íŒë¡€: nb íŒŒë¼ë¯¸í„°ë¡œ ì‚¬ê±´ë²ˆí˜¸ ê²€ìƒ‰
                    params = {
                        'OC': api_key,
                        'target': 'prec',
                        'type': 'JSON',
                        'nb': formatted,  # ì‚¬ê±´ë²ˆí˜¸
                        'display': 20
                    }
                    logger.info(f"íŒë¡€ ì‚¬ê±´ë²ˆí˜¸ ê²€ìƒ‰: nb={formatted}")

                elif case_type == 'expc':
                    # ë²•ë ¹í•´ì„ë¡€: itmno íŒŒë¼ë¯¸í„°ë¡œ ì•ˆê±´ë²ˆí˜¸ ê²€ìƒ‰
                    params = {
                        'OC': api_key,
                        'target': 'expc',
                        'type': 'JSON',
                        'itmno': formatted,  # ì•ˆê±´ë²ˆí˜¸ (í•˜ì´í”ˆ ì œê±°)
                        'display': 20
                    }
                    logger.info(f"ë²•ë ¹í•´ì„ë¡€ ì•ˆê±´ë²ˆí˜¸ ê²€ìƒ‰: itmno={formatted}")

                elif case_type == 'decc':
                    # í–‰ì •ì‹¬íŒë¡€: queryë¡œ ì‚¬ê±´ë²ˆí˜¸ ê²€ìƒ‰ (ì§ì ‘ íŒŒë¼ë¯¸í„° ì—†ìŒ)
                    params = {
                        'OC': api_key,
                        'target': 'decc',
                        'type': 'JSON',
                        'query': case_info['case_numbers'][0],  # ì‚¬ê±´ë²ˆí˜¸ë¡œ ê²€ìƒ‰
                        'display': 20
                    }
                    logger.info(f"í–‰ì •ì‹¬íŒë¡€ ì‚¬ê±´ë²ˆí˜¸ ê²€ìƒ‰: query={case_info['case_numbers'][0]}")
                else:
                    return {}

                async with session.get(
                    self.api_endpoints['search'],
                    params=params,
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    if response.status == 200:
                        text = await response.text()
                        try:
                            data = json.loads(text)
                            logger.info(f"[{case_type}] ì‚¬ê±´ë²ˆí˜¸ ê²€ìƒ‰ ì‘ë‹µ: {list(data.keys())}")

                            # ê²°ê³¼ ì¶”ì¶œ
                            items = self._extract_search_results(data, case_type)
                            results[case_type] = items
                            logger.info(f"[{case_type}] ì‚¬ê±´ë²ˆí˜¸ ê²€ìƒ‰ ê²°ê³¼: {len(items)}ê±´")

                        except json.JSONDecodeError as e:
                            logger.error(f"ì‚¬ê±´ë²ˆí˜¸ ê²€ìƒ‰ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                    else:
                        logger.error(f"ì‚¬ê±´ë²ˆí˜¸ ê²€ìƒ‰ API ì˜¤ë¥˜: {response.status}")

        except Exception as e:
            logger.error(f"ì‚¬ê±´ë²ˆí˜¸ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")

        return results

    def _extract_search_results(self, data: Dict, target: str) -> List[Dict]:
        """API ì‘ë‹µì—ì„œ ê²€ìƒ‰ ê²°ê³¼ ë°°ì—´ ì¶”ì¶œ"""
        results = []

        # API ì‘ë‹µ êµ¬ì¡°ì—ì„œ ì‹¤ì œ ë°ì´í„° ì°¾ê¸°
        wrapper_keys = [
            f'{target.capitalize()}Search',
            target.capitalize(),
            f'{target.upper()}Search',
            target,
            target.lower(),
            target.upper(),
        ]

        inner_data = data
        for wkey in wrapper_keys:
            if wkey in data and isinstance(data[wkey], dict):
                inner_data = data[wkey]
                break
            elif wkey in data and isinstance(data[wkey], list):
                return data[wkey]

        if isinstance(inner_data, dict):
            data_keys = [target.lower(), target, target.capitalize()]
            for dkey in data_keys:
                if dkey in inner_data:
                    value = inner_data[dkey]
                    if isinstance(value, list) and len(value) > 0:
                        return value

            # ì²« ë²ˆì§¸ ë¦¬ìŠ¤íŠ¸ ì°¾ê¸°
            skip_keys = {'totalCnt', 'page', 'target', 'section', 'í‚¤ì›Œë“œ',
                        'resultMsg', 'resultCode', 'numOfRows'}
            for key, value in inner_data.items():
                if key not in skip_keys and isinstance(value, list) and len(value) > 0:
                    return value

        return results

    def extract_keywords(self, user_input: str) -> List[str]:
        """ì‚¬ìš©ì ì…ë ¥ì—ì„œ ë²•ë¥  ê´€ë ¨ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ - ë²•ë¥ ëª…/ì¡°ë¬¸ ìš°ì„ """
        # ë¶ˆìš©ì–´ ì •ì˜ (ì¼ë°˜ì ì¸ ë‹¨ì–´, ì¡°ì‚¬, êµ¬ì–´ì²´ í‘œí˜„ ë“±)
        stopwords = [
            # ì¡°ì‚¬
            'ì€', 'ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì˜', 'ì—', 'ì—ì„œ', 'ìœ¼ë¡œ', 'ë¡œ',
            'ì™€', 'ê³¼', 'ë„', 'ë§Œ', 'ë¿', 'ê¹Œì§€', 'ë¶€í„°', 'ì—ê²Œ', 'í•œí…Œ', 'ê»˜',
            # ì–´ë¯¸/ì„œìˆ ì–´
            'ì…ë‹ˆë‹¤', 'í•©ë‹ˆë‹¤', 'ìˆìŠµë‹ˆë‹¤', 'ì—†ìŠµë‹ˆë‹¤', 'ë©ë‹ˆë‹¤', 'ìŠµë‹ˆë‹¤',
            'í•˜ëŠ”', 'ë˜ëŠ”', 'ìˆëŠ”', 'ì—†ëŠ”', 'í•œ', 'ëœ', 'í• ', 'ë ',
            'í–ˆìŠµë‹ˆë‹¤', 'í–ˆë‹¤', 'í•œë‹¤', 'í•˜ë‹¤', 'ì´ë‹¤',
            # ì ‘ì†ì–´
            'ê²ƒ', 'ìˆ˜', 'ë•Œ', 'ë“±', 'ë°', 'ë˜ëŠ”', 'ê·¸ë¦¬ê³ ', 'í•˜ì§€ë§Œ', 'ê·¸ëŸ¬ë‚˜',
            # ì˜ë¬¸ì‚¬
            'ì–´ë–»ê²Œ', 'ë¬´ì—‡', 'ì–´ë””', 'ì–¸ì œ', 'ëˆ„êµ¬', 'ì™œ', 'ì–´ë–¤',
            # ë¶€ì‚¬
            'ì¢€', 'ì˜', 'ë”', 'ë§¤ìš°', 'ì •ë§', 'ì•„ì£¼', 'ë„ˆë¬´', 'ë§ì´', 'í˜„ì¬', 'ì§€ê¸ˆ',
            # ëŒ€ëª…ì‚¬/ì§€ì‹œì–´
            'ì €', 'ì œ', 'ë‚˜', 'ë‚´', 'ìš°ë¦¬', 'ì €í¬', 'ê·¸', 'ê·¸ë…€', 'ê·¸ë“¤',
            'ì´ê²ƒ', 'ì €ê²ƒ', 'ê·¸ê²ƒ', 'ì—¬ê¸°', 'ê±°ê¸°', 'ì €ê¸°',
            # ì¼ë°˜ ëª…ì‚¬ (ë²•ë¥ ê³¼ ë¬´ê´€)
            'í˜„í–‰', 'í•´ë‹¹', 'ìš”ê±´', 'í™•ì¸', 'ê²€ìƒ‰', 'ê´€ë ¨', 'íŒë¡€',
            'ì‚¬ëŒ', 'ê²½ìš°', 'ìƒí™©', 'ë¬¸ì œ', 'ë¶€ë¶„', 'ë°©ë²•', 'ì •ë„',
            # êµ¬ì–´ì²´/ë¬¸ì¥ í‘œí˜„
            'ìˆì„ê¹Œìš”', 'ë ê¹Œìš”', 'ì¸ê°€ìš”', 'ì¼ê¹Œìš”', 'í• ê¹Œìš”', 'ì‹¶ìŠµë‹ˆë‹¤',
            'ì—„ë§ˆë¡œì¨', 'ì•„ë¹ ë¡œì¨', 'ì°¾ì•„ê°€ì', 'ë³´ëŸ¬', 'ëª‡ë²ˆ', 'ìê¸°ì—ê²Œ',
            'ìˆë‹¤ê³ ', 'í•œë‹¤ê³ ', 'ë¼ê³ ', 'ë‹¤ê³ ',
        ]

        keywords = []

        # 1. ë²•ë¥ ëª… íŒ¨í„´ ì¶”ì¶œ (XXë²•, XXë ¹, XXê·œì¹™ ë“±) - ìµœìš°ì„ 
        law_patterns = re.findall(r'[ê°€-í£]+(?:ë²•|ë ¹|ê·œì¹™|ì¡°ë¡€|ê·œì •|ì§€ì¹¨|ê³ ì‹œ)', user_input)
        for law in law_patterns:
            if len(law) >= 3 and law not in keywords:
                keywords.append(law)

        # 2. ì¡°ë¬¸ ê´€ë ¨ ì¶”ì¶œ (ì œXì¡°, ì œXí•­ ë“±)
        article_patterns = re.findall(r'ì œ\d+ì¡°(?:ì˜\d+)?(?:ì œ\d+í•­)?', user_input)
        keywords.extend(article_patterns)

        # 3. êµ¬ì²´ì ì¸ ë²•ë¥  ìš©ì–´ (ë³µí•© í‚¤ì›Œë“œ ìš°ì„ )
        specific_legal_terms = [
            # ê°€ì¡±ë²•/ì´í˜¼ ê´€ë ¨ - ì¤‘ìš”!
            'ë©´ì ‘êµì„­ê¶Œ', 'ë©´ì ‘êµì„­', 'ì–‘ìœ¡ê¶Œ', 'ì¹œê¶Œ', 'ì–‘ìœ¡ë¹„',
            'ì ‘ê·¼ê¸ˆì§€', 'ì ‘ê·¼ê¸ˆì§€ê°€ì²˜ë¶„', 'ê°€ì²˜ë¶„', 'ì„ì‹œì²˜ë¶„',
            'ì´í˜¼ì†Œì†¡', 'í˜‘ì˜ì´í˜¼', 'ì¬íŒì´í˜¼', 'ì¬ì‚°ë¶„í• ì²­êµ¬',
            'ìœ„ìë£Œì²­êµ¬', 'ì–‘ìœ¡ìì§€ì •', 'ì¹œê¶Œìì§€ì •',
            # ê¸ˆìœµ/ëŒ€ë¶€ì—… ê´€ë ¨
            'ëŒ€ë¶€ì—…', 'ëŒ€ë¶€ì¤‘ê°œì—…', 'ë§¤ì…ì±„ê¶Œì¶”ì‹¬ì—…', 'ë§¤ì…ì±„ê¶Œ', 'ì¶”ì‹¬ì—…',
            'ìê¸°ìë³¸', 'ìë³¸ê¸ˆ', 'ë“±ë¡ìš”ê±´', 'ì˜ì—…ìš”ê±´',
            'ê¸ˆìœµì—…', 'ì—¬ì‹ ì—…', 'ì‹ ìš©ì •ë³´', 'ì±„ê¶Œì¶”ì‹¬', 'ì±„ê¶Œë§¤ì…',
            'ë“±ë¡ê¸°ì¤€', 'í—ˆê°€ê¸°ì¤€', 'ì¸ê°€ê¸°ì¤€', 'ìë³¸ìš”ê±´',
            # ë…¸ë™ë²• ê´€ë ¨
            'ë¶€ë‹¹í•´ê³ ', 'í•´ê³ ë¬´íš¨', 'ë¶€ë‹¹ë…¸ë™í–‰ìœ„', 'ê·¼ë¡œê³„ì•½',
            'í•´ê³ ì˜ˆê³ ', 'ì •ë¦¬í•´ê³ ', 'ì§•ê³„í•´ê³ ', 'í‡´ì§ê¸ˆì²­êµ¬',
            # ë¶€ë™ì‚°/ì„ëŒ€ì°¨ ê´€ë ¨
            'ì„ëŒ€ì°¨ë³´í˜¸', 'ìƒê°€ì„ëŒ€ì°¨', 'ì£¼íƒì„ëŒ€ì°¨', 'ì „ì„¸ë³´ì¦ê¸ˆ',
            'ëª…ë„ì†Œì†¡', 'ì„ëŒ€ì°¨ê³„ì•½', 'ë³´ì¦ê¸ˆë°˜í™˜', 'ê³„ì•½ê°±ì‹ ',
            # ë¯¼ì‚¬ ì¼ë°˜
            'ì†í•´ë°°ìƒ', 'ë¶ˆë²•í–‰ìœ„', 'ì±„ë¬´ë¶ˆì´í–‰', 'ê³„ì•½ìœ„ë°˜',
            'ì†í•´ë°°ìƒì²­êµ¬', 'ìœ„ì•½ê¸ˆ', 'ì§€ì²´ìƒê¸ˆ',
            # ê°œì¸ì •ë³´/ê³µì •ê±°ë˜
            'ê°œì¸ì •ë³´ë³´í˜¸', 'ì •ë³´ì£¼ì²´', 'ê°œì¸ì •ë³´ì²˜ë¦¬',
            'ê³µì •ê±°ë˜', 'ë…ì ê·œì œ', 'ë¶ˆê³µì •ê±°ë˜', 'ì‹œì¥ì§€ë°°ì ì§€ìœ„',
        ]

        for term in specific_legal_terms:
            if term in user_input and term not in keywords:
                keywords.append(term)

        # 4. ì¼ë°˜ ë²•ë¥  í‚¤ì›Œë“œ
        general_legal_keywords = [
            # ê°€ì¡±ë²•
            'ì´í˜¼', 'ì–‘ìœ¡', 'ì¹œê¶Œ', 'ë©´ì ‘', 'êµì„­', 'ìœ„ìë£Œ', 'ì¬ì‚°ë¶„í• ',
            'ê°€ì²˜ë¶„', 'ì„ì‹œ', 'ì²˜ë¶„', 'ì ‘ê·¼', 'ê¸ˆì§€', 'ë°°ìš°ì', 'ìë…€',
            'ìƒì†', 'ìœ ì–¸', 'ì¦ì—¬', 'ìœ ë¥˜ë¶„',
            # ë…¸ë™ë²•
            'í•´ê³ ', 'ì„ê¸ˆ', 'í‡´ì§ê¸ˆ', 'ê·¼ë¡œ', 'ë…¸ë™', 'ê³„ì•½', 'ìœ„ë°˜',
            # ë¯¼ì‚¬
            'ì†í•´ë°°ìƒ', 'ë¶ˆë²•í–‰ìœ„', 'ê³„ì•½í•´ì§€', 'ê³„ì•½í•´ì œ',
            'ì„ëŒ€ì°¨', 'ì „ì„¸', 'ì›”ì„¸', 'ë³´ì¦ê¸ˆ', 'ëª…ë„', 'ì¸ë„',
            # ì†Œì†¡
            'í˜•ì‚¬', 'ë¯¼ì‚¬', 'í–‰ì •', 'ì†Œì†¡', 'ì¬íŒ', 'í•­ì†Œ', 'ìƒê³ ', 'íŒê²°',
            # í˜•ì‚¬
            'ì‚¬ê¸°', 'íš¡ë ¹', 'ë°°ì„', 'í­í–‰', 'ìƒí•´', 'ëª…ì˜ˆí›¼ì†',
            # ì§€ì¬ê¶Œ
            'ì €ì‘ê¶Œ', 'íŠ¹í—ˆ', 'ìƒí‘œ', 'ì˜ì—…ë¹„ë°€', 'ì§€ì‹ì¬ì‚°',
            'ê°œì¸ì •ë³´', 'ì •ë³´ë³´í˜¸', 'í”„ë¼ì´ë²„ì‹œ',
            # ì¡°ì„¸
            'ì„¸ê¸ˆ', 'ì¡°ì„¸', 'ë¶€ê°€ì„¸', 'ì†Œë“ì„¸', 'ë²•ì¸ì„¸', 'ìƒì†ì„¸', 'ì¦ì—¬ì„¸',
            # í–‰ì •
            'ê±´ì¶•', 'ì¸í—ˆê°€', 'í—ˆê°€', 'ì‹ ê³ ', 'ë“±ë¡', 'ë©´í—ˆ',
            # ê¸°íƒ€
            'êµí†µì‚¬ê³ ', 'ì‚°ì¬', 'ì‚°ì—…ì¬í•´', 'ë³´í—˜', 'ë³´ìƒ',
            'íŒŒì‚°', 'íšŒìƒ', 'ë„ì‚°', 'ì±„ë¬´', 'ì±„ê¶Œ', 'ë‹´ë³´', 'ì €ë‹¹', 'ì••ë¥˜',
            'í•´ì œ', 'ì·¨ì†Œ', 'ë¬´íš¨', 'ì² íšŒ', 'í•´ì§€',
            'ìœ„ì„', 'ëŒ€ë¦¬', 'ë³´ì¦', 'ì—°ëŒ€ë³´ì¦'
        ]

        for kw in general_legal_keywords:
            if kw in user_input and kw not in keywords:
                keywords.append(kw)

        # 5. ë‚¨ì€ ëª…ì‚¬ ì¶”ì¶œ (2ê¸€ì ì´ìƒ, 4ê¸€ì ì´ìƒ ìš°ì„ )
        words = re.findall(r'[ê°€-í£]{2,}', user_input)
        long_words = [w for w in words if len(w) >= 4]
        short_words = [w for w in words if len(w) >= 2 and len(w) < 4]

        for word in long_words + short_words:
            is_stopword = any(word.endswith(sw) or word == sw for sw in stopwords)
            if not is_stopword and word not in keywords:
                keywords.append(word)

        # 6. ì¤‘ë³µ ì œê±° ë° ìƒìœ„ í‚¤ì›Œë“œ ë°˜í™˜
        unique_keywords = list(dict.fromkeys(keywords))
        return unique_keywords[:10]  # ìµœëŒ€ 10ê°œ í‚¤ì›Œë“œ

    def analyze_query_with_ai(self, user_input: str) -> Dict:
        """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì§ˆì˜ ì˜ë„ íŒŒì•… ë° ê²€ìƒ‰ í‚¤ì›Œë“œ ìƒì„±

        ì‚¬ìš©ìì˜ ë²•ë¥  ê²€í†  ì§ˆì˜ë¥¼ ë¶„ì„í•˜ì—¬:
        1. ì§ˆì˜ ì˜ë„ì™€ ë²•ì  ìŸì  íŒŒì•…
        2. ê´€ë ¨ ë²•ë ¹, íŒë¡€, ìœ ê¶Œí•´ì„ ê²€ìƒ‰ì„ ìœ„í•œ ìµœì  í‚¤ì›Œë“œ ìƒì„±
        3. ê²€ìƒ‰ ìš°ì„ ìˆœìœ„ ë° ì¶”ì²œ ê²€ìƒ‰ ìœ í˜• ì œì•ˆ
        """
        # ê¸°ë³¸ í‚¤ì›Œë“œ ë¨¼ì € ì¶”ì¶œ (fallbackìš©)
        basic_keywords = self.extract_keywords(user_input)
        default_result = {
            'intent': 'ë²•ë¥  ì •ë³´ ê²€ìƒ‰',
            'legal_issues': [],
            'law_names': [],
            'keywords': basic_keywords,
            'search_queries': basic_keywords[:3] if basic_keywords else [user_input],
            'search_priority': {
                'laws': True,
                'precedents': True,
                'interpretations': True,
                'committee_decisions': False,
                'ministry_opinions': False
            },
            'recommended_sources': ['law', 'prec']
        }

        client = get_openai_client()
        if not client:
            logger.info("OpenAI í´ë¼ì´ì–¸íŠ¸ ì—†ìŒ - ê¸°ë³¸ í‚¤ì›Œë“œ ì‚¬ìš©")
            return default_result

        try:
            prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ ë²•ë¥  ê²€ìƒ‰ ë° ë²•ë¥  ê²€í†  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ë²•ë¥  ê²€í†  ì§ˆì˜ë¥¼ ê¹Šì´ ë¶„ì„í•˜ì—¬ ë²•ì œì²˜ Open API ê²€ìƒ‰ì— ìµœì í™”ëœ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

## ì‚¬ìš©ì ì§ˆì˜
{user_input}

## ë¶„ì„ ì§€ì¹¨
1. ì§ˆì˜ì—ì„œ **í•µì‹¬ ë²•ì  ìŸì **ì„ ì •í™•íˆ íŒŒì•…í•˜ì„¸ìš”.
2. ë°°ê²½ ì„¤ëª…ì´ ì•„ë‹Œ **ì‹¤ì œ ì§ˆë¬¸**ì— ì§‘ì¤‘í•˜ì„¸ìš”.
3. ê´€ë ¨ ë²•ë¥  ì¡°ë¬¸ê³¼ ë²•ì  ê°œë…ì„ ì •í™•íˆ ì‹ë³„í•˜ì„¸ìš”.
4. ê²€ìƒ‰ì–´ëŠ” í•µì‹¬ ìŸì ì— ì§ì ‘ ê´€ë ¨ëœ ê²ƒë§Œ ìƒì„±í•˜ì„¸ìš”.

## ë¶„ì„ ìš”ì²­
ìœ„ ì§ˆì˜ë¥¼ ë¶„ì„í•˜ì—¬ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš” (ë‹¤ë¥¸ ì„¤ëª… ì—†ì´):

{{
    "intent": "ì§ˆë¬¸ì˜ í•µì‹¬ ì˜ë„ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ",
    "core_question": "ì‚¬ìš©ìê°€ ì‹¤ì œë¡œ ì•Œê³  ì‹¶ì€ ë²•ì  ì§ˆë¬¸",
    "legal_issues": ["í•µì‹¬ ë²•ì  ìŸì  ë¦¬ìŠ¤íŠ¸ - ì§ˆë¬¸ê³¼ ì§ì ‘ ê´€ë ¨ëœ ê²ƒë§Œ"],
    "law_names": ["ê´€ë ¨ ë²•ë¥ ëª… (ë¯¼ë²•, ê°€ì‚¬ì†Œì†¡ë²• ë“±)"],
    "legal_concepts": ["ê´€ë ¨ ë²•ì  ê°œë… (ë©´ì ‘êµì„­ê¶Œ, ê°€ì²˜ë¶„ ë“±)"],
    "keywords": ["í•µì‹¬ ê²€ìƒ‰ í‚¤ì›Œë“œ 5ê°œ"],
    "search_queries": ["ë²•ì œì²˜ API ê²€ìƒ‰ì–´ 5ê°œ - í•µì‹¬ ìŸì  ì¤‘ì‹¬"],
    "search_priority": {{
        "laws": true/false,
        "precedents": true/false,
        "interpretations": true/false,
        "committee_decisions": true/false,
        "ministry_opinions": true/false
    }},
    "recommended_sources": ["law", "prec", "expc", "decc"]
}}

## ê²€ìƒ‰ì–´ ìƒì„± ê·œì¹™ (ë§¤ìš° ì¤‘ìš”!)
âš ï¸ ë²•ì œì²˜ APIëŠ” ë‹¨ìˆœ í‚¤ì›Œë“œ ë§¤ì¹­ì…ë‹ˆë‹¤. ê¸´ ë¬¸ì¥ì€ ê²€ìƒ‰ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤!

1. **ê²€ìƒ‰ì–´ëŠ” ë°˜ë“œì‹œ 2-3ë‹¨ì–´ ì´í•˜ë¡œ ì§§ê²Œ**:
   - âŒ "ë¯¼ë²• ë©´ì ‘êµì„­ê¶Œ ì´í˜¼ì†Œì†¡ ì¤‘ ì„ì‹œì²˜ë¶„" (ë„ˆë¬´ ê¹€)
   - âœ… "ë©´ì ‘êµì„­ê¶Œ", "ë©´ì ‘êµì„­ ê°€ì²˜ë¶„" (ì§§ê³  í•µì‹¬ì )

2. **ë‹¨ì–´ ì¡°í•© íŒ¨í„´**:
   - ë²•ë¥ ëª… ë‹¨ë…: "ë¯¼ë²•", "ê°€ì‚¬ì†Œì†¡ë²•"
   - í•µì‹¬ê°œë… ë‹¨ë…: "ë©´ì ‘êµì„­ê¶Œ", "ì–‘ìœ¡ê¶Œ"
   - 2ë‹¨ì–´ ì¡°í•©: "ë©´ì ‘êµì„­ ê°€ì²˜ë¶„", "ì–‘ìœ¡ê¶Œ ì„ì‹œì²˜ë¶„"

3. **í”¼í•´ì•¼ í•  ê²ƒ**:
   - ë¬¸ì¥í˜• ì¿¼ë¦¬ ê¸ˆì§€
   - ì¡°ì‚¬(ì˜, ì—, ë¥¼) ì‚¬ìš© ê¸ˆì§€
   - 4ë‹¨ì–´ ì´ìƒ ì¡°í•© ê¸ˆì§€

## ì˜ˆì‹œ 1 - ê°€ì¡±ë²•
ì§ˆì˜: "ì´í˜¼ ì†Œì†¡ ì¤‘ ì ‘ê·¼ê¸ˆì§€ ê°€ì²˜ë¶„ ìƒíƒœì—ì„œ ë©´ì ‘êµì„­ê¶Œì„ ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?"
ì‘ë‹µ:
{{
    "intent": "ì ‘ê·¼ê¸ˆì§€ ê°€ì²˜ë¶„ê³¼ ë©´ì ‘êµì„­ê¶Œì˜ ê´€ê³„ í™•ì¸",
    "core_question": "ì ‘ê·¼ê¸ˆì§€ ê°€ì²˜ë¶„ì´ ìˆì–´ë„ ìë…€ ë©´ì ‘êµì„­ê¶Œì„ í–‰ì‚¬í•  ìˆ˜ ìˆëŠ”ì§€",
    "legal_issues": ["ë©´ì ‘êµì„­ê¶Œì˜ ë²•ì  ì„±ê²©", "ì ‘ê·¼ê¸ˆì§€ ê°€ì²˜ë¶„ì˜ íš¨ë ¥ ë²”ìœ„", "ì´í˜¼ì†Œì†¡ ì¤‘ ì„ì‹œ ë©´ì ‘êµì„­"],
    "law_names": ["ë¯¼ë²•", "ê°€ì‚¬ì†Œì†¡ë²•", "ê°€ì‚¬ì†Œì†¡ê·œì¹™"],
    "legal_concepts": ["ë©´ì ‘êµì„­ê¶Œ", "ì ‘ê·¼ê¸ˆì§€ê°€ì²˜ë¶„", "ì–‘ìœ¡ê¶Œ", "ì„ì‹œì²˜ë¶„"],
    "keywords": ["ë©´ì ‘êµì„­ê¶Œ", "ì ‘ê·¼ê¸ˆì§€", "ê°€ì²˜ë¶„", "ì–‘ìœ¡ê¶Œ", "ì´í˜¼"],
    "search_queries": ["ë©´ì ‘êµì„­ê¶Œ", "ë©´ì ‘êµì„­ ê°€ì²˜ë¶„", "ì ‘ê·¼ê¸ˆì§€ ê°€ì²˜ë¶„", "ì–‘ìœ¡ê¶Œ", "ì„ì‹œì²˜ë¶„"],
    "search_priority": {{
        "laws": true,
        "precedents": true,
        "interpretations": true,
        "committee_decisions": false,
        "ministry_opinions": false
    }},
    "recommended_sources": ["law", "prec", "expc"]
}}

## ì˜ˆì‹œ 2 - í–‰ì •ë²•
ì§ˆì˜: "ëŒ€ë¶€ì—…ë²•ìƒ ìê¸°ìë³¸ ìš”ê±´ì´ ì–¼ë§ˆì¸ê°€ìš”?"
ì‘ë‹µ:
{{
    "intent": "ëŒ€ë¶€ì—… ë“±ë¡ìš”ê±´ ì¤‘ ìê¸°ìë³¸ ê¸°ì¤€ í™•ì¸",
    "core_question": "ëŒ€ë¶€ì—… ë“±ë¡ì— í•„ìš”í•œ ìê¸°ìë³¸ ê¸ˆì•¡",
    "legal_issues": ["ëŒ€ë¶€ì—… ë“±ë¡ìš”ê±´", "ìê¸°ìë³¸ ì‚°ì •ê¸°ì¤€"],
    "law_names": ["ëŒ€ë¶€ì—…ë²•", "ëŒ€ë¶€ì—…ë²• ì‹œí–‰ë ¹"],
    "legal_concepts": ["ìê¸°ìë³¸", "ë“±ë¡ìš”ê±´", "ëŒ€ë¶€ì—…"],
    "keywords": ["ëŒ€ë¶€ì—…", "ìê¸°ìë³¸", "ë“±ë¡ìš”ê±´"],
    "search_queries": ["ëŒ€ë¶€ì—…ë²• ìê¸°ìë³¸", "ëŒ€ë¶€ì—… ë“±ë¡ìš”ê±´", "ëŒ€ë¶€ì—…ë²• ì‹œí–‰ë ¹ ìë³¸"],
    "search_priority": {{
        "laws": true,
        "precedents": false,
        "interpretations": true,
        "committee_decisions": false,
        "ministry_opinions": true
    }},
    "recommended_sources": ["law", "expc", "admrul"]
}}
"""

            response = client.chat.completions.create(
                model="gpt-5.1",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ í•œêµ­ ë²•ë¥  ê²€ìƒ‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•©ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_completion_tokens=800
            )

            result_text = response.choices[0].message.content.strip()
            logger.info(f"AI ì›ë³¸ ì‘ë‹µ: {result_text[:200]}")

            # JSON íŒŒì‹± ì‹œë„
            try:
                # JSON ë¸”ë¡ ì¶”ì¶œ
                if '```json' in result_text:
                    json_str = result_text.split('```json')[1].split('```')[0].strip()
                elif '```' in result_text:
                    json_str = result_text.split('```')[1].split('```')[0].strip()
                elif result_text.startswith('{'):
                    json_str = result_text
                else:
                    # JSON ì‹œì‘ ìœ„ì¹˜ ì°¾ê¸°
                    start_idx = result_text.find('{')
                    end_idx = result_text.rfind('}') + 1
                    if start_idx >= 0 and end_idx > start_idx:
                        json_str = result_text[start_idx:end_idx]
                    else:
                        raise ValueError("JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")

                result = json.loads(json_str)

                # í•„ìˆ˜ í•„ë“œ í™•ì¸ ë° ë³´ì •
                if 'search_queries' not in result or not result['search_queries']:
                    result['search_queries'] = result.get('keywords', basic_keywords)[:5]
                if 'keywords' not in result or not result['keywords']:
                    result['keywords'] = basic_keywords
                if 'legal_issues' not in result:
                    result['legal_issues'] = []
                if 'legal_concepts' not in result:
                    result['legal_concepts'] = []
                if 'core_question' not in result:
                    result['core_question'] = result.get('intent', '')
                if 'search_priority' not in result:
                    result['search_priority'] = default_result['search_priority']
                if 'recommended_sources' not in result:
                    result['recommended_sources'] = default_result['recommended_sources']

                logger.info(f"AI ì˜ë„ ë¶„ì„ ê²°ê³¼: intent={result.get('intent')}, core_question={result.get('core_question')}")
                logger.info(f"ê²€ìƒ‰ ì¿¼ë¦¬: {result.get('search_queries')}")
                return result

            except (json.JSONDecodeError, ValueError) as e:
                logger.warning(f"AI ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {e}, ì‘ë‹µ: {result_text[:200]}")
                return default_result

        except Exception as e:
            logger.error(f"AI ì˜ë„ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return default_result

    def verify_search_results(self, user_query: str, ai_analysis: Dict, results: List[Dict], category: str) -> List[Dict]:
        """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ê²°ê³¼ì˜ ê´€ë ¨ì„±ì„ ê²€ì¦í•˜ê³  í•„í„°ë§

        Args:
            user_query: ì›ë³¸ ì‚¬ìš©ì ì§ˆì˜
            ai_analysis: AI ì˜ë„ ë¶„ì„ ê²°ê³¼
            results: ê²€ìƒ‰ëœ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            category: ê²°ê³¼ ì¹´í…Œê³ ë¦¬ (prec, expc, decc ë“±)

        Returns:
            ê´€ë ¨ì„±ì´ ë†’ì€ ê²°ê³¼ë§Œ í•„í„°ë§ëœ ë¦¬ìŠ¤íŠ¸
        """
        if not results:
            return results

        client = get_openai_client()
        if not client:
            return results  # AI ì—†ìœ¼ë©´ ì›ë³¸ ë°˜í™˜

        # ê²°ê³¼ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ìƒìœ„ 20ê°œë§Œ ê²€ì¦
        results_to_verify = results[:20]

        # ê²°ê³¼ ìš”ì•½ ìƒì„±
        result_summaries = []
        for idx, item in enumerate(results_to_verify):
            title = item.get('ì‚¬ê±´ëª…') or item.get('ì œëª©') or item.get('íŒë¡€ëª…') or item.get('ì•ˆê±´ëª…') or ''
            case_no = item.get('ì‚¬ê±´ë²ˆí˜¸') or item.get('ì•ˆê±´ë²ˆí˜¸') or ''
            summary = f"{idx+1}. {title} ({case_no})"
            result_summaries.append(summary)

        results_text = "\n".join(result_summaries)

        try:
            prompt = f"""ë‹¹ì‹ ì€ ë²•ë¥  ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì‚¬ìš©ì ì§ˆì˜
{user_query}

## í•µì‹¬ ì§ˆë¬¸
{ai_analysis.get('core_question', ai_analysis.get('intent', ''))}

## í•µì‹¬ ë²•ì  ìŸì 
{', '.join(ai_analysis.get('legal_issues', []))}

## í•µì‹¬ ë²•ì  ê°œë…
{', '.join(ai_analysis.get('legal_concepts', []))}

## ê²€ìƒ‰ëœ {category} ê²°ê³¼
{results_text}

## ìš”ì²­
ìœ„ ê²€ìƒ‰ ê²°ê³¼ ì¤‘ì—ì„œ ì‚¬ìš©ì ì§ˆì˜ì˜ í•µì‹¬ ìŸì ê³¼ **ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨**ìˆëŠ” ê²°ê³¼ì˜ ë²ˆí˜¸ë§Œ ì„ íƒí•˜ì„¸ìš”.

ì‘ë‹µ í˜•ì‹ (JSONë§Œ):
{{"relevant_indices": [1, 3, 5], "reason": "ì„ íƒ ì´ìœ  í•œ ì¤„"}}

íŒë‹¨ ê¸°ì¤€:
1. ì œëª©/ì‚¬ê±´ëª…ì´ í•µì‹¬ ë²•ì  ìŸì ê³¼ ì§ì ‘ ê´€ë ¨ë˜ì–´ì•¼ í•¨
2. ë°°ê²½ ì„¤ëª…(ì´í˜¼, ì†Œì†¡ ë“±)ë§Œ ì¼ì¹˜í•˜ëŠ” ê²ƒì€ ê´€ë ¨ ì—†ìŒìœ¼ë¡œ ì²˜ë¦¬
3. ì˜ˆ: ì§ˆë¬¸ì´ "ë©´ì ‘êµì„­ê¶Œ"ì´ë©´ ì¬ì‚°ë¶„í• /ìœ„ìë£Œ íŒë¡€ëŠ” ê´€ë ¨ ì—†ìŒ
"""

            response = client.chat.completions.create(
                model="gpt-5.1",
                messages=[
                    {"role": "system", "content": "ë²•ë¥  ê²€ìƒ‰ ê²°ê³¼ ê´€ë ¨ì„± í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•©ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_completion_tokens=500
            )

            result_text = response.choices[0].message.content.strip()
            logger.info(f"AI ê²€ì¦ ê²°ê³¼: {result_text[:200]}")

            # JSON íŒŒì‹±
            try:
                if '{' in result_text:
                    start_idx = result_text.find('{')
                    end_idx = result_text.rfind('}') + 1
                    json_str = result_text[start_idx:end_idx]
                    verification = json.loads(json_str)

                    relevant_indices = verification.get('relevant_indices', [])
                    if relevant_indices:
                        # 1-indexedë¥¼ 0-indexedë¡œ ë³€í™˜
                        filtered_results = [
                            results_to_verify[i-1] for i in relevant_indices
                            if 1 <= i <= len(results_to_verify)
                        ]
                        logger.info(f"AI ê²€ì¦: {len(results_to_verify)}ê°œ ì¤‘ {len(filtered_results)}ê°œ ê´€ë ¨ ê²°ê³¼ ì„ íƒ")
                        logger.info(f"ì„ íƒ ì´ìœ : {verification.get('reason', '')}")
                        return filtered_results if filtered_results else results[:5]

            except (json.JSONDecodeError, ValueError, IndexError) as e:
                logger.warning(f"AI ê²€ì¦ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨: {e}")

        except Exception as e:
            logger.error(f"AI ê²€ìƒ‰ ê²°ê³¼ ê²€ì¦ ì˜¤ë¥˜: {e}")

        return results  # ì˜¤ë¥˜ ì‹œ ì›ë³¸ ë°˜í™˜

    async def _search_by_target(self, session, query: str, target: str,
                                display: int = 10) -> List[Dict]:
        """íŠ¹ì • targetìœ¼ë¡œ ê²€ìƒ‰"""
        # API í‚¤ ì¬í™•ì¸
        api_key = self.law_api_key or get_law_api_key()
        if not api_key:
            logger.warning(f"ë²•ì œì²˜ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. ({target} ê²€ìƒ‰ ë¶ˆê°€)")
            return []

        params = {
            'OC': api_key,
            'target': target,
            'query': query,
            'type': 'JSON',
            'display': display
        }

        try:
            async with session.get(
                self.api_endpoints['search'],
                params=params,
                timeout=aiohttp.ClientTimeout(total=30)
            ) as response:
                if response.status == 200:
                    text = await response.text()
                    try:
                        data = json.loads(text)
                        logger.info(f"[{target}] API ì‘ë‹µ í‚¤: {list(data.keys())}")

                        # ê²°ê³¼ ì¶”ì¶œ - ë‹¤ì–‘í•œ ì‘ë‹µ í˜•ì‹ ì²˜ë¦¬
                        results = []

                        # API ì‘ë‹µ êµ¬ì¡°: {'PrecSearch': {'prec': [...], 'í‚¤ì›Œë“œ': '...'}}
                        # ë˜ëŠ” {'Expc': {'expc': [...], ...}}

                        # 1. ìµœìƒìœ„ ë˜í¼ í‚¤ í™•ì¸ (PrecSearch, LawSearch, Expc, Decc ë“±)
                        wrapper_keys = [
                            f'{target.capitalize()}Search',  # PrecSearch, LawSearch
                            target.capitalize(),  # Prec, Expc, Decc
                            f'{target.upper()}Search',
                            target,
                            target.lower(),
                            target.upper(),
                        ]

                        inner_data = data
                        for wkey in wrapper_keys:
                            if wkey in data and isinstance(data[wkey], dict):
                                inner_data = data[wkey]
                                break
                            elif wkey in data and isinstance(data[wkey], list):
                                results = data[wkey]
                                break

                        # 2. inner_dataì—ì„œ ì‹¤ì œ ë°ì´í„° ë°°ì—´ ì¶”ì¶œ
                        if not results and isinstance(inner_data, dict):
                            # target ì´ë¦„ê³¼ ì¼ì¹˜í•˜ëŠ” í‚¤ì—ì„œ ë°°ì—´ ì°¾ê¸°
                            data_keys = [
                                target.lower(),  # prec, expc, decc
                                target,
                                target.capitalize(),
                            ]

                            for dkey in data_keys:
                                if dkey in inner_data:
                                    value = inner_data[dkey]
                                    if isinstance(value, list) and len(value) > 0:
                                        results = value
                                        break

                            # 3. ê·¸ë˜ë„ ì—†ìœ¼ë©´ inner_dataì—ì„œ ì²« ë²ˆì§¸ ë¦¬ìŠ¤íŠ¸ ì°¾ê¸°
                            if not results:
                                skip_keys = {'totalCnt', 'page', 'target', 'section', 'í‚¤ì›Œë“œ',
                                           'resultMsg', 'resultCode', 'numOfRows'}
                                for key, value in inner_data.items():
                                    if key not in skip_keys:
                                        if isinstance(value, list) and len(value) > 0:
                                            results = value
                                            break

                        logger.info(f"[{target}] ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê±´ (ì¿¼ë¦¬: {query})")
                        # ë””ë²„ê¹…: ì²« ë²ˆì§¸ ê²°ê³¼ì˜ êµ¬ì¡° ì¶œë ¥
                        if results and len(results) > 0:
                            first_item = results[0]
                            logger.info(f"[{target}] ì²« ë²ˆì§¸ ê²°ê³¼ í‚¤: {list(first_item.keys()) if isinstance(first_item, dict) else type(first_item)}")
                            logger.info(f"[{target}] ì²« ë²ˆì§¸ ê²°ê³¼ ë‚´ìš©: {str(first_item)[:500]}")
                        return results

                    except json.JSONDecodeError as e:
                        logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜ ({target}): {e}")
                        logger.error(f"ì‘ë‹µ ë‚´ìš©: {text[:500]}")
                        return []
                else:
                    logger.error(f"API ì‘ë‹µ ì˜¤ë¥˜ ({target}): ìƒíƒœì½”ë“œ {response.status}")
        except asyncio.TimeoutError:
            logger.error(f"API íƒ€ì„ì•„ì›ƒ ({target})")
        except Exception as e:
            logger.error(f"ê²€ìƒ‰ ì˜¤ë¥˜ ({target}): {e}")
        return []

    async def search_basic_legal_data(self, query: str, search_queries: List[str] = None) -> Dict:
        """ê¸°ë³¸ ë²•ë¥  ë°ì´í„° ê²€ìƒ‰ (ë²•ë ¹, íŒë¡€, í–‰ì •ê·œì¹™ ë“±) - AI ê²€ìƒ‰ì–´ ê¸°ë°˜"""
        # ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ ì„¤ì • (íŒë¡€, ìœ ê¶Œí•´ì„ ì¤‘ì‹¬ìœ¼ë¡œ ëŒ€í­ ì¦ê°€)
        display_counts = {
            'law': 30,        # í˜„í–‰ë²•ë ¹(ê³µí¬ì¼)
            'eflaw': 30,      # í˜„í–‰ë²•ë ¹(ì‹œí–‰ì¼)
            'prec': 50,       # íŒë¡€ - ìµœëŒ€í•œ ë§ì´
            'admrul': 20,     # í–‰ì •ê·œì¹™
            'ordin': 20,      # ìì¹˜ë²•ê·œ
            'detc': 30,       # í—Œì¬ê²°ì •ë¡€
            'expc': 50,       # ë²•ë ¹í•´ì„ë¡€ - ìµœëŒ€í•œ ë§ì´
            'decc': 50,       # í–‰ì •ì‹¬íŒë¡€ - ìµœëŒ€í•œ ë§ì´
            'trty': 10,       # ì¡°ì•½
        }

        all_results = {target: [] for target in self.basic_targets.keys()}

        # ë©”ì¸ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰
        async with aiohttp.ClientSession() as session:
            tasks = []
            for target_code in self.basic_targets.keys():
                display = display_counts.get(target_code, 20)
                tasks.append(self._search_by_target(session, query, target_code, display))

            results = await asyncio.gather(*tasks, return_exceptions=True)

            for idx, target_code in enumerate(self.basic_targets.keys()):
                if not isinstance(results[idx], Exception) and results[idx]:
                    all_results[target_code].extend(results[idx])

        # AIê°€ ìƒì„±í•œ ì¶”ê°€ ê²€ìƒ‰ì–´ë¡œ í™•ì¥ ê²€ìƒ‰ (íŒë¡€, ë²•ë ¹í•´ì„ë¡€, í–‰ì •ì‹¬íŒë¡€, ë²•ë ¹ ëŒ€ìƒ)
        if search_queries:
            important_targets = ['prec', 'expc', 'decc', 'detc', 'law', 'eflaw']
            for search_query in search_queries[:3]:  # ìƒìœ„ 3ê°œ ê²€ìƒ‰ì–´ë§Œ
                if search_query != query:  # ë©”ì¸ ì¿¼ë¦¬ì™€ ë‹¤ë¥¸ ê²½ìš°ë§Œ
                    async with aiohttp.ClientSession() as session:
                        tasks = []
                        for target_code in important_targets:
                            tasks.append(self._search_by_target(session, search_query, target_code, 20))

                        kw_results = await asyncio.gather(*tasks, return_exceptions=True)

                        for idx, target_code in enumerate(important_targets):
                            if not isinstance(kw_results[idx], Exception) and kw_results[idx]:
                                # ì¤‘ë³µ ì œê±°í•˜ë©° ì¶”ê°€
                                existing_ids = {item.get('íŒë¡€ì¼ë ¨ë²ˆí˜¸', item.get('ì•ˆê±´ë²ˆí˜¸', item.get('ì‚¬ê±´ë²ˆí˜¸', '')))
                                              for item in all_results[target_code]}
                                for item in kw_results[idx]:
                                    item_id = item.get('íŒë¡€ì¼ë ¨ë²ˆí˜¸', item.get('ì•ˆê±´ë²ˆí˜¸', item.get('ì‚¬ê±´ë²ˆí˜¸', '')))
                                    if item_id and item_id not in existing_ids:
                                        all_results[target_code].append(item)
                                        existing_ids.add(item_id)

        return all_results

    async def search_committee_decisions(self, query: str,
                                        selected_committees: List[str] = None) -> Dict:
        """ìœ„ì›íšŒ ê²°ì •ë¬¸ ê²€ìƒ‰"""
        if selected_committees is None:
            selected_committees = list(self.committee_targets.keys())

        async with aiohttp.ClientSession() as session:
            tasks = []
            for committee in selected_committees:
                if committee in self.committee_targets:
                    tasks.append(self._search_by_target(session, query, committee, 10))

            results = await asyncio.gather(*tasks, return_exceptions=True)

            valid_committees = [c for c in selected_committees if c in self.committee_targets]
            return {
                valid_committees[idx]: results[idx] if not isinstance(results[idx], Exception) else []
                for idx in range(len(valid_committees))
            }

    async def search_ministry_interpretations(self, query: str,
                                             selected_ministries: List[str] = None) -> Dict:
        """ë¶€ì²˜ë³„ ë²•ë ¹í•´ì„ ê²€ìƒ‰"""
        if selected_ministries is None:
            # ì£¼ìš” ë¶€ì²˜ë§Œ ê¸°ë³¸ ê²€ìƒ‰
            selected_ministries = [
                'moelCgmExpc', 'molitCgmExpc', 'moisCgmExpc',
                'mohwCgmExpc', 'molegCgmExpc'
            ]

        async with aiohttp.ClientSession() as session:
            tasks = []
            for ministry in selected_ministries:
                if ministry in self.ministry_targets:
                    tasks.append(self._search_by_target(session, query, ministry, 10))

            results = await asyncio.gather(*tasks, return_exceptions=True)

            valid_ministries = [m for m in selected_ministries if m in self.ministry_targets]
            return {
                valid_ministries[idx]: results[idx] if not isinstance(results[idx], Exception) else []
                for idx in range(len(valid_ministries))
            }

    async def search_special_tribunals(self, query: str) -> Dict:
        """íŠ¹ë³„í–‰ì •ì‹¬íŒë¡€ ê²€ìƒ‰"""
        async with aiohttp.ClientSession() as session:
            tasks = []
            for target_code in self.special_tribunal_targets.keys():
                tasks.append(self._search_by_target(session, query, target_code, 10))

            results = await asyncio.gather(*tasks, return_exceptions=True)

            return {
                target_code: results[idx] if not isinstance(results[idx], Exception) else []
                for idx, target_code in enumerate(self.special_tribunal_targets.keys())
            }

    async def comprehensive_search(self, query: str,
                                  search_options: Dict = None) -> Dict:
        """ì¢…í•© ë²•ë¥  ê²€ìƒ‰ - AI ì˜ë„ ë¶„ì„ ê¸°ë°˜ ê²€ìƒ‰ + ì‚¬ê±´ë²ˆí˜¸ ì§ì ‘ ê²€ìƒ‰

        AIê°€ ì‚¬ìš©ì ì§ˆì˜ë¥¼ ë¶„ì„í•˜ì—¬:
        1. ë²•ì  ìŸì  íŒŒì•…
        2. ê´€ë ¨ ë²•ë ¹, íŒë¡€, ìœ ê¶Œí•´ì„ ê²€ìƒ‰ì–´ ìƒì„±
        3. ìµœì ì˜ ê²€ìƒ‰ ì†ŒìŠ¤ ì¶”ì²œ

        ì‚¬ê±´ë²ˆí˜¸/ì•ˆê±´ë²ˆí˜¸ê°€ ê°ì§€ë˜ë©´ ì§ì ‘ ê²€ìƒ‰ë„ ìˆ˜í–‰
        """
        if search_options is None:
            search_options = {
                'basic': True,
                'committees': [],
                'ministries': [],
                'special_tribunals': True
            }

        # 1. ì‚¬ê±´ë²ˆí˜¸/ì•ˆê±´ë²ˆí˜¸ íŒ¨í„´ ê°ì§€
        case_info = self.detect_case_number(query)
        case_number_results = {}
        is_case_number_only = False  # ì‚¬ê±´ë²ˆí˜¸ë§Œ ì…ë ¥ëœ ê²½ìš° í”Œë˜ê·¸

        if case_info.get('type'):
            logger.info(f"=== ì‚¬ê±´ë²ˆí˜¸/ì•ˆê±´ë²ˆí˜¸ ê°ì§€ ===")
            logger.info(f"ìœ í˜•: {case_info['type']}, ë²ˆí˜¸: {case_info['case_numbers']}")
            # ì‚¬ê±´ë²ˆí˜¸ë¡œ ì§ì ‘ ê²€ìƒ‰
            case_number_results = await self.search_by_case_number(case_info)
            case_count = sum(len(v) for v in case_number_results.values())
            logger.info(f"ì‚¬ê±´ë²ˆí˜¸ ê²€ìƒ‰ ê²°ê³¼: {case_count}ê±´")

            # ì‚¬ê±´ë²ˆí˜¸ë§Œ ì…ë ¥ëœ ê²½ìš° íŒë‹¨ (ë‹¤ë¥¸ í‚¤ì›Œë“œê°€ ê±°ì˜ ì—†ëŠ” ê²½ìš°)
            # ì‚¬ê±´ë²ˆí˜¸ íŒ¨í„´ì„ ì œê±°í•œ í›„ ë‚¨ì€ í…ìŠ¤íŠ¸ê°€ ë²•ì›ëª… ë“±ë§Œ ìˆëŠ”ì§€ í™•ì¸
            remaining_text = query
            for case_no in case_info['case_numbers']:
                remaining_text = remaining_text.replace(case_no, '')
            # ë²•ì›ëª…, ê³µë°±, ê¸°íƒ€ ì§§ì€ í‚¤ì›Œë“œë§Œ ë‚¨ì€ ê²½ìš°
            court_names = ['ëŒ€ë²•ì›', 'ê³ ë“±ë²•ì›', 'ì§€ë°©ë²•ì›', 'í–‰ì •ë²•ì›', 'ê°€ì •ë²•ì›',
                          'ì„œìš¸', 'ë¶€ì‚°', 'ëŒ€êµ¬', 'ì¸ì²œ', 'ê´‘ì£¼', 'ëŒ€ì „', 'ìš¸ì‚°', 'ìˆ˜ì›', 'ì²­ì£¼']
            for court in court_names:
                remaining_text = remaining_text.replace(court, '')
            remaining_text = remaining_text.strip()
            # ë‚¨ì€ í…ìŠ¤íŠ¸ê°€ ê±°ì˜ ì—†ìœ¼ë©´ ì‚¬ê±´ë²ˆí˜¸ ì „ìš© ê²€ìƒ‰
            if len(remaining_text) <= 5:
                is_case_number_only = True
                logger.info("ì‚¬ê±´ë²ˆí˜¸ ì „ìš© ê²€ìƒ‰ ëª¨ë“œ í™œì„±í™”")

        # 2. AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆì˜ ì˜ë„ ë¶„ì„ ë° ê²€ìƒ‰ í‚¤ì›Œë“œ ìƒì„±
        # ì‚¬ê±´ë²ˆí˜¸ë§Œ ì…ë ¥ëœ ê²½ìš° AI ë¶„ì„ ìƒëµ
        if is_case_number_only:
            ai_analysis = {
                'intent': 'íŠ¹ì • ì‚¬ê±´ë²ˆí˜¸ ê²€ìƒ‰',
                'legal_issues': [],
                'law_names': [],
                'keywords': case_info.get('case_numbers', []),
                'search_queries': case_info.get('case_numbers', []),
                'search_priority': {'laws': False, 'precedents': True, 'interpretations': True,
                                   'committee_decisions': False, 'ministry_opinions': False},
                'recommended_sources': [case_info.get('type', 'prec')]
            }
            keywords = case_info.get('case_numbers', [])
            search_queries = []  # ì¼ë°˜ ê²€ìƒ‰ ì¿¼ë¦¬ëŠ” ë¹ˆ ë¦¬ìŠ¤íŠ¸
        else:
            ai_analysis = self.analyze_query_with_ai(query)
            keywords = ai_analysis.get('keywords', [])
            search_queries = ai_analysis.get('search_queries', [query])
        law_names = ai_analysis.get('law_names', [])
        legal_issues = ai_analysis.get('legal_issues', [])
        search_priority = ai_analysis.get('search_priority', {})
        recommended_sources = ai_analysis.get('recommended_sources', [])

        logger.info(f"=== AI ë²•ë¥  ê²€í†  ë¶„ì„ ê²°ê³¼ ===")
        logger.info(f"ì˜ë„: {ai_analysis.get('intent', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
        logger.info(f"ë²•ì  ìŸì : {legal_issues}")
        logger.info(f"ê´€ë ¨ ë²•ë ¹: {law_names}")
        logger.info(f"ê²€ìƒ‰ í‚¤ì›Œë“œ: {keywords}")
        logger.info(f"ìƒì„±ëœ ê²€ìƒ‰ ì¿¼ë¦¬: {search_queries}")
        logger.info(f"ì¶”ì²œ ê²€ìƒ‰ ì†ŒìŠ¤: {recommended_sources}")

        results = {
            'query': query,
            'keywords': keywords,
            'search_queries': search_queries,
            'ai_analysis': ai_analysis,
            'legal_issues': legal_issues,
            'law_names': law_names,
            'search_time': datetime.now().isoformat(),
            'case_info': case_info,  # ì‚¬ê±´ë²ˆí˜¸ ì •ë³´ ì¶”ê°€
            'is_case_number_only': is_case_number_only,  # ì‚¬ê±´ë²ˆí˜¸ ì „ìš© ê²€ìƒ‰ ì—¬ë¶€
            'basic': {},
            'committees': {},
            'ministries': {},
            'special_tribunals': {}
        }

        # ì‚¬ê±´ë²ˆí˜¸ ì „ìš© ê²€ìƒ‰ ëª¨ë“œì¼ ë•ŒëŠ” ì¼ë°˜ í‚¤ì›Œë“œ ê²€ìƒ‰ ê±´ë„ˆëœ€
        if not is_case_number_only:
            # AIê°€ ìƒì„±í•œ ê²€ìƒ‰ ì¿¼ë¦¬ ì‚¬ìš© (ì—†ìœ¼ë©´ ì›ë³¸ ì¿¼ë¦¬ ì‚¬ìš©)
            primary_query = search_queries[0] if search_queries else query
            # ì¶”ê°€ ê²€ìƒ‰ì–´ë„ í™œìš© (ìµœëŒ€ 3ê°œ)
            additional_queries = search_queries[1:4] if len(search_queries) > 1 else []

            tasks = []

            # ê¸°ë³¸ ë²•ë¥  ë°ì´í„° ê²€ìƒ‰ (AI ìƒì„± ê²€ìƒ‰ì–´ ê¸°ë°˜)
            if search_options.get('basic', True):
                tasks.append(('basic', self.search_basic_legal_data(primary_query, search_queries)))

            # ìœ„ì›íšŒ ê²°ì •ë¬¸ ê²€ìƒ‰ (AIê°€ ì¶”ì²œí•˜ê±°ë‚˜ ì‚¬ìš©ìê°€ ì„ íƒí•œ ê²½ìš°)
            committees = search_options.get('committees', [])
            if committees:
                tasks.append(('committees', self.search_committee_decisions(primary_query, committees)))

            # ë¶€ì²˜ë³„ ë²•ë ¹í•´ì„ ê²€ìƒ‰ (AIê°€ ì¶”ì²œí•˜ê±°ë‚˜ ì‚¬ìš©ìê°€ ì„ íƒí•œ ê²½ìš°)
            ministries = search_options.get('ministries', [])
            if ministries:
                tasks.append(('ministries', self.search_ministry_interpretations(primary_query, ministries)))

            # íŠ¹ë³„í–‰ì •ì‹¬íŒë¡€ ê²€ìƒ‰
            if search_options.get('special_tribunals', False):
                tasks.append(('special_tribunals', self.search_special_tribunals(primary_query)))

            # ë³‘ë ¬ ì‹¤í–‰
            for key, task in tasks:
                try:
                    results[key] = await task
                except Exception as e:
                    logger.error(f"ê²€ìƒ‰ ì˜¤ë¥˜ ({key}): {e}")
                    results[key] = {}
        else:
            logger.info("ì‚¬ê±´ë²ˆí˜¸ ì „ìš© ê²€ìƒ‰: ì¼ë°˜ í‚¤ì›Œë“œ ê²€ìƒ‰ ê±´ë„ˆëœ€")

        # ì‚¬ê±´ë²ˆí˜¸ ê²€ìƒ‰ ê²°ê³¼ë¥¼ basicì— ë³‘í•© (ì¤‘ë³µ ì œê±°)
        if case_number_results:
            for case_type, items in case_number_results.items():
                if items:
                    if case_type not in results['basic']:
                        results['basic'][case_type] = []
                    # ê¸°ì¡´ ê²°ê³¼ì™€ ë³‘í•© (ì‚¬ê±´ë²ˆí˜¸ ê²€ìƒ‰ ê²°ê³¼ ìš°ì„ )
                    existing_ids = set()
                    for item in results['basic'][case_type]:
                        item_id = item.get('íŒë¡€ì¼ë ¨ë²ˆí˜¸', item.get('ë²•ë ¹í•´ì„ë¡€ì¼ë ¨ë²ˆí˜¸',
                                  item.get('í–‰ì •ì‹¬íŒì¬ê²°ë¡€ì¼ë ¨ë²ˆí˜¸', '')))
                        if item_id:
                            existing_ids.add(str(item_id))

                    for item in items:
                        item_id = item.get('íŒë¡€ì¼ë ¨ë²ˆí˜¸', item.get('ë²•ë ¹í•´ì„ë¡€ì¼ë ¨ë²ˆí˜¸',
                                  item.get('í–‰ì •ì‹¬íŒì¬ê²°ë¡€ì¼ë ¨ë²ˆí˜¸', '')))
                        if not item_id or str(item_id) not in existing_ids:
                            results['basic'][case_type].insert(0, item)  # ì•ì— ì¶”ê°€
                            if item_id:
                                existing_ids.add(str(item_id))

                    logger.info(f"[{case_type}] ì‚¬ê±´ë²ˆí˜¸ ê²€ìƒ‰ ê²°ê³¼ {len(items)}ê±´ ë³‘í•© ì™„ë£Œ")

        # AIë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ê²°ê³¼ ê²€ì¦ ë° í•„í„°ë§
        logger.info("=== AI ê²€ìƒ‰ ê²°ê³¼ ê²€ì¦ ì‹œì‘ ===")

        # ê¸°ë³¸ ê²€ìƒ‰ ê²°ê³¼ ê²€ì¦ (íŒë¡€, ë²•ë ¹í•´ì„ë¡€, í–‰ì •ì‹¬íŒë¡€)
        if results.get('basic'):
            for category in ['prec', 'expc', 'decc', 'detc']:
                if results['basic'].get(category):
                    original_count = len(results['basic'][category])
                    results['basic'][category] = self.verify_search_results(
                        query, ai_analysis, results['basic'][category], category
                    )
                    filtered_count = len(results['basic'][category])
                    if original_count != filtered_count:
                        logger.info(f"[{category}] ê²€ì¦ ì™„ë£Œ: {original_count}ê±´ â†’ {filtered_count}ê±´")

        # ìœ„ì›íšŒ ê²°ì •ë¬¸ ê²€ì¦
        if results.get('committees'):
            for comm_key, comm_results in results['committees'].items():
                if comm_results:
                    original_count = len(comm_results)
                    results['committees'][comm_key] = self.verify_search_results(
                        query, ai_analysis, comm_results, f"ìœ„ì›íšŒê²°ì •ë¬¸({comm_key})"
                    )
                    filtered_count = len(results['committees'][comm_key])
                    if original_count != filtered_count:
                        logger.info(f"[{comm_key}] ê²€ì¦ ì™„ë£Œ: {original_count}ê±´ â†’ {filtered_count}ê±´")

        # ë¶€ì²˜ë³„ ë²•ë ¹í•´ì„ ê²€ì¦
        if results.get('ministries'):
            for ministry_key, ministry_results in results['ministries'].items():
                if ministry_results:
                    original_count = len(ministry_results)
                    results['ministries'][ministry_key] = self.verify_search_results(
                        query, ai_analysis, ministry_results, f"ë¶€ì²˜ë²•ë ¹í•´ì„({ministry_key})"
                    )
                    filtered_count = len(results['ministries'][ministry_key])
                    if original_count != filtered_count:
                        logger.info(f"[{ministry_key}] ê²€ì¦ ì™„ë£Œ: {original_count}ê±´ â†’ {filtered_count}ê±´")

        logger.info("=== AI ê²€ìƒ‰ ê²°ê³¼ ê²€ì¦ ì™„ë£Œ ===")

        return results

    async def get_detail(self, target: str, item_id: str) -> Dict:
        """ìƒì„¸ ì •ë³´ ì¡°íšŒ"""
        params = {
            'OC': self.law_api_key,
            'target': target,
            'ID': item_id,
            'type': 'JSON'
        }

        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    self.api_endpoints['service'],
                    params=params,
                    timeout=aiohttp.ClientTimeout(total=15)
                ) as response:
                    if response.status == 200:
                        return await response.json()
        except Exception as e:
            logger.error(f"ìƒì„¸ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return {}

    def format_document_as_markdown(self, detail_data: Dict, target: str) -> str:
        """ìƒì„¸ ì •ë³´ë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        if not detail_data:
            return ""

        # ì‘ë‹µ ë°ì´í„° íŒŒì‹± (ì¤‘ì²© êµ¬ì¡° ì²˜ë¦¬)
        data = detail_data
        if isinstance(detail_data, dict):
            # JSON ì‘ë‹µ êµ¬ì¡°ì— ë”°ë¼ ë°ì´í„° ì¶”ì¶œ
            for key in ['prec', 'expc', 'decc', 'detc', 'PrecService', 'ExpcService', 'DeccService', 'DetcService']:
                if key in detail_data:
                    data = detail_data[key]
                    break

        md_content = []

        if target == 'prec':  # íŒë¡€
            title = self._get_value(data, 'ì‚¬ê±´ëª…', 'caseName', 'ì œëª©')
            case_no = self._get_value(data, 'ì‚¬ê±´ë²ˆí˜¸', 'caseNo')
            court = self._get_value(data, 'ë²•ì›ëª…', 'courtName')
            date = self._get_value(data, 'ì„ ê³ ì¼ì', 'judgmentDate')
            case_type = self._get_value(data, 'ì‚¬ê±´ì¢…ë¥˜ëª…', 'caseTypeName')
            verdict_type = self._get_value(data, 'íŒê²°ìœ í˜•', 'verdictType')

            md_content.append(f"# {title or 'íŒë¡€'}")
            md_content.append("")
            md_content.append("## ê¸°ë³¸ ì •ë³´")
            md_content.append(f"- **ì‚¬ê±´ë²ˆí˜¸**: {case_no or '-'}")
            md_content.append(f"- **ë²•ì›**: {court or '-'}")
            md_content.append(f"- **ì„ ê³ ì¼ì**: {date or '-'}")
            md_content.append(f"- **ì‚¬ê±´ì¢…ë¥˜**: {case_type or '-'}")
            md_content.append(f"- **íŒê²°ìœ í˜•**: {verdict_type or '-'}")
            md_content.append("")

            # íŒì‹œì‚¬í•­
            summary = self._get_value(data, 'íŒì‹œì‚¬í•­', 'judgmentSummary')
            if summary:
                md_content.append("## íŒì‹œì‚¬í•­")
                md_content.append(self._clean_html(summary))
                md_content.append("")

            # íŒê²°ìš”ì§€
            gist = self._get_value(data, 'íŒê²°ìš”ì§€', 'judgmentGist')
            if gist:
                md_content.append("## íŒê²°ìš”ì§€")
                md_content.append(self._clean_html(gist))
                md_content.append("")

            # ì°¸ì¡°ì¡°ë¬¸
            ref_law = self._get_value(data, 'ì°¸ì¡°ì¡°ë¬¸', 'referenceLaw')
            if ref_law:
                md_content.append("## ì°¸ì¡°ì¡°ë¬¸")
                md_content.append(self._clean_html(ref_law))
                md_content.append("")

            # ì°¸ì¡°íŒë¡€
            ref_prec = self._get_value(data, 'ì°¸ì¡°íŒë¡€', 'referencePrec')
            if ref_prec:
                md_content.append("## ì°¸ì¡°íŒë¡€")
                md_content.append(self._clean_html(ref_prec))
                md_content.append("")

            # íŒë¡€ë‚´ìš© (ë³¸ë¬¸)
            content = self._get_value(data, 'íŒë¡€ë‚´ìš©', 'judgmentContent', 'content')
            if content:
                md_content.append("## íŒë¡€ ë³¸ë¬¸")
                md_content.append(self._clean_html(content))
                md_content.append("")

        elif target == 'expc':  # ë²•ë ¹í•´ì„ë¡€
            title = self._get_value(data, 'ì•ˆê±´ëª…', 'title', 'ì œëª©')
            case_no = self._get_value(data, 'ì•ˆê±´ë²ˆí˜¸', 'caseNo')
            org = self._get_value(data, 'í•´ì„ê¸°ê´€ëª…', 'íšŒì‹ ê¸°ê´€ëª…', 'replyOrg')
            date = self._get_value(data, 'í•´ì„ì¼ì', 'íšŒì‹ ì¼ì', 'replyDate')
            query_org = self._get_value(data, 'ì§ˆì˜ê¸°ê´€ëª…', 'queryOrg')

            md_content.append(f"# {title or 'ë²•ë ¹í•´ì„ë¡€'}")
            md_content.append("")
            md_content.append("## ê¸°ë³¸ ì •ë³´")
            md_content.append(f"- **ì•ˆê±´ë²ˆí˜¸**: {case_no or '-'}")
            md_content.append(f"- **í•´ì„ê¸°ê´€**: {org or '-'}")
            md_content.append(f"- **ì§ˆì˜ê¸°ê´€**: {query_org or '-'}")
            md_content.append(f"- **í•´ì„ì¼ì**: {date or '-'}")
            md_content.append("")

            # ì§ˆì˜ìš”ì§€
            query = self._get_value(data, 'ì§ˆì˜ìš”ì§€', 'queryGist')
            if query:
                md_content.append("## ì§ˆì˜ìš”ì§€")
                md_content.append(self._clean_html(query))
                md_content.append("")

            # íšŒë‹µ
            answer = self._get_value(data, 'íšŒë‹µ', 'answer')
            if answer:
                md_content.append("## íšŒë‹µ")
                md_content.append(self._clean_html(answer))
                md_content.append("")

            # ì´ìœ 
            reason = self._get_value(data, 'ì´ìœ ', 'reason')
            if reason:
                md_content.append("## ì´ìœ ")
                md_content.append(self._clean_html(reason))
                md_content.append("")

        elif target == 'decc':  # í–‰ì •ì‹¬íŒë¡€
            title = self._get_value(data, 'ì‚¬ê±´ëª…', 'caseName', 'ì œëª©')
            case_no = self._get_value(data, 'ì‚¬ê±´ë²ˆí˜¸', 'caseNo')
            ruling_type = self._get_value(data, 'ì¬ê²°ë¡€ìœ í˜•ëª…', 'rulingType')
            ruling_date = self._get_value(data, 'ì˜ê²°ì¼ì', 'decisionDate')
            disp_date = self._get_value(data, 'ì²˜ë¶„ì¼ì', 'dispositionDate')
            disp_org = self._get_value(data, 'ì²˜ë¶„ì²­', 'dispositionOrg')
            ruling_org = self._get_value(data, 'ì¬ê²°ì²­', 'rulingOrg')

            md_content.append(f"# {title or 'í–‰ì •ì‹¬íŒë¡€'}")
            md_content.append("")
            md_content.append("## ê¸°ë³¸ ì •ë³´")
            md_content.append(f"- **ì‚¬ê±´ë²ˆí˜¸**: {case_no or '-'}")
            md_content.append(f"- **ì¬ê²°ìœ í˜•**: {ruling_type or '-'}")
            md_content.append(f"- **ì˜ê²°ì¼ì**: {ruling_date or '-'}")
            md_content.append(f"- **ì²˜ë¶„ì¼ì**: {disp_date or '-'}")
            md_content.append(f"- **ì²˜ë¶„ì²­**: {disp_org or '-'}")
            md_content.append(f"- **ì¬ê²°ì²­**: {ruling_org or '-'}")
            md_content.append("")

            # ì£¼ë¬¸
            order = self._get_value(data, 'ì£¼ë¬¸', 'mainText')
            if order:
                md_content.append("## ì£¼ë¬¸")
                md_content.append(self._clean_html(order))
                md_content.append("")

            # ì²­êµ¬ì·¨ì§€
            purpose = self._get_value(data, 'ì²­êµ¬ì·¨ì§€', 'claimPurpose')
            if purpose:
                md_content.append("## ì²­êµ¬ì·¨ì§€")
                md_content.append(self._clean_html(purpose))
                md_content.append("")

            # ì´ìœ 
            reason = self._get_value(data, 'ì´ìœ ', 'reason')
            if reason:
                md_content.append("## ì´ìœ ")
                md_content.append(self._clean_html(reason))
                md_content.append("")

            # ì¬ê²°ìš”ì§€
            gist = self._get_value(data, 'ì¬ê²°ìš”ì§€', 'rulingGist')
            if gist:
                md_content.append("## ì¬ê²°ìš”ì§€")
                md_content.append(self._clean_html(gist))
                md_content.append("")

        elif target == 'detc':  # í—Œì¬ê²°ì •ë¡€
            title = self._get_value(data, 'ì‚¬ê±´ëª…', 'caseName', 'ê²°ì •ëª…', 'ì œëª©')
            case_no = self._get_value(data, 'ì‚¬ê±´ë²ˆí˜¸', 'caseNo')
            date = self._get_value(data, 'ì¢…êµ­ì¼ì', 'ì„ ê³ ì¼ì', 'decisionDate')
            result = self._get_value(data, 'ê²°ì •ìœ í˜•', 'ì¢…êµ­ê²°ê³¼', 'decisionType')

            md_content.append(f"# {title or 'í—Œì¬ê²°ì •ë¡€'}")
            md_content.append("")
            md_content.append("## ê¸°ë³¸ ì •ë³´")
            md_content.append(f"- **ì‚¬ê±´ë²ˆí˜¸**: {case_no or '-'}")
            md_content.append(f"- **ì¢…êµ­ì¼ì**: {date or '-'}")
            md_content.append(f"- **ê²°ì •ìœ í˜•**: {result or '-'}")
            md_content.append("")

            # íŒì‹œì‚¬í•­
            summary = self._get_value(data, 'íŒì‹œì‚¬í•­', 'judgmentSummary')
            if summary:
                md_content.append("## íŒì‹œì‚¬í•­")
                md_content.append(self._clean_html(summary))
                md_content.append("")

            # ê²°ì •ìš”ì§€
            gist = self._get_value(data, 'ê²°ì •ìš”ì§€', 'decisionGist')
            if gist:
                md_content.append("## ê²°ì •ìš”ì§€")
                md_content.append(self._clean_html(gist))
                md_content.append("")

            # ë³¸ë¬¸
            content = self._get_value(data, 'ê²°ì •ë‚´ìš©', 'ë³¸ë¬¸', 'content')
            if content:
                md_content.append("## ê²°ì • ë³¸ë¬¸")
                md_content.append(self._clean_html(content))
                md_content.append("")
        else:
            # ê¸°íƒ€ ë¬¸ì„œ ìœ í˜• (ìœ„ì›íšŒ ê²°ì •ë¬¸ ë“±)
            title = self._get_value(data, 'ì‚¬ê±´ëª…', 'ì•ˆê±´ëª…', 'caseName', 'title', 'ì œëª©')
            md_content.append(f"# {title or 'ë²•ë¥  ë¬¸ì„œ'}")
            md_content.append("")

            # ëª¨ë“  í•„ë“œë¥¼ ìˆœíšŒí•˜ë©° ì¶œë ¥
            for key, value in data.items():
                if value and isinstance(value, str) and len(value) > 0:
                    md_content.append(f"## {key}")
                    md_content.append(self._clean_html(str(value)))
                    md_content.append("")

        return "\n".join(md_content)

    def _clean_html(self, text: str) -> str:
        """HTML íƒœê·¸ ì œê±° ë° í…ìŠ¤íŠ¸ ì •ë¦¬"""
        if not text:
            return ""
        # HTML íƒœê·¸ ì œê±°
        import re
        text = re.sub(r'<br\s*/?>', '\n', text, flags=re.IGNORECASE)
        text = re.sub(r'<p\s*/?>', '\n', text, flags=re.IGNORECASE)
        text = re.sub(r'</p>', '\n', text, flags=re.IGNORECASE)
        text = re.sub(r'<[^>]+>', '', text)
        # HTML ì—”í‹°í‹° ë³€í™˜
        text = text.replace('&nbsp;', ' ')
        text = text.replace('&lt;', '<')
        text = text.replace('&gt;', '>')
        text = text.replace('&amp;', '&')
        text = text.replace('&quot;', '"')
        # ì—°ì†ëœ ê³µë°±/ì¤„ë°”ê¿ˆ ì •ë¦¬
        text = re.sub(r'\n\s*\n', '\n\n', text)
        text = re.sub(r' +', ' ', text)
        return text.strip()

    def generate_pdf_content(self, markdown_content: str, title: str = "ë²•ë¥  ë¬¸ì„œ") -> bytes:
        """ë§ˆí¬ë‹¤ìš´ ë‚´ìš©ì„ PDFë¡œ ë³€í™˜"""
        if not REPORTLAB_AVAILABLE:
            logger.warning("reportlab ëª¨ë“ˆì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. PDF ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return b""

        buffer = io.BytesIO()

        # PDF ë¬¸ì„œ ìƒì„±
        doc = SimpleDocTemplate(
            buffer,
            pagesize=A4,
            rightMargin=20*mm,
            leftMargin=20*mm,
            topMargin=20*mm,
            bottomMargin=20*mm
        )

        # í•œê¸€ í°íŠ¸ ì„¤ì • ì‹œë„
        font_name = 'Helvetica'  # ê¸°ë³¸ í°íŠ¸
        try:
            # ì‹œìŠ¤í…œ í•œê¸€ í°íŠ¸ ê²½ë¡œ ì‹œë„
            font_paths = [
                '/usr/share/fonts/truetype/nanum/NanumGothic.ttf',
                '/usr/share/fonts/nanum/NanumGothic.ttf',
                '/System/Library/Fonts/AppleSDGothicNeo.ttc',
                'C:/Windows/Fonts/malgun.ttf',
                '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf'
            ]
            for font_path in font_paths:
                if os.path.exists(font_path):
                    pdfmetrics.registerFont(TTFont('KoreanFont', font_path))
                    font_name = 'KoreanFont'
                    break
        except Exception as e:
            logger.warning(f"í•œê¸€ í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}, ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©")

        # ìŠ¤íƒ€ì¼ ì„¤ì •
        styles = getSampleStyleSheet()

        # ì œëª© ìŠ¤íƒ€ì¼
        title_style = ParagraphStyle(
            'CustomTitle',
            parent=styles['Heading1'],
            fontName=font_name,
            fontSize=16,
            spaceAfter=12,
            leading=20
        )

        # ì„¹ì…˜ í—¤ë” ìŠ¤íƒ€ì¼
        heading_style = ParagraphStyle(
            'CustomHeading',
            parent=styles['Heading2'],
            fontName=font_name,
            fontSize=12,
            spaceBefore=12,
            spaceAfter=6,
            leading=16
        )

        # ë³¸ë¬¸ ìŠ¤íƒ€ì¼
        body_style = ParagraphStyle(
            'CustomBody',
            parent=styles['Normal'],
            fontName=font_name,
            fontSize=10,
            leading=14,
            spaceAfter=8
        )

        # ì»¨í…ì¸  ë¹Œë“œ
        story = []

        lines = markdown_content.split('\n')
        for line in lines:
            line = line.strip()
            if not line:
                story.append(Spacer(1, 6))
            elif line.startswith('# '):
                story.append(Paragraph(line[2:], title_style))
            elif line.startswith('## '):
                story.append(Paragraph(line[3:], heading_style))
            elif line.startswith('- **'):
                # ë¦¬ìŠ¤íŠ¸ í•­ëª©
                story.append(Paragraph('â€¢ ' + line[2:], body_style))
            else:
                # ì¼ë°˜ í…ìŠ¤íŠ¸
                # XML íŠ¹ìˆ˜ë¬¸ì ì´ìŠ¤ì¼€ì´í”„
                escaped = line.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
                try:
                    story.append(Paragraph(escaped, body_style))
                except Exception:
                    # íŒŒì‹± ì˜¤ë¥˜ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ ì‚¬ìš©
                    story.append(Paragraph(line, body_style))

        try:
            doc.build(story)
        except Exception as e:
            logger.error(f"PDF ìƒì„± ì˜¤ë¥˜: {e}")
            return b""

        return buffer.getvalue()

    async def get_documents_for_download(self, items: List[Dict], target: str) -> List[Dict]:
        """ì—¬ëŸ¬ ë¬¸ì„œì˜ ìƒì„¸ ì •ë³´ë¥¼ ê°€ì ¸ì™€ì„œ ë‹¤ìš´ë¡œë“œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        results = []

        for item in items:
            # ID ì¶”ì¶œ
            item_id = None
            id_fields = ['íŒë¡€ì¼ë ¨ë²ˆí˜¸', 'ë²•ë ¹í•´ì„ë¡€ì¼ë ¨ë²ˆí˜¸', 'í–‰ì •ì‹¬íŒë¡€ì¼ë ¨ë²ˆí˜¸',
                        'í—Œì¬ê²°ì •ë¡€ì¼ë ¨ë²ˆí˜¸', 'ID', 'id', 'ì¼ë ¨ë²ˆí˜¸']
            for field in id_fields:
                if field in item:
                    item_id = str(item[field])
                    break

            if not item_id:
                continue

            # ìƒì„¸ ì •ë³´ ì¡°íšŒ
            detail = await self.get_detail(target, item_id)
            if detail:
                md_content = self.format_document_as_markdown(detail, target)

                # ì œëª© ì¶”ì¶œ
                title = self._get_item_display(item, 'ì‚¬ê±´ëª…', 'ì•ˆê±´ëª…', 'ì œëª©', 'caseName', 'title')
                case_no = self._get_value(item, 'ì‚¬ê±´ë²ˆí˜¸', 'ì•ˆê±´ë²ˆí˜¸', 'caseNo')

                results.append({
                    'id': item_id,
                    'title': title or f"{target}_{item_id}",
                    'case_no': case_no or '',
                    'target': target,
                    'markdown': md_content,
                    'detail': detail
                })

        return results

    def merge_documents_as_markdown(self, documents: List[Dict]) -> str:
        """ì—¬ëŸ¬ ë¬¸ì„œë¥¼ í•˜ë‚˜ì˜ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³‘í•©"""
        merged = []
        merged.append("# ë²•ë¥  ë¬¸ì„œ ëª¨ìŒ")
        merged.append(f"\nìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        merged.append(f"\në¬¸ì„œ ìˆ˜: {len(documents)}ê±´")
        merged.append("\n---\n")

        for idx, doc in enumerate(documents, 1):
            merged.append(f"\n## ë¬¸ì„œ {idx}: {doc.get('title', 'ì œëª© ì—†ìŒ')}")
            merged.append(f"ì‚¬ê±´ë²ˆí˜¸: {doc.get('case_no', '-')}")
            merged.append("\n---\n")
            merged.append(doc.get('markdown', ''))
            merged.append("\n\n---\n")

        return "\n".join(merged)

    def create_fact_sheet(self, user_input: str, legal_data: Dict) -> Dict:
        """ì‚¬ì‹¤ê´€ê³„ ì •ë¦¬"""
        fact_sheet = {
            'query': user_input,
            'timestamp': datetime.now().isoformat(),
            'statistics': {},
            'key_facts': self._extract_key_facts(user_input),
            'timeline': self._extract_timeline(user_input)
        }

        # ê¸°ë³¸ ë°ì´í„° í†µê³„
        if legal_data.get('basic'):
            for key, items in legal_data['basic'].items():
                if items:
                    fact_sheet['statistics'][key] = len(items)

        # ìœ„ì›íšŒ ë°ì´í„° í†µê³„
        if legal_data.get('committees'):
            for key, items in legal_data['committees'].items():
                if items:
                    fact_sheet['statistics'][f'committee_{key}'] = len(items)

        # ë¶€ì²˜ ë°ì´í„° í†µê³„
        if legal_data.get('ministries'):
            for key, items in legal_data['ministries'].items():
                if items:
                    fact_sheet['statistics'][f'ministry_{key}'] = len(items)

        # íŠ¹ë³„í–‰ì •ì‹¬íŒ í†µê³„
        if legal_data.get('special_tribunals'):
            for key, items in legal_data['special_tribunals'].items():
                if items:
                    fact_sheet['statistics'][f'tribunal_{key}'] = len(items)

        return fact_sheet

    def _extract_key_facts(self, text: str) -> List[str]:
        """í•µì‹¬ ì‚¬ì‹¤ ì¶”ì¶œ"""
        facts = []

        # ë‚ ì§œ íŒ¨í„´
        date_pattern = r'\d{4}[ë…„\.\-]\d{1,2}[ì›”\.\-]\d{1,2}[ì¼]?'
        dates = re.findall(date_pattern, text)
        for date in dates:
            facts.append(f"ê´€ë ¨ ì¼ì: {date}")

        # ê¸ˆì•¡ íŒ¨í„´
        money_pattern = r'\d+[ë§Œì²œë°±]?\s?ì›'
        amounts = re.findall(money_pattern, text)
        for amount in amounts:
            facts.append(f"ê´€ë ¨ ê¸ˆì•¡: {amount}")

        return facts

    def _extract_timeline(self, text: str) -> List[Dict]:
        """íƒ€ì„ë¼ì¸ ì¶”ì¶œ"""
        timeline = []
        date_pattern = r'(\d{4}[ë…„\.\-]\d{1,2}[ì›”\.\-]\d{1,2}[ì¼]?)'

        sentences = text.split('.')
        for sentence in sentences:
            dates = re.findall(date_pattern, sentence)
            if dates:
                for date in dates:
                    timeline.append({
                        'date': date,
                        'event': sentence.strip()
                    })

        return sorted(timeline, key=lambda x: x['date'])

    # API í•„ë“œëª… ë§¤í•‘ (camelCase -> í•œê¸€)
    FIELD_MAPPING = {
        'evtNm': 'ì‚¬ê±´ëª…',
        'itmNm': 'ì•ˆê±´ëª…',
        'caseNm': 'ì‚¬ê±´ëª…',
        'caseName': 'ì‚¬ê±´ëª…',
        'caseNo': 'ì‚¬ê±´ë²ˆí˜¸',
        'caseNumber': 'ì‚¬ê±´ë²ˆí˜¸',
        'courtNm': 'ë²•ì›ëª…',
        'courtName': 'ë²•ì›ëª…',
        'judgeDate': 'ì„ ê³ ì¼ì',
        'judgmentDate': 'ì„ ê³ ì¼ì',
        'decisionDate': 'ì˜ê²°ì¼ì',
        'replyDate': 'íšŒì‹ ì¼ì',
        'replyOrg': 'íšŒì‹ ê¸°ê´€',
        'lawNm': 'ë²•ë ¹ëª…',
        'lawName': 'ë²•ë ¹ëª…',
    }

    # ì œì™¸í•  ê°’ë“¤ (ë©”íƒ€ë°ì´í„°, ìƒíƒœê°’, í•„ë“œëª… ë“±)
    SKIP_VALUES = {
        # ìƒíƒœê°’
        'success', 'true', 'false', 'null', 'none', 'error', 'ok',
        # ìˆ«ì
        '00', '0', '1', '2', '3', '4', '5',
        # camelCase í•„ë“œëª…ë“¤
        'evtnm', 'itmnm', 'casenm', 'caseno', 'courtnm', 'lawNm', 'lawnm',
        'casename', 'casenumber', 'courtname', 'judgmentdate', 'decisiondate',
        'replydate', 'replyorg', 'lawname', 'enforcementdate', 'promulgationdate',
        # API ë©”íƒ€ë°ì´í„° í‚¤
        'target', 'type', 'page', 'totalcnt', 'section', 'display', 'sort',
        'query', 'search', 'keyword', 'q',
        # ê¸°íƒ€
        'prec', 'expc', 'decc', 'detc', 'law', 'eflaw', 'admrul', 'ordin', 'trty'
    }

    def _is_valid_value(self, value, query: str = '', exclude_urls: bool = True) -> bool:
        """ìœ íš¨í•œ ë°ì´í„° ê°’ì¸ì§€ í™•ì¸

        Args:
            value: ê²€ì‚¬í•  ê°’
            query: í˜„ì¬ ê²€ìƒ‰ì–´ (ì¤‘ë³µ ì œì™¸ìš©)
            exclude_urls: URL í˜•ì‹ ê°’ ì œì™¸ ì—¬ë¶€ (ê¸°ë³¸: True)
        """
        if not value:
            return False

        val_str = str(value).strip()

        # ë¹ˆ ê°’ ì²´í¬
        if not val_str:
            return False

        val_lower = val_str.lower()

        # SKIP_VALUES ì²´í¬
        if val_lower in self.SKIP_VALUES:
            return False

        # URL í˜•ì‹ ê°’ ì œì™¸ (ìƒì„¸ë§í¬ ë“±)
        if exclude_urls:
            # ë²•ì œì²˜ API ìƒì„¸ë§í¬ íŒ¨í„´: /DRF/lawService.do?... í˜•ì‹
            if val_str.startswith('/DRF/') or val_str.startswith('http'):
                return False
            # lawService.do, lawSearch.do ë“± API ì—”ë“œí¬ì¸íŠ¸ íŒ¨í„´
            if 'lawService.do' in val_str or 'lawSearch.do' in val_str:
                return False
            # URL íŒŒë¼ë¯¸í„° íŒ¨í„´: OC=, target=, ID= ë“±ì´ í¬í•¨ëœ ê²½ìš°
            if re.search(r'[?&](OC|target|ID|type)=', val_str):
                return False

        # ê²€ìƒ‰ì–´ì™€ ë™ì¼í•œ ê°’ì€ ì œì™¸ (ì—ì½”ëœ ê²€ìƒ‰ì–´)
        if query:
            query_lower = query.strip().lower()
            if val_lower == query_lower:
                return False
            # ê²€ìƒ‰ì–´ê°€ ê°’ì— í¬í•¨ëœ ê²½ìš°ë„ ì œì™¸ (ë¶€ë¶„ ì¼ì¹˜)
            if len(query_lower) > 5 and query_lower in val_lower and len(val_str) < len(query) + 10:
                return False

        # camelCase íŒ¨í„´ ê°ì§€ (ì†Œë¬¸ì+ëŒ€ë¬¸ì ì—°ì†)
        if re.match(r'^[a-z]+[A-Z][a-z]+$', val_str):
            return False

        # ë„ˆë¬´ ì§§ì€ ê°’ ì œì™¸ (1-2ì ìˆ«ì)
        if len(val_str) <= 2 and val_str.isdigit():
            return False

        # ì˜ë¬¸ ì†Œë¬¸ìë¡œë§Œ ëœ ì§§ì€ ê°’ ì œì™¸ (í•„ë“œëª…ì¼ ê°€ëŠ¥ì„±)
        if len(val_str) <= 10 and val_str.isalpha() and val_str.islower():
            return False

        return True

    def _get_value(self, item: Dict, *keys, default='', query: str = '') -> str:
        """ì—¬ëŸ¬ ê°€ëŠ¥í•œ í‚¤ì—ì„œ ê°’ì„ ì°¾ëŠ” í—¬í¼ í•¨ìˆ˜"""
        if not isinstance(item, dict):
            if item and self._is_valid_value(item, query):
                return str(item)
            return default

        # 1. ì§€ì •ëœ í‚¤ì—ì„œ ì°¾ê¸° (ë§¤í•‘ëœ í‚¤ í¬í•¨)
        all_keys = list(keys)
        for key in keys:
            if key in self.FIELD_MAPPING:
                all_keys.append(self.FIELD_MAPPING[key])
            # ì—­ë§¤í•‘ë„ í™•ì¸
            for eng, kor in self.FIELD_MAPPING.items():
                if key == kor:
                    all_keys.append(eng)

        for key in all_keys:
            if key in item:
                val = item[key]
                if self._is_valid_value(val, query):
                    return str(val)

        # 2. í‚¤ ì´ë¦„ì— í¬í•¨ëœ ë‹¨ì–´ë¡œ ì°¾ê¸° (ë¶€ë¶„ ì¼ì¹˜)
        search_terms = ['ëª…', 'ë²ˆí˜¸', 'ì¼ì', 'Nm', 'No', 'Date', 'Name', 'Title']
        for key, value in item.items():
            if self._is_valid_value(value, query):
                for term in search_terms:
                    if term in key:
                        return str(value)

        return default

    def _get_item_display(self, item: Dict, *preferred_keys, query: str = '') -> str:
        """ì•„ì´í…œ í‘œì‹œìš© ë¬¸ìì—´ ë°˜í™˜ - ì•ˆê±´ëª…/ì‚¬ê±´ëª… ìš°ì„ , URL ì œì™¸"""
        if not isinstance(item, dict):
            if item and self._is_valid_value(item, query):
                return str(item)
            return '(ì •ë³´ ì—†ìŒ)'

        # 1. ìš°ì„  í‚¤ì—ì„œ ì°¾ê¸° (ì•ˆê±´ëª…, ì‚¬ê±´ëª…, ì œëª© ë“±)
        all_keys = list(preferred_keys)
        for key in preferred_keys:
            if key in self.FIELD_MAPPING:
                all_keys.append(self.FIELD_MAPPING[key])
            for eng, kor in self.FIELD_MAPPING.items():
                if key == kor:
                    all_keys.append(eng)

        for key in all_keys:
            if key in item:
                val = item[key]
                if self._is_valid_value(val, query):
                    return str(val)

        # 2. ëª…ì¹­/ì´ë¦„ ê´€ë ¨ í‚¤ ì¶”ê°€ íƒìƒ‰
        name_keys = ['ì•ˆê±´ëª…', 'ì‚¬ê±´ëª…', 'ì œëª©', 'íŒë¡€ëª…', 'ê²°ì •ëª…', 'ì¬ê²°ë¡€ëª…',
                     'ë²•ë ¹ëª…', 'ë²•ë ¹ëª…í•œê¸€', 'í–‰ì •ê·œì¹™ëª…', 'ìì¹˜ë²•ê·œëª…', 'ì¡°ì•½ëª…',
                     'caseName', 'title', 'lawName', 'evtNm', 'itmNm', 'caseNm']
        for key in name_keys:
            if key in item and key not in all_keys:
                val = item[key]
                if self._is_valid_value(val, query):
                    return str(val)

        # 3. ìœ íš¨í•œ ê°’ë“¤ ìˆ˜ì§‘ (URL/ìƒì„¸ë§í¬ ê´€ë ¨ í‚¤ ì œì™¸)
        skip_keys = {
            'target', 'type', 'id', 'page', 'totalcnt', 'section', 'success',
            # ìƒì„¸ë§í¬ ê´€ë ¨ í‚¤ ì œì™¸
            'íŒë¡€ìƒì„¸ë§í¬', 'ë²•ë ¹í•´ì„ë¡€ìƒì„¸ë§í¬', 'í–‰ì •ì‹¬íŒë¡€ìƒì„¸ë§í¬', 'í—Œì¬ê²°ì •ë¡€ìƒì„¸ë§í¬',
            'ìƒì„¸ë§í¬', 'detailLink', 'link', 'url',
            # API ë©”íƒ€ë°ì´í„°
            'oc', 'display', 'sort', 'query', 'keyword', 'í‚¤ì›Œë“œ'
        }
        valid_parts = []
        for key, value in item.items():
            if key.lower() not in skip_keys and self._is_valid_value(value, query):
                # ìƒì„¸ë§í¬ í‚¤ì¸ì§€ ì¶”ê°€ í™•ì¸
                if 'ìƒì„¸ë§í¬' in key or 'ë§í¬' in key or 'link' in key.lower():
                    continue
                valid_parts.append(str(value))

        return " | ".join(valid_parts[:3]) if valid_parts else '(ì •ë³´ ì—†ìŒ)'

    def _build_context(self, legal_data: Dict) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ êµ¬ì„± - íŒë¡€/ìœ ê¶Œí•´ì„ ì¤‘ì‹¬ í™•ì¥"""
        context_parts = []

        # ê¸°ë³¸ ë²•ë¥  ë°ì´í„°
        if legal_data.get('basic'):
            basic = legal_data['basic']

            # ë²•ë ¹ (ìƒìœ„ 15ê°œ)
            if basic.get('law') or basic.get('eflaw'):
                laws = (basic.get('law', []) or []) + (basic.get('eflaw', []) or [])
                if laws:
                    context_parts.append(f"\n[ê´€ë ¨ ë²•ë ¹] (ì´ {len(laws)}ê±´)")
                    for idx, law in enumerate(laws[:15], 1):
                        name = self._get_value(law, 'ë²•ë ¹ëª…í•œê¸€', 'ë²•ë ¹ëª…', 'lawNameKorean', 'lawName', 'ë²•ë ¹ëª…ì•½ì¹­')
                        dept = self._get_value(law, 'ì†Œê´€ë¶€ì²˜ëª…', 'ì†Œê´€ë¶€ì²˜', 'competentDept')
                        date = self._get_value(law, 'ì‹œí–‰ì¼ì', 'ê³µí¬ì¼ì', 'enforcementDate', 'promulgationDate')
                        if name:
                            context_parts.append(f"{idx}. {name}")
                            if dept:
                                context_parts.append(f"   - ì†Œê´€ë¶€ì²˜: {dept}")
                            if date:
                                context_parts.append(f"   - ì‹œí–‰/ê³µí¬ì¼: {date}")

            # íŒë¡€ (ìƒìœ„ 30ê°œ - í•µì‹¬ ìë£Œ)
            if basic.get('prec'):
                precs = basic['prec']
                context_parts.append(f"\n[ê´€ë ¨ íŒë¡€] (ì´ {len(precs)}ê±´) â˜… í•µì‹¬ ìë£Œ")
                for idx, prec in enumerate(precs[:30], 1):
                    name = self._get_value(prec, 'ì‚¬ê±´ëª…', 'íŒë¡€ëª…', 'caseName', 'caseNm', 'ì œëª©')
                    date = self._get_value(prec, 'ì„ ê³ ì¼ì', 'íŒê²°ì¼ì', 'judgmentDate', 'decisionDate')
                    court = self._get_value(prec, 'ë²•ì›ëª…', 'ë²•ì›', 'courtName', 'court')
                    case_no = self._get_value(prec, 'ì‚¬ê±´ë²ˆí˜¸', 'caseNo', 'caseNumber')
                    if name or case_no:
                        context_parts.append(f"{idx}. {name or '(ì‚¬ê±´ëª… ì—†ìŒ)'}")
                        if case_no:
                            context_parts.append(f"   - ì‚¬ê±´ë²ˆí˜¸: {case_no}")
                        if court:
                            context_parts.append(f"   - ë²•ì›: {court}")
                        if date:
                            context_parts.append(f"   - ì„ ê³ ì¼: {date}")

            # í—Œì¬ê²°ì •ë¡€ (ìƒìœ„ 15ê°œ)
            if basic.get('detc'):
                detcs = basic['detc']
                context_parts.append(f"\n[í—Œì¬ê²°ì •ë¡€] (ì´ {len(detcs)}ê±´)")
                for idx, case in enumerate(detcs[:15], 1):
                    name = self._get_value(case, 'ì‚¬ê±´ëª…', 'ê²°ì •ëª…', 'caseName', 'ì œëª©')
                    date = self._get_value(case, 'ì¢…êµ­ì¼ì', 'ì„ ê³ ì¼ì', 'ê²°ì •ì¼ì', 'decisionDate')
                    case_no = self._get_value(case, 'ì‚¬ê±´ë²ˆí˜¸', 'caseNo', 'caseNumber')
                    if name or case_no:
                        context_parts.append(f"{idx}. {name or '(ì‚¬ê±´ëª… ì—†ìŒ)'}")
                        if case_no:
                            context_parts.append(f"   - ì‚¬ê±´ë²ˆí˜¸: {case_no}")
                        if date:
                            context_parts.append(f"   - ì¢…êµ­ì¼: {date}")

            # ë²•ë ¹í•´ì„ë¡€ (ìƒìœ„ 25ê°œ - í•µì‹¬ ìë£Œ)
            if basic.get('expc'):
                expcs = basic['expc']
                context_parts.append(f"\n[ë²•ë ¹í•´ì„ë¡€/ìœ ê¶Œí•´ì„] (ì´ {len(expcs)}ê±´) â˜… í•µì‹¬ ìë£Œ")
                for idx, interp in enumerate(expcs[:25], 1):
                    name = self._get_value(interp, 'ì•ˆê±´ëª…', 'ì œëª©', 'title', 'caseName')
                    no = self._get_value(interp, 'ì•ˆê±´ë²ˆí˜¸', 'caseNo', 'number')
                    org = self._get_value(interp, 'íšŒì‹ ê¸°ê´€ëª…', 'íšŒì‹ ê¸°ê´€', 'replyOrg')
                    date = self._get_value(interp, 'íšŒì‹ ì¼ì', 'replyDate')
                    if name or no:
                        context_parts.append(f"{idx}. {name or '(ì•ˆê±´ëª… ì—†ìŒ)'}")
                        if no:
                            context_parts.append(f"   - ì•ˆê±´ë²ˆí˜¸: {no}")
                        if org:
                            context_parts.append(f"   - íšŒì‹ ê¸°ê´€: {org}")
                        if date:
                            context_parts.append(f"   - íšŒì‹ ì¼ì: {date}")

            # í–‰ì •ì‹¬íŒë¡€ (ìƒìœ„ 25ê°œ - í•µì‹¬ ìë£Œ)
            if basic.get('decc'):
                deccs = basic['decc']
                context_parts.append(f"\n[í–‰ì •ì‹¬íŒë¡€] (ì´ {len(deccs)}ê±´) â˜… í•µì‹¬ ìë£Œ")
                for idx, ruling in enumerate(deccs[:25], 1):
                    name = self._get_value(ruling, 'ì‚¬ê±´ëª…', 'ì œëª©', 'caseName', 'title')
                    date = self._get_value(ruling, 'ì˜ê²°ì¼ì', 'ì¬ê²°ì¼ì', 'decisionDate')
                    case_no = self._get_value(ruling, 'ì‚¬ê±´ë²ˆí˜¸', 'caseNo', 'caseNumber')
                    result = self._get_value(ruling, 'ì¬ê²°ê²°ê³¼', 'ì¬ê²°êµ¬ë¶„ëª…', 'result')
                    if name or case_no:
                        context_parts.append(f"{idx}. {name or '(ì‚¬ê±´ëª… ì—†ìŒ)'}")
                        if case_no:
                            context_parts.append(f"   - ì‚¬ê±´ë²ˆí˜¸: {case_no}")
                        if result:
                            context_parts.append(f"   - ì¬ê²°ê²°ê³¼: {result}")
                        if date:
                            context_parts.append(f"   - ì˜ê²°ì¼: {date}")

            # í–‰ì •ê·œì¹™ (ìƒìœ„ 10ê°œ)
            if basic.get('admrul'):
                admruls = basic['admrul']
                context_parts.append(f"\n[í–‰ì •ê·œì¹™] (ì´ {len(admruls)}ê±´)")
                for idx, rule in enumerate(admruls[:10], 1):
                    name = self._get_value(rule, 'í–‰ì •ê·œì¹™ëª…', 'ì œëª©', 'ruleName', 'title')
                    dept = self._get_value(rule, 'ì†Œê´€ë¶€ì²˜ëª…', 'ì†Œê´€ë¶€ì²˜', 'competentDept')
                    if name:
                        context_parts.append(f"{idx}. {name}")
                        if dept:
                            context_parts.append(f"   - ì†Œê´€ë¶€ì²˜: {dept}")

            # ìì¹˜ë²•ê·œ (ìƒìœ„ 10ê°œ)
            if basic.get('ordin'):
                ordins = basic['ordin']
                context_parts.append(f"\n[ìì¹˜ë²•ê·œ] (ì´ {len(ordins)}ê±´)")
                for idx, ordin in enumerate(ordins[:10], 1):
                    name = self._get_value(ordin, 'ìì¹˜ë²•ê·œëª…', 'ì œëª©', 'ordinName', 'title')
                    local = self._get_value(ordin, 'ì§€ìì²´ê¸°ê´€ëª…', 'ìì¹˜ë‹¨ì²´ëª…', 'localGovt')
                    context_parts.append(f"{idx}. {name}")
                    if local:
                        context_parts.append(f"   - ì§€ìì²´: {local}")

            # ì¡°ì•½ (ìƒìœ„ 5ê°œ)
            if basic.get('trty'):
                trtys = basic['trty']
                if trtys:
                    context_parts.append(f"\n[ì¡°ì•½] (ì´ {len(trtys)}ê±´)")
                    for idx, treaty in enumerate(trtys[:5], 1):
                        name = treaty.get('ì¡°ì•½ëª…', treaty.get('ì¡°ì•½ëª…í•œê¸€', ''))
                        date = treaty.get('ì²´ê²°ì¼ì', '')
                        context_parts.append(f"{idx}. {name}")
                        if date:
                            context_parts.append(f"   - ì²´ê²°ì¼ì: {date}")

        # ìœ„ì›íšŒ ê²°ì •ë¬¸
        if legal_data.get('committees'):
            for comm_key, items in legal_data['committees'].items():
                if items:
                    comm_name = self.committee_targets.get(comm_key, {}).get('name', comm_key)
                    context_parts.append(f"\n[{comm_name} ê²°ì •ë¬¸]")
                    for idx, item in enumerate(items[:5], 1):
                        name = item.get('ì‚¬ê±´ëª…', item.get('ì•ˆê±´ëª…', ''))
                        date = item.get('ì˜ê²°ì¼ì', item.get('ê²°ì •ì¼ì', ''))
                        context_parts.append(f"{idx}. {name} ({date})")

        # ë¶€ì²˜ë³„ ë²•ë ¹í•´ì„
        if legal_data.get('ministries'):
            for min_key, items in legal_data['ministries'].items():
                if items:
                    min_name = self.ministry_targets.get(min_key, {}).get('name', min_key)
                    context_parts.append(f"\n[{min_name}]")
                    for idx, item in enumerate(items[:5], 1):
                        name = item.get('ì•ˆê±´ëª…', item.get('ì œëª©', ''))
                        date = item.get('íšŒì‹ ì¼ì', item.get('ë“±ë¡ì¼ì', ''))
                        context_parts.append(f"{idx}. {name} ({date})")

        # íŠ¹ë³„í–‰ì •ì‹¬íŒë¡€
        if legal_data.get('special_tribunals'):
            for trib_key, items in legal_data['special_tribunals'].items():
                if items:
                    trib_name = self.special_tribunal_targets.get(trib_key, {}).get('name', trib_key)
                    context_parts.append(f"\n[{trib_name}]")
                    for idx, item in enumerate(items[:5], 1):
                        name = item.get('ì‚¬ê±´ëª…', item.get('ì•ˆê±´ëª…', ''))
                        date = item.get('ì¬ê²°ì¼ì', item.get('ì˜ê²°ì¼ì', ''))
                        context_parts.append(f"{idx}. {name} ({date})")

        return "\n".join(context_parts)

    def _generate_fallback_response(self, query: str, legal_data: Dict) -> str:
        """API í‚¤ ì—†ì„ ë•Œ ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ ê¸°ë³¸ ì‘ë‹µ"""
        context = self._build_context(legal_data)

        # í†µê³„ ê³„ì‚°
        stats = []
        if legal_data.get('basic'):
            for key, items in legal_data['basic'].items():
                if items:
                    name = self.basic_targets.get(key, {}).get('name', key)
                    stats.append(f"{name} {len(items)}ê±´")

        if legal_data.get('committees'):
            for key, items in legal_data['committees'].items():
                if items:
                    name = self.committee_targets.get(key, {}).get('name', key)
                    stats.append(f"{name} {len(items)}ê±´")

        if legal_data.get('ministries'):
            for key, items in legal_data['ministries'].items():
                if items:
                    name = self.ministry_targets.get(key, {}).get('name', key)
                    stats.append(f"{name} {len(items)}ê±´")

        if legal_data.get('special_tribunals'):
            for key, items in legal_data['special_tribunals'].items():
                if items:
                    name = self.special_tribunal_targets.get(key, {}).get('name', key)
                    stats.append(f"{name} {len(items)}ê±´")

        stats_text = ", ".join(stats) if stats else "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"

        return f"""## ë²•ë¥  ë°ì´í„° ê²€ìƒ‰ ê²°ê³¼

**ì§ˆì˜:** {query}

**ê²€ìƒ‰ í†µê³„:** {stats_text}

{context if context else "ê´€ë ¨ ë²•ë¥  ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}

---
âš ï¸ **ì•ˆë‚´:** OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ AI ë¶„ì„ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
ìœ„ ê²€ìƒ‰ ê²°ê³¼ëŠ” ë²•ì œì²˜ Open APIì—ì„œ ê°€ì ¸ì˜¨ ì›ë³¸ ë°ì´í„°ì…ë‹ˆë‹¤.

AI ë¶„ì„ì„ ì´ìš©í•˜ì‹œë ¤ë©´ ì‚¬ì´ë“œë°”ì—ì„œ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.

âš–ï¸ ë³¸ ë‚´ìš©ì€ ì°¸ê³ ìë£Œì´ë©°, êµ¬ì²´ì ì¸ ì‚¬ì•ˆì— ëŒ€í•´ì„œëŠ” ë°˜ë“œì‹œ ë³€í˜¸ì‚¬ ë“± ì „ë¬¸ê°€ì˜ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.
"""

        try:
            client = get_openai_client()
            if not client:
                return "AI ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. OpenAI API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
            response = client.chat.completions.create(
                model="gpt-5.1",
                messages=[
                    {"role": "system", "content": AI_LAWYER_SYSTEM_PROMPT},
                    {"role": "user", "content": prompt}
                ],
                max_completion_tokens=2000
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"AI ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
            return "AI ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

    async def generate_legal_advice(self, query: str, legal_data: Dict, fact_sheet: Dict) -> str:
        """AI ë²•ë¥  ì¡°ì–¸ ìƒì„± - ì‹¤ì œ ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜"""
        # API í‚¤ í™•ì¸
        if not get_openai_api_key():
            return self._generate_fallback_response(query, legal_data)

        context = self._build_context(legal_data)
        timeline = "\n".join([f"- {item['date']}: {item['event']}"
                             for item in fact_sheet.get('timeline', [])])

        # ê²€ìƒ‰ í†µê³„ ìš”ì•½
        stats_summary = self._get_search_stats_summary(legal_data)

        # ì¶”ì¶œëœ í‚¤ì›Œë“œ
        keywords = legal_data.get('keywords', [])
        keywords_str = ', '.join(keywords) if keywords else 'ì—†ìŒ'

        # ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
        has_results = bool(context and context.strip())

        if has_results:
            prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ ë²•ë¥  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ì— ë²•ì œì²˜ Open APIì—ì„œ ê²€ìƒ‰ëœ **ì‹¤ì œ ë²•ë¥  ìë£Œ**ê°€ ì œê³µë©ë‹ˆë‹¤.
ë°˜ë“œì‹œ ì´ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
## ì˜ë¢°ì¸ ì§ˆë¬¸/ìƒí™©:
{query}

## ì¶”ì¶œëœ ê²€ìƒ‰ í‚¤ì›Œë“œ:
{keywords_str}

## ê²€ìƒ‰ í†µê³„:
{stats_summary}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## ğŸ” ë²•ì œì²˜ì—ì„œ ê²€ìƒ‰ëœ ì‹¤ì œ ë²•ë¥  ìë£Œ:
{context}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## âš ï¸ í•„ìˆ˜ ì§€ì¹¨ (ë°˜ë“œì‹œ ì¤€ìˆ˜):
1. **ìœ„ì— ì œê³µëœ ê²€ìƒ‰ ê²°ê³¼ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.** ì¼ë°˜ì ì¸ ë²•ë¥  ì§€ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì§€ ë§ˆì„¸ìš”.
2. **íŒë¡€ë¥¼ ì¸ìš©í•  ë•ŒëŠ” ë°˜ë“œì‹œ ìœ„ ëª©ë¡ì—ì„œ ì‚¬ê±´ë²ˆí˜¸ë¥¼ ì •í™•íˆ ë³µì‚¬í•˜ì„¸ìš”.**
   ì˜ˆ: "ëŒ€ë²•ì› 2020ë‹¤12345 íŒê²°ì—ì„œ..."
3. **ë²•ë ¹í•´ì„ë¡€ë¥¼ ì¸ìš©í•  ë•ŒëŠ” ì•ˆê±´ë²ˆí˜¸ë¥¼ ëª…ì‹œí•˜ì„¸ìš”.**
   ì˜ˆ: "ë²•ì œì²˜ ì•ˆê±´ë²ˆí˜¸ 22-0123ì— ë”°ë¥´ë©´..."
4. **í–‰ì •ì‹¬íŒë¡€ë¥¼ ì¸ìš©í•  ë•ŒëŠ” ì‚¬ê±´ë²ˆí˜¸ë¥¼ ëª…ì‹œí•˜ì„¸ìš”.**
   ì˜ˆ: "ì¤‘ì•™í–‰ì •ì‹¬íŒìœ„ì›íšŒ 2023-12345 ì¬ê²°ì—ì„œ..."
5. ìœ„ ê²€ìƒ‰ ê²°ê³¼ì— ì—†ëŠ” ë‚´ìš©ì€ "ê²€ìƒ‰ ê²°ê³¼ì— í¬í•¨ë˜ì§€ ì•ŠìŒ"ì´ë¼ê³  ëª…ì‹œí•˜ì„¸ìš”.

## ë‹µë³€ í˜•ì‹:

### ğŸ“‹ í•µì‹¬ ìš”ì•½
[ì˜ë¢°ì¸ ìƒí™©ì— ëŒ€í•œ 2-3ë¬¸ì¥ í•µì‹¬ ê²°ë¡ ]

### ğŸ“š ê´€ë ¨ íŒë¡€ (ìœ„ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì¸ìš©)
[ê²€ìƒ‰ëœ íŒë¡€ ëª©ë¡ì—ì„œ ê´€ë ¨ íŒë¡€ë¥¼ ì„ íƒí•˜ì—¬ ì‚¬ê±´ë²ˆí˜¸ì™€ í•¨ê»˜ ìƒì„¸ ì„¤ëª…]
- **ì‚¬ê±´ë²ˆí˜¸**: [ìœ„ì—ì„œ ë³µì‚¬]
- **ë²•ì›/ì„ ê³ ì¼**: [ìœ„ì—ì„œ ë³µì‚¬]
- **íŒì‹œì‚¬í•­**: [ë‚´ìš© ì„¤ëª…]
- **ì˜ë¢°ì¸ ì‚¬ì•ˆ ì ìš©**: [ë¶„ì„]

### ğŸ“‹ ê´€ë ¨ ë²•ë ¹í•´ì„ë¡€/í–‰ì •ì‹¬íŒë¡€ (ìœ„ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì¸ìš©)
[ê²€ìƒ‰ëœ í•´ì„ë¡€/ì‹¬íŒë¡€ì—ì„œ ê´€ë ¨ ê±´ì„ ì„ íƒí•˜ì—¬ ì•ˆê±´ë²ˆí˜¸ì™€ í•¨ê»˜ ì„¤ëª…]

### ğŸ“– ê´€ë ¨ ë²•ë ¹
[ê²€ìƒ‰ëœ ë²•ë ¹ ì¤‘ ê´€ë ¨ ë²•ë ¹ ì¸ìš©]

### ğŸ’¡ ì¢…í•© ì˜ê²¬ ë° ì¡°ì–¸
[ìœ„ ìë£Œë“¤ì„ ì¢…í•©í•œ ë¶„ì„]

---
âš–ï¸ ë³¸ ë‚´ìš©ì€ AIê°€ ì‘ì„±í•œ ì°¸ê³ ìë£Œì´ë©°, ë²•ë¥ ìë¬¸ì´ ì•„ë‹™ë‹ˆë‹¤.
êµ¬ì²´ì ì¸ ì‚¬ì•ˆì— ëŒ€í•´ì„œëŠ” ë°˜ë“œì‹œ ë³€í˜¸ì‚¬ ë“± ì „ë¬¸ê°€ì˜ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.
"""
        else:
            prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ ë²•ë¥  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì˜ë¢°ì¸ ì§ˆë¬¸/ìƒí™©:
{query}

## ì¶”ì¶œëœ ê²€ìƒ‰ í‚¤ì›Œë“œ:
{keywords_str}

## âš ï¸ ê²€ìƒ‰ ê²°ê³¼:
ë²•ì œì²˜ Open API ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.

## ì§€ì¹¨:
1. ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŒì„ ë¨¼ì € ì•ˆë‚´í•˜ì„¸ìš”.
2. ì¼ë°˜ì ì¸ ë²•ë¥  ì •ë³´ë¥¼ ì œê³µí•˜ë˜, "ë²•ì œì²˜ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"ì„ ëª…ì‹œí•˜ì„¸ìš”.
3. ë‹¤ë¥¸ ê²€ìƒ‰ì–´ ì œì•ˆì„ í¬í•¨í•˜ì„¸ìš”.

---
âš–ï¸ ë³¸ ë‚´ìš©ì€ AIê°€ ì‘ì„±í•œ ì°¸ê³ ìë£Œì´ë©°, ë²•ë¥ ìë¬¸ì´ ì•„ë‹™ë‹ˆë‹¤.
êµ¬ì²´ì ì¸ ì‚¬ì•ˆì— ëŒ€í•´ì„œëŠ” ë°˜ë“œì‹œ ë³€í˜¸ì‚¬ ë“± ì „ë¬¸ê°€ì˜ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.
"""

        try:
            client = get_openai_client()
            if not client:
                return self._generate_fallback_response(query, legal_data)
            response = client.chat.completions.create(
                model="gpt-5.1",
                messages=[
                    {"role": "system", "content": AI_LAWYER_SYSTEM_PROMPT},
                    {"role": "user", "content": prompt}
                ],
                max_completion_tokens=2500
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"AI ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
            return self._generate_fallback_response(query, legal_data)

    async def _generate_contract_review(self, query: str, legal_data: Dict, fact_sheet: Dict) -> str:
        """ê³„ì•½ì„œ ê²€í†  ì‘ë‹µ ìƒì„±"""
        # API í‚¤ í™•ì¸
        if not get_openai_api_key():
            return self._generate_fallback_response(query, legal_data)

        context = self._build_context(legal_data)
        timeline = "\n".join([f"- {item['date']}: {item['event']}"
                             for item in fact_sheet.get('timeline', [])])

        # ê²€ìƒ‰ í†µê³„ ìš”ì•½
        stats_summary = self._get_search_stats_summary(legal_data)

        # ì¶”ì¶œëœ í‚¤ì›Œë“œ
        keywords = legal_data.get('keywords', [])
        keywords_str = ', '.join(keywords) if keywords else 'ì—†ìŒ'

        # ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
        has_results = bool(context and context.strip())

        if has_results:
            prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ ë²•ë¥  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ì— ë²•ì œì²˜ Open APIì—ì„œ ê²€ìƒ‰ëœ **ì‹¤ì œ ë²•ë¥  ìë£Œ**ê°€ ì œê³µë©ë‹ˆë‹¤.
ë°˜ë“œì‹œ ì´ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
## ì˜ë¢°ì¸ ì§ˆë¬¸/ìƒí™©:
{query}

## ì¶”ì¶œëœ ê²€ìƒ‰ í‚¤ì›Œë“œ:
{keywords_str}

## ê²€ìƒ‰ í†µê³„:
{stats_summary}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## ğŸ” ë²•ì œì²˜ì—ì„œ ê²€ìƒ‰ëœ ì‹¤ì œ ë²•ë¥  ìë£Œ:
{context}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## âš ï¸ í•„ìˆ˜ ì§€ì¹¨ (ë°˜ë“œì‹œ ì¤€ìˆ˜):
1. **ìœ„ì— ì œê³µëœ ê²€ìƒ‰ ê²°ê³¼ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.** ì¼ë°˜ì ì¸ ë²•ë¥  ì§€ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì§€ ë§ˆì„¸ìš”.
2. **íŒë¡€ë¥¼ ì¸ìš©í•  ë•ŒëŠ” ë°˜ë“œì‹œ ìœ„ ëª©ë¡ì—ì„œ ì‚¬ê±´ë²ˆí˜¸ë¥¼ ì •í™•íˆ ë³µì‚¬í•˜ì„¸ìš”.**
   ì˜ˆ: "ëŒ€ë²•ì› 2020ë‹¤12345 íŒê²°ì—ì„œ..."
3. **ë²•ë ¹í•´ì„ë¡€ë¥¼ ì¸ìš©í•  ë•ŒëŠ” ì•ˆê±´ë²ˆí˜¸ë¥¼ ëª…ì‹œí•˜ì„¸ìš”.**
   ì˜ˆ: "ë²•ì œì²˜ ì•ˆê±´ë²ˆí˜¸ 22-0123ì— ë”°ë¥´ë©´..."
4. **í–‰ì •ì‹¬íŒë¡€ë¥¼ ì¸ìš©í•  ë•ŒëŠ” ì‚¬ê±´ë²ˆí˜¸ë¥¼ ëª…ì‹œí•˜ì„¸ìš”.**
   ì˜ˆ: "ì¤‘ì•™í–‰ì •ì‹¬íŒìœ„ì›íšŒ 2023-12345 ì¬ê²°ì—ì„œ..."
5. ìœ„ ê²€ìƒ‰ ê²°ê³¼ì— ì—†ëŠ” ë‚´ìš©ì€ "ê²€ìƒ‰ ê²°ê³¼ì— í¬í•¨ë˜ì§€ ì•ŠìŒ"ì´ë¼ê³  ëª…ì‹œí•˜ì„¸ìš”.

## ë‹µë³€ í˜•ì‹:

### ğŸ“‹ í•µì‹¬ ìš”ì•½
[ì˜ë¢°ì¸ ìƒí™©ì— ëŒ€í•œ 2-3ë¬¸ì¥ í•µì‹¬ ê²°ë¡ ]

### ğŸ“š ê´€ë ¨ íŒë¡€ (ìœ„ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì¸ìš©)
[ê²€ìƒ‰ëœ íŒë¡€ ëª©ë¡ì—ì„œ ê´€ë ¨ íŒë¡€ë¥¼ ì„ íƒí•˜ì—¬ ì‚¬ê±´ë²ˆí˜¸ì™€ í•¨ê»˜ ìƒì„¸ ì„¤ëª…]
- **ì‚¬ê±´ë²ˆí˜¸**: [ìœ„ì—ì„œ ë³µì‚¬]
- **ë²•ì›/ì„ ê³ ì¼**: [ìœ„ì—ì„œ ë³µì‚¬]
- **íŒì‹œì‚¬í•­**: [ë‚´ìš© ì„¤ëª…]
- **ì˜ë¢°ì¸ ì‚¬ì•ˆ ì ìš©**: [ë¶„ì„]

### ğŸ“‹ ê´€ë ¨ ë²•ë ¹í•´ì„ë¡€/í–‰ì •ì‹¬íŒë¡€ (ìœ„ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì¸ìš©)
[ê²€ìƒ‰ëœ í•´ì„ë¡€/ì‹¬íŒë¡€ì—ì„œ ê´€ë ¨ ê±´ì„ ì„ íƒí•˜ì—¬ ì•ˆê±´ë²ˆí˜¸ì™€ í•¨ê»˜ ì„¤ëª…]

### ğŸ“– ê´€ë ¨ ë²•ë ¹
[ê²€ìƒ‰ëœ ë²•ë ¹ ì¤‘ ê´€ë ¨ ë²•ë ¹ ì¸ìš©]

### ğŸ’¡ ì¢…í•© ì˜ê²¬ ë° ì¡°ì–¸
[ìœ„ ìë£Œë“¤ì„ ì¢…í•©í•œ ë¶„ì„]

---
âš–ï¸ ë³¸ ë‚´ìš©ì€ AIê°€ ì‘ì„±í•œ ì°¸ê³ ìë£Œì´ë©°, ë²•ë¥ ìë¬¸ì´ ì•„ë‹™ë‹ˆë‹¤.
êµ¬ì²´ì ì¸ ì‚¬ì•ˆì— ëŒ€í•´ì„œëŠ” ë°˜ë“œì‹œ ë³€í˜¸ì‚¬ ë“± ì „ë¬¸ê°€ì˜ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.
"""
        else:
            prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ ë²•ë¥  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì˜ë¢°ì¸ ì§ˆë¬¸/ìƒí™©:
{query}

## ì¶”ì¶œëœ ê²€ìƒ‰ í‚¤ì›Œë“œ:
{keywords_str}

## âš ï¸ ê²€ìƒ‰ ê²°ê³¼:
ë²•ì œì²˜ Open API ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.

## ì§€ì¹¨:
1. ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŒì„ ë¨¼ì € ì•ˆë‚´í•˜ì„¸ìš”.
2. ì¼ë°˜ì ì¸ ë²•ë¥  ì •ë³´ë¥¼ ì œê³µí•˜ë˜, "ë²•ì œì²˜ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"ì„ ëª…ì‹œí•˜ì„¸ìš”.
3. ë‹¤ë¥¸ ê²€ìƒ‰ì–´ ì œì•ˆì„ í¬í•¨í•˜ì„¸ìš”.

---
âš–ï¸ ë³¸ ë‚´ìš©ì€ AIê°€ ì‘ì„±í•œ ì°¸ê³ ìë£Œì´ë©°, ë²•ë¥ ìë¬¸ì´ ì•„ë‹™ë‹ˆë‹¤.
êµ¬ì²´ì ì¸ ì‚¬ì•ˆì— ëŒ€í•´ì„œëŠ” ë°˜ë“œì‹œ ë³€í˜¸ì‚¬ ë“± ì „ë¬¸ê°€ì˜ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.
"""

        try:
            client = get_openai_client()
            if not client:
                return self._generate_fallback_response(query, legal_data)
            response = client.chat.completions.create(
                model="gpt-5.1",
                messages=[
                    {"role": "system", "content": AI_LAWYER_SYSTEM_PROMPT},
                    {"role": "user", "content": prompt}
                ],
                max_completion_tokens=2500
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"AI ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
            return self._generate_fallback_response(query, legal_data)

    def _get_search_stats_summary(self, legal_data: Dict) -> str:
        """ê²€ìƒ‰ í†µê³„ ìš”ì•½ ìƒì„±"""
        stats = []

        if legal_data.get('basic'):
            basic = legal_data['basic']
            if basic.get('law') or basic.get('eflaw'):
                laws = (basic.get('law', []) or []) + (basic.get('eflaw', []) or [])
                if laws:
                    stats.append(f"- ë²•ë ¹: {len(laws)}ê±´")
            if basic.get('prec'):
                stats.append(f"- íŒë¡€: {len(basic['prec'])}ê±´ â˜…")
            if basic.get('detc'):
                stats.append(f"- í—Œì¬ê²°ì •ë¡€: {len(basic['detc'])}ê±´")
            if basic.get('expc'):
                stats.append(f"- ë²•ë ¹í•´ì„ë¡€: {len(basic['expc'])}ê±´ â˜…")
            if basic.get('decc'):
                stats.append(f"- í–‰ì •ì‹¬íŒë¡€: {len(basic['decc'])}ê±´ â˜…")
            if basic.get('admrul'):
                stats.append(f"- í–‰ì •ê·œì¹™: {len(basic['admrul'])}ê±´")
            if basic.get('ordin'):
                stats.append(f"- ìì¹˜ë²•ê·œ: {len(basic['ordin'])}ê±´")

        if legal_data.get('committees'):
            for key, items in legal_data['committees'].items():
                if items:
                    name = self.committee_targets.get(key, {}).get('name', key)
                    stats.append(f"- {name}: {len(items)}ê±´")

        if legal_data.get('ministries'):
            for key, items in legal_data['ministries'].items():
                if items:
                    name = self.ministry_targets.get(key, {}).get('name', key)
                    stats.append(f"- {name}: {len(items)}ê±´")

        if legal_data.get('special_tribunals'):
            for key, items in legal_data['special_tribunals'].items():
                if items:
                    name = self.special_tribunal_targets.get(key, {}).get('name', key)
                    stats.append(f"- {name}: {len(items)}ê±´")

        return "\n".join(stats) if stats else "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"

# ===== UI í•¨ìˆ˜ë“¤ =====
def display_chat_message(role: str, content: str):
    """ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ"""
    if role == "user":
        st.markdown(f'''
        <div class="chat-message user-message">
            <strong>ğŸ‘¤ ì˜ë¢°ì¸:</strong><br>
            {content}
        </div>
        ''', unsafe_allow_html=True)
    else:
        st.markdown(content)

def display_search_results_detail(legal_data: Dict, engine: LegalAIEngine, query: str = ''):
    """ê²€ìƒ‰ëœ íŒë¡€/ìœ ê¶Œí•´ì„ ìƒì„¸ í‘œì‹œ"""
    if not legal_data:
        return

    basic = legal_data.get('basic', {})

    # íŒë¡€ ìƒì„¸
    if basic.get('prec'):
        with st.expander(f"ğŸ“š ê²€ìƒ‰ëœ íŒë¡€ ({len(basic['prec'])}ê±´)", expanded=True):
            for idx, prec in enumerate(basic['prec'][:20], 1):
                display_name = engine._get_item_display(prec, 'ì‚¬ê±´ëª…', 'íŒë¡€ëª…', 'caseName', 'ì œëª©', query=query)
                case_no = engine._get_value(prec, 'ì‚¬ê±´ë²ˆí˜¸', 'caseNo', 'caseNumber', query=query)
                court = engine._get_value(prec, 'ë²•ì›ëª…', 'ë²•ì›', 'courtName', 'court', query=query)
                date = engine._get_value(prec, 'ì„ ê³ ì¼ì', 'íŒê²°ì¼ì', 'judgmentDate', 'decisionDate', query=query)
                detail_link = engine._get_value(prec, 'íŒë¡€ìƒì„¸ë§í¬', 'detailLink', query=query)
                if display_name and display_name != '(ì •ë³´ ì—†ìŒ)':
                    col1, col2 = st.columns([5, 1])
                    with col1:
                        st.markdown(f"**{idx}. {display_name}**")
                        if case_no or court or date:
                            st.caption(f"ì‚¬ê±´ë²ˆí˜¸: {case_no or '-'} | ë²•ì›: {court or '-'} | ì„ ê³ ì¼: {date or '-'}")
                    with col2:
                        if detail_link:
                            full_link = f"https://www.law.go.kr{detail_link}" if detail_link.startswith('/') else detail_link
                            st.markdown(f"[ìƒì„¸ë³´ê¸°]({full_link})")

    # ë²•ë ¹í•´ì„ë¡€ ìƒì„¸
    if basic.get('expc'):
        with st.expander(f"ğŸ“‹ ê²€ìƒ‰ëœ ë²•ë ¹í•´ì„ë¡€ ({len(basic['expc'])}ê±´)", expanded=True):
            for idx, expc in enumerate(basic['expc'][:20], 1):
                display_name = engine._get_item_display(expc, 'ì•ˆê±´ëª…', 'ì œëª©', 'title', 'caseName', query=query)
                no = engine._get_value(expc, 'ì•ˆê±´ë²ˆí˜¸', 'caseNo', 'number', query=query)
                org = engine._get_value(expc, 'íšŒì‹ ê¸°ê´€ëª…', 'íšŒì‹ ê¸°ê´€', 'replyOrg', query=query)
                date = engine._get_value(expc, 'íšŒì‹ ì¼ì', 'replyDate', query=query)
                detail_link = engine._get_value(expc, 'ë²•ë ¹í•´ì„ë¡€ìƒì„¸ë§í¬', 'detailLink', query=query)
                if display_name and display_name != '(ì •ë³´ ì—†ìŒ)':
                    col1, col2 = st.columns([5, 1])
                    with col1:
                        st.markdown(f"**{idx}. {display_name}**")
                        if no or org or date:
                            st.caption(f"ì•ˆê±´ë²ˆí˜¸: {no or '-'} | íšŒì‹ ê¸°ê´€: {org or '-'} | íšŒì‹ ì¼: {date or '-'}")
                    with col2:
                        if detail_link:
                            full_link = f"https://www.law.go.kr{detail_link}" if detail_link.startswith('/') else detail_link
                            st.markdown(f"[ìƒì„¸ë³´ê¸°]({full_link})")

    # í–‰ì •ì‹¬íŒë¡€ ìƒì„¸
    if basic.get('decc'):
        with st.expander(f"âš–ï¸ ê²€ìƒ‰ëœ í–‰ì •ì‹¬íŒë¡€ ({len(basic['decc'])}ê±´)", expanded=True):
            for idx, decc in enumerate(basic['decc'][:20], 1):
                display_name = engine._get_item_display(decc, 'ì‚¬ê±´ëª…', 'ì œëª©', 'caseName', 'title', query=query)
                case_no = engine._get_value(decc, 'ì‚¬ê±´ë²ˆí˜¸', 'caseNo', 'caseNumber', query=query)
                result = engine._get_value(decc, 'ì¬ê²°ê²°ê³¼', 'ì¬ê²°êµ¬ë¶„ëª…', 'result', query=query)
                date = engine._get_value(decc, 'ì˜ê²°ì¼ì', 'ì¬ê²°ì¼ì', 'decisionDate', query=query)
                detail_link = engine._get_value(decc, 'í–‰ì •ì‹¬íŒë¡€ìƒì„¸ë§í¬', 'detailLink', query=query)
                if display_name and display_name != '(ì •ë³´ ì—†ìŒ)':
                    col1, col2 = st.columns([5, 1])
                    with col1:
                        st.markdown(f"**{idx}. {display_name}**")
                        if case_no or result or date:
                            st.caption(f"ì‚¬ê±´ë²ˆí˜¸: {case_no or '-'} | ì¬ê²°ê²°ê³¼: {result or '-'} | ì˜ê²°ì¼: {date or '-'}")
                    with col2:
                        if detail_link:
                            full_link = f"https://www.law.go.kr{detail_link}" if detail_link.startswith('/') else detail_link
                            st.markdown(f"[ìƒì„¸ë³´ê¸°]({full_link})")

    # í—Œì¬ê²°ì •ë¡€ ìƒì„¸
    if basic.get('detc'):
        with st.expander(f"ğŸ›ï¸ ê²€ìƒ‰ëœ í—Œì¬ê²°ì •ë¡€ ({len(basic['detc'])}ê±´)", expanded=False):
            for idx, detc in enumerate(basic['detc'][:10], 1):
                display_name = engine._get_item_display(detc, 'ì‚¬ê±´ëª…', 'ê²°ì •ëª…', 'caseName', 'ì œëª©', query=query)
                case_no = engine._get_value(detc, 'ì‚¬ê±´ë²ˆí˜¸', 'caseNo', 'caseNumber', query=query)
                date = engine._get_value(detc, 'ì¢…êµ­ì¼ì', 'ì„ ê³ ì¼ì', 'ê²°ì •ì¼ì', 'decisionDate', query=query)
                detail_link = engine._get_value(detc, 'í—Œì¬ê²°ì •ë¡€ìƒì„¸ë§í¬', 'detailLink', query=query)
                if display_name and display_name != '(ì •ë³´ ì—†ìŒ)':
                    col1, col2 = st.columns([5, 1])
                    with col1:
                        st.markdown(f"**{idx}. {display_name}**")
                        st.caption(f"ì‚¬ê±´ë²ˆí˜¸: {case_no or '-'} | ì¢…êµ­ì¼: {date or '-'}")
                    with col2:
                        if detail_link:
                            full_link = f"https://www.law.go.kr{detail_link}" if detail_link.startswith('/') else detail_link
                            st.markdown(f"[ìƒì„¸ë³´ê¸°]({full_link})")

    # ìœ„ì›íšŒ ê²°ì •ë¬¸ í‘œì‹œ
    committees = legal_data.get('committees', {})
    if committees:
        total_committee = sum(len(items) for items in committees.values() if items)
        if total_committee > 0:
            with st.expander(f"ğŸ¢ ìœ„ì›íšŒ ê²°ì •ë¬¸ ({total_committee}ê±´)", expanded=False):
                for comm_key, items in committees.items():
                    if items:
                        comm_name = engine.committee_targets.get(comm_key, {}).get('name', comm_key)
                        st.markdown(f"**{comm_name}** ({len(items)}ê±´)")
                        for idx, item in enumerate(items[:10], 1):
                            display_name = engine._get_item_display(item, 'ì‚¬ê±´ëª…', 'ì œëª©', 'caseName', 'title', query=query)
                            case_no = engine._get_value(item, 'ì‚¬ê±´ë²ˆí˜¸', 'caseNo', query=query)
                            date = engine._get_value(item, 'ì˜ê²°ì¼ì', 'ê²°ì •ì¼ì', 'decisionDate', query=query)
                            detail_link = engine._get_value(item, 'ìƒì„¸ë§í¬', 'detailLink', query=query)
                            if display_name and display_name != '(ì •ë³´ ì—†ìŒ)':
                                col1, col2 = st.columns([5, 1])
                                with col1:
                                    st.markdown(f"{idx}. {display_name}")
                                    if case_no or date:
                                        st.caption(f"ì‚¬ê±´ë²ˆí˜¸: {case_no or '-'} | ì¼ì: {date or '-'}")
                                with col2:
                                    if detail_link:
                                        full_link = f"https://www.law.go.kr{detail_link}" if detail_link.startswith('/') else detail_link
                                        st.markdown(f"[ìƒì„¸]({full_link})")
                        st.markdown("---")

    # ë¶€ì²˜ë³„ ë²•ë ¹í•´ì„ í‘œì‹œ
    ministries = legal_data.get('ministries', {})
    if ministries:
        total_ministry = sum(len(items) for items in ministries.values() if items)
        if total_ministry > 0:
            with st.expander(f"ğŸ›ï¸ ë¶€ì²˜ë³„ ë²•ë ¹í•´ì„ ({total_ministry}ê±´)", expanded=False):
                for min_key, items in ministries.items():
                    if items:
                        min_name = engine.ministry_targets.get(min_key, {}).get('name', min_key)
                        st.markdown(f"**{min_name}** ({len(items)}ê±´)")
                        for idx, item in enumerate(items[:10], 1):
                            display_name = engine._get_item_display(item, 'ì•ˆê±´ëª…', 'ì œëª©', 'title', query=query)
                            no = engine._get_value(item, 'ì•ˆê±´ë²ˆí˜¸', 'caseNo', query=query)
                            date = engine._get_value(item, 'íšŒì‹ ì¼ì', 'replyDate', query=query)
                            detail_link = engine._get_value(item, 'ë²•ë ¹í•´ì„ë¡€ìƒì„¸ë§í¬', 'detailLink', query=query)
                            if display_name and display_name != '(ì •ë³´ ì—†ìŒ)':
                                col1, col2 = st.columns([5, 1])
                                with col1:
                                    st.markdown(f"{idx}. {display_name}")
                                    if no or date:
                                        st.caption(f"ì•ˆê±´ë²ˆí˜¸: {no or '-'} | íšŒì‹ ì¼: {date or '-'}")
                                with col2:
                                    if detail_link:
                                        full_link = f"https://www.law.go.kr{detail_link}" if detail_link.startswith('/') else detail_link
                                        st.markdown(f"[ìƒì„¸]({full_link})")
                        st.markdown("---")

    # íŠ¹ë³„í–‰ì •ì‹¬íŒë¡€ í‘œì‹œ
    special_tribunals = legal_data.get('special_tribunals', {})
    if special_tribunals:
        total_tribunal = sum(len(items) for items in special_tribunals.values() if items)
        if total_tribunal > 0:
            with st.expander(f"âš–ï¸ íŠ¹ë³„í–‰ì •ì‹¬íŒë¡€ ({total_tribunal}ê±´)", expanded=False):
                for trib_key, items in special_tribunals.items():
                    if items:
                        trib_name = engine.special_tribunal_targets.get(trib_key, {}).get('name', trib_key)
                        st.markdown(f"**{trib_name}** ({len(items)}ê±´)")
                        for idx, item in enumerate(items[:10], 1):
                            display_name = engine._get_item_display(item, 'ì‚¬ê±´ëª…', 'ì œëª©', 'caseName', query=query)
                            case_no = engine._get_value(item, 'ì‚¬ê±´ë²ˆí˜¸', 'caseNo', query=query)
                            date = engine._get_value(item, 'ì¬ê²°ì¼ì', 'ì˜ê²°ì¼ì', 'decisionDate', query=query)
                            detail_link = engine._get_value(item, 'í–‰ì •ì‹¬íŒë¡€ìƒì„¸ë§í¬', 'detailLink', query=query)
                            if display_name and display_name != '(ì •ë³´ ì—†ìŒ)':
                                col1, col2 = st.columns([5, 1])
                                with col1:
                                    st.markdown(f"{idx}. {display_name}")
                                    if case_no or date:
                                        st.caption(f"ì‚¬ê±´ë²ˆí˜¸: {case_no or '-'} | ì¬ê²°ì¼: {date or '-'}")
                                with col2:
                                    if detail_link:
                                        full_link = f"https://www.law.go.kr{detail_link}" if detail_link.startswith('/') else detail_link
                                        st.markdown(f"[ìƒì„¸]({full_link})")
                        st.markdown("---")

def display_download_section(legal_data: Dict, engine: LegalAIEngine):
    """ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ ì„¹ì…˜ í‘œì‹œ"""
    if not legal_data:
        return

    basic = legal_data.get('basic', {})

    # ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ ë¬¸ì„œ ìˆ˜ì§‘
    download_targets = []
    if basic.get('prec'):
        download_targets.append(('prec', 'íŒë¡€', basic['prec']))
    if basic.get('expc'):
        download_targets.append(('expc', 'ë²•ë ¹í•´ì„ë¡€', basic['expc']))
    if basic.get('decc'):
        download_targets.append(('decc', 'í–‰ì •ì‹¬íŒë¡€', basic['decc']))
    if basic.get('detc'):
        download_targets.append(('detc', 'í—Œì¬ê²°ì •ë¡€', basic['detc']))

    if not download_targets:
        return

    st.markdown("---")
    st.markdown("### ğŸ“¥ ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ")

    # ë‹¤ìš´ë¡œë“œ í˜•ì‹ ì„ íƒ
    col1, col2 = st.columns(2)
    with col1:
        download_format = st.selectbox(
            "ë‹¤ìš´ë¡œë“œ í˜•ì‹",
            options=['markdown', 'pdf'],
            format_func=lambda x: 'Markdown (.md)' if x == 'markdown' else 'PDF (.pdf)',
            key='download_format'
        )
    with col2:
        download_type = st.selectbox(
            "ë‹¤ìš´ë¡œë“œ ìœ í˜•",
            options=['individual', 'merge'],
            format_func=lambda x: 'ê°œë³„ ë¬¸ì„œ' if x == 'individual' else 'ë³‘í•© ë¬¸ì„œ',
            key='download_type'
        )

    # ë¬¸ì„œ ì„ íƒ
    st.markdown("#### ğŸ“‹ ë‹¤ìš´ë¡œë“œí•  ë¬¸ì„œ ì„ íƒ")

    # ì„¸ì…˜ ìƒíƒœì— ì„ íƒëœ ë¬¸ì„œ ì €ì¥
    if 'selected_docs' not in st.session_state:
        st.session_state.selected_docs = {}

    for target_code, target_name, items in download_targets:
        with st.expander(f"{target_name} ({len(items)}ê±´)", expanded=False):
            # ì „ì²´ ì„ íƒ ì²´í¬ë°•ìŠ¤
            select_all_key = f"select_all_{target_code}"
            select_all = st.checkbox(f"ì „ì²´ ì„ íƒ", key=select_all_key)

            for idx, item in enumerate(items[:20]):
                # ID ì¶”ì¶œ
                item_id = None
                id_fields = ['íŒë¡€ì¼ë ¨ë²ˆí˜¸', 'ë²•ë ¹í•´ì„ë¡€ì¼ë ¨ë²ˆí˜¸', 'í–‰ì •ì‹¬íŒë¡€ì¼ë ¨ë²ˆí˜¸',
                            'í—Œì¬ê²°ì •ë¡€ì¼ë ¨ë²ˆí˜¸', 'ID', 'id', 'ì¼ë ¨ë²ˆí˜¸']
                for field in id_fields:
                    if field in item:
                        item_id = str(item[field])
                        break

                if not item_id:
                    continue

                # ì œëª© ì¶”ì¶œ
                title = engine._get_item_display(item, 'ì‚¬ê±´ëª…', 'ì•ˆê±´ëª…', 'ì œëª©', 'caseName', 'title')
                case_no = engine._get_value(item, 'ì‚¬ê±´ë²ˆí˜¸', 'ì•ˆê±´ë²ˆí˜¸', 'caseNo')

                doc_key = f"{target_code}_{item_id}"
                default_value = select_all or st.session_state.selected_docs.get(doc_key, False)

                if st.checkbox(
                    f"{idx + 1}. {title or 'ì œëª© ì—†ìŒ'} ({case_no or '-'})",
                    value=default_value,
                    key=f"doc_{doc_key}"
                ):
                    st.session_state.selected_docs[doc_key] = {
                        'target': target_code,
                        'id': item_id,
                        'title': title,
                        'case_no': case_no,
                        'item': item
                    }
                else:
                    if doc_key in st.session_state.selected_docs:
                        del st.session_state.selected_docs[doc_key]

    # ì„ íƒëœ ë¬¸ì„œ ìˆ˜ í‘œì‹œ
    selected_count = len([k for k, v in st.session_state.selected_docs.items() if v])
    st.info(f"ì„ íƒëœ ë¬¸ì„œ: {selected_count}ê±´")

    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    if st.button("ğŸ“¥ ì„ íƒí•œ ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ", type="primary", disabled=selected_count == 0):
        with st.spinner("ë¬¸ì„œë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
            # ì„ íƒëœ ë¬¸ì„œë“¤ ê°€ì ¸ì˜¤ê¸°
            selected_items = [v for v in st.session_state.selected_docs.values() if v]

            if not selected_items:
                st.warning("ë‹¤ìš´ë¡œë“œí•  ë¬¸ì„œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
                return

            # ìƒì„¸ ì •ë³´ ì¡°íšŒ ë° ë³€í™˜
            downloaded_docs = []
            progress_bar = st.progress(0)

            for idx, doc_info in enumerate(selected_items):
                try:
                    detail = asyncio.run(engine.get_detail(doc_info['target'], doc_info['id']))
                    if detail:
                        md_content = engine.format_document_as_markdown(detail, doc_info['target'])
                        downloaded_docs.append({
                            'id': doc_info['id'],
                            'title': doc_info['title'] or f"ë¬¸ì„œ_{doc_info['id']}",
                            'case_no': doc_info['case_no'] or '',
                            'target': doc_info['target'],
                            'markdown': md_content
                        })
                except Exception as e:
                    logger.error(f"ë¬¸ì„œ ì¡°íšŒ ì‹¤íŒ¨: {e}")

                progress_bar.progress((idx + 1) / len(selected_items))

            if not downloaded_docs:
                st.error("ë¬¸ì„œë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                return

            # ë‹¤ìš´ë¡œë“œ ì²˜ë¦¬
            if download_type == 'merge':
                # ë³‘í•© ë‹¤ìš´ë¡œë“œ
                merged_content = engine.merge_documents_as_markdown(downloaded_docs)

                if download_format == 'markdown':
                    st.download_button(
                        label="ğŸ’¾ ë³‘í•© ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ (MD)",
                        data=merged_content,
                        file_name=f"ë²•ë¥ ë¬¸ì„œ_ë³‘í•©_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
                        mime="text/markdown"
                    )
                else:
                    pdf_content = engine.generate_pdf_content(merged_content, "ë²•ë¥  ë¬¸ì„œ ëª¨ìŒ")
                    if pdf_content:
                        st.download_button(
                            label="ğŸ’¾ ë³‘í•© ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ (PDF)",
                            data=pdf_content,
                            file_name=f"ë²•ë¥ ë¬¸ì„œ_ë³‘í•©_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf",
                            mime="application/pdf"
                        )
                    else:
                        st.warning("PDF ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. Markdownìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.")
                        st.download_button(
                            label="ğŸ’¾ ë³‘í•© ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ (MD)",
                            data=merged_content,
                            file_name=f"ë²•ë¥ ë¬¸ì„œ_ë³‘í•©_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
                            mime="text/markdown"
                        )
            else:
                # ê°œë³„ ë‹¤ìš´ë¡œë“œ
                st.markdown("#### ğŸ“ ê°œë³„ ë‹¤ìš´ë¡œë“œ")
                for doc in downloaded_docs:
                    safe_title = re.sub(r'[<>:"/\\|?*]', '_', doc['title'][:30])

                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.write(f"**{doc['title']}** ({doc['case_no']})")
                    with col2:
                        if download_format == 'markdown':
                            st.download_button(
                                label="ğŸ“„ MD",
                                data=doc['markdown'],
                                file_name=f"{safe_title}.md",
                                mime="text/markdown",
                                key=f"dl_md_{doc['id']}"
                            )
                        else:
                            pdf_content = engine.generate_pdf_content(doc['markdown'], doc['title'])
                            if pdf_content:
                                st.download_button(
                                    label="ğŸ“„ PDF",
                                    data=pdf_content,
                                    file_name=f"{safe_title}.pdf",
                                    mime="application/pdf",
                                    key=f"dl_pdf_{doc['id']}"
                                )
                            else:
                                st.download_button(
                                    label="ğŸ“„ MD",
                                    data=doc['markdown'],
                                    file_name=f"{safe_title}.md",
                                    mime="text/markdown",
                                    key=f"dl_md_fallback_{doc['id']}"
                                )

            st.success(f"âœ… {len(downloaded_docs)}ê±´ì˜ ë¬¸ì„œ ì¤€ë¹„ ì™„ë£Œ!")

def display_search_statistics(fact_sheet: Dict, engine: LegalAIEngine):
    """ê²€ìƒ‰ ê²°ê³¼ í†µê³„ í‘œì‹œ"""
    stats = fact_sheet.get('statistics', {})
    if not stats:
        return

    st.markdown("### ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ í†µê³„")

    # ê¸°ë³¸ ë°ì´í„°
    basic_stats = {k: v for k, v in stats.items()
                  if not k.startswith(('committee_', 'ministry_', 'tribunal_'))}
    if basic_stats:
        cols = st.columns(4)
        for idx, (key, count) in enumerate(basic_stats.items()):
            name = engine.basic_targets.get(key, {}).get('name', key)
            with cols[idx % 4]:
                st.metric(name, count)

    # ìœ„ì›íšŒ ê²°ì •ë¬¸
    committee_stats = {k.replace('committee_', ''): v for k, v in stats.items()
                      if k.startswith('committee_')}
    if committee_stats:
        st.markdown("#### ìœ„ì›íšŒ ê²°ì •ë¬¸")
        cols = st.columns(4)
        for idx, (key, count) in enumerate(committee_stats.items()):
            name = engine.committee_targets.get(key, {}).get('name', key)
            with cols[idx % 4]:
                st.metric(name, count)

    # ë¶€ì²˜ë³„ ë²•ë ¹í•´ì„
    ministry_stats = {k.replace('ministry_', ''): v for k, v in stats.items()
                     if k.startswith('ministry_')}
    if ministry_stats:
        st.markdown("#### ë¶€ì²˜ë³„ ë²•ë ¹í•´ì„")
        cols = st.columns(4)
        for idx, (key, count) in enumerate(ministry_stats.items()):
            name = engine.ministry_targets.get(key, {}).get('name', key)
            with cols[idx % 4]:
                st.metric(name, count)

async def process_search(query: str, search_options: Dict):
    """ê²€ìƒ‰ ì²˜ë¦¬"""
    engine = LegalAIEngine()

    # ê²€ìƒ‰ ìƒíƒœ í‘œì‹œ ì˜ì—­
    status_container = st.container()

    with status_container:
        st.info("ğŸ” ë²•ë¥  ë°ì´í„° ê²€ìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        progress = st.progress(0)

        # API í‚¤ í™•ì¸
        api_key = get_law_api_key()
        if not api_key:
            st.error("âŒ ë²•ì œì²˜ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return {}, {}, "ë²•ì œì²˜ API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.", engine

        # 1. ì¢…í•© ê²€ìƒ‰
        progress.progress(20, "ë²•ì œì²˜ ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ì¤‘...")
        legal_data = await engine.comprehensive_search(query, search_options)

        # ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½ í‘œì‹œ
        basic = legal_data.get('basic', {})
        search_summary = []
        if basic.get('prec'):
            search_summary.append(f"íŒë¡€ {len(basic['prec'])}ê±´")
        if basic.get('expc'):
            search_summary.append(f"ë²•ë ¹í•´ì„ë¡€ {len(basic['expc'])}ê±´")
        if basic.get('decc'):
            search_summary.append(f"í–‰ì •ì‹¬íŒë¡€ {len(basic['decc'])}ê±´")
        if basic.get('law') or basic.get('eflaw'):
            laws = (basic.get('law', []) or []) + (basic.get('eflaw', []) or [])
            if laws:
                search_summary.append(f"ë²•ë ¹ {len(laws)}ê±´")

        if search_summary:
            progress.progress(50, f"ê²€ìƒ‰ ì™„ë£Œ: {', '.join(search_summary)}")
        else:
            st.warning("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¡œ ì‹œë„í•´ë³´ì„¸ìš”.")
            progress.progress(50, "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")

        # ì‚¬ê±´ë²ˆí˜¸ ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
        case_info = legal_data.get('case_info', {})
        is_case_number_only = legal_data.get('is_case_number_only', False)
        if case_info and case_info.get('type'):
            case_type_names = {
                'prec': 'íŒë¡€',
                'expc': 'ë²•ë ¹í•´ì„ë¡€',
                'decc': 'í–‰ì •ì‹¬íŒë¡€'
            }
            case_type_name = case_type_names.get(case_info['type'], case_info['type'])

            # ì‚¬ê±´ë²ˆí˜¸ ê²€ìƒ‰ ê²°ê³¼ í™•ì¸
            case_type = case_info['type']
            case_results = basic.get(case_type, []) if basic else []

            if case_results:
                st.success(f"ğŸ”¢ **ì‚¬ê±´ë²ˆí˜¸ ê²€ìƒ‰ ì„±ê³µ:** {', '.join(case_info['case_numbers'])} ({case_type_name}) - {len(case_results)}ê±´")
            elif is_case_number_only:
                st.warning(f"âš ï¸ **ì‚¬ê±´ë²ˆí˜¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ:** {', '.join(case_info['case_numbers'])} ({case_type_name})\n\n"
                          f"í•´ë‹¹ ì‚¬ê±´ë²ˆí˜¸ì˜ {case_type_name}ì„(ë¥¼) ë²•ì œì²˜ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
                          f"- ì‚¬ê±´ë²ˆí˜¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”\n"
                          f"- ìµœê·¼ ì‚¬ê±´ì˜ ê²½ìš° ì•„ì§ ë“±ë¡ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            else:
                st.info(f"ğŸ”¢ **ì‚¬ê±´ë²ˆí˜¸ ê°ì§€:** {', '.join(case_info['case_numbers'])} ({case_type_name}) - ì§ì ‘ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ, í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ")

        # AI ë¶„ì„ ê²°ê³¼ í‘œì‹œ (ì‚¬ê±´ë²ˆí˜¸ ì „ìš© ê²€ìƒ‰ì´ ì•„ë‹ ë•Œë§Œ)
        ai_analysis = legal_data.get('ai_analysis', {})
        if ai_analysis and ai_analysis.get('intent') and not is_case_number_only:
            with st.expander("ğŸ¤– AI ì§ˆì˜ ë¶„ì„ ê²°ê³¼", expanded=True):
                # í•µì‹¬ ì§ˆë¬¸
                core_question = ai_analysis.get('core_question', '')
                if core_question:
                    st.markdown(f"**â“ í•µì‹¬ ì§ˆë¬¸:** {core_question}")

                # ì˜ë„ ë¶„ì„
                st.markdown(f"**ğŸ“Œ ë¶„ì„ëœ ì˜ë„:** {ai_analysis.get('intent', 'ì•Œ ìˆ˜ ì—†ìŒ')}")

                # ë²•ì  ìŸì 
                legal_issues = ai_analysis.get('legal_issues', [])
                if legal_issues:
                    st.markdown("**âš–ï¸ íŒŒì•…ëœ ë²•ì  ìŸì :**")
                    for issue in legal_issues:
                        st.markdown(f"  - {issue}")

                # í•µì‹¬ ë²•ì  ê°œë…
                legal_concepts = ai_analysis.get('legal_concepts', [])
                if legal_concepts:
                    st.markdown(f"**ğŸ”– í•µì‹¬ ë²•ì  ê°œë…:** {', '.join(legal_concepts)}")

                # ê´€ë ¨ ë²•ë ¹
                law_names = ai_analysis.get('law_names', [])
                if law_names:
                    st.markdown(f"**ğŸ“š ê´€ë ¨ ë²•ë ¹:** {', '.join(law_names)}")

                # ê²€ìƒ‰ í‚¤ì›Œë“œ
                search_queries = ai_analysis.get('search_queries', [])
                if search_queries:
                    st.markdown(f"**ğŸ” ìƒì„±ëœ ê²€ìƒ‰ì–´:** {', '.join(search_queries)}")

                st.info("ğŸ’¡ ê²€ìƒ‰ ê²°ê³¼ëŠ” AIê°€ ê´€ë ¨ì„±ì„ ê²€ì¦í•˜ì—¬ í•µì‹¬ ìŸì ê³¼ ì§ì ‘ ê´€ë ¨ëœ ìë£Œë§Œ í‘œì‹œí•©ë‹ˆë‹¤.")

        # 2. ì‚¬ì‹¤ê´€ê³„ ì •ë¦¬
        progress.progress(60, "ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„ ì¤‘...")
        fact_sheet = engine.create_fact_sheet(query, legal_data)

        # 3. AI ë¶„ì„
        progress.progress(80, "AI ë¶„ì„ ì¤‘...")
        advice = await engine.generate_legal_advice(query, legal_data, fact_sheet)

        progress.progress(100, "ì™„ë£Œ!")
        time.sleep(0.5)
        progress.empty()

        # ìµœì¢… ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½
        if search_summary:
            st.success(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: {', '.join(search_summary)}")
        else:
            st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

    return legal_data, fact_sheet, advice, engine

# ===== PDF ë²ˆì—­ UI í•¨ìˆ˜ =====
def render_pdf_translation_tab():
    """PDF ë²ˆì—­ íƒ­ ë Œë”ë§"""
    st.header("ğŸ“„ PDF ë¬¸ì„œ ë²ˆì—­")
    st.markdown("PDF ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ë©´ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  ë²ˆì—­í•©ë‹ˆë‹¤. (ìˆ˜ì‹ì€ ë³´ì¡´ë©ë‹ˆë‹¤)")

    if not PDF_TRANSLATOR_AVAILABLE:
        st.error("PDF ë²ˆì—­ ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
        st.code("pip install pymupdf Pillow pytesseract reportlab", language="bash")
        return

    # OpenAI API í‚¤ í™•ì¸
    openai_key = get_openai_api_key()
    if not openai_key:
        st.warning("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    # ë²ˆì—­ ì„¤ì •
    col1, col2 = st.columns(2)
    with col1:
        source_lang = st.selectbox(
            "ì›ë³¸ ì–¸ì–´",
            options=["en", "ko", "ja", "zh", "de", "fr", "es", "ru"],
            format_func=lambda x: {
                "en": "ì˜ì–´", "ko": "í•œêµ­ì–´", "ja": "ì¼ë³¸ì–´",
                "zh": "ì¤‘êµ­ì–´", "de": "ë…ì¼ì–´", "fr": "í”„ë‘ìŠ¤ì–´",
                "es": "ìŠ¤í˜ì¸ì–´", "ru": "ëŸ¬ì‹œì•„ì–´"
            }.get(x, x),
            index=0
        )
    with col2:
        target_lang = st.selectbox(
            "ë²ˆì—­ ì–¸ì–´",
            options=["ko", "en", "ja", "zh", "de", "fr", "es", "ru"],
            format_func=lambda x: {
                "en": "ì˜ì–´", "ko": "í•œêµ­ì–´", "ja": "ì¼ë³¸ì–´",
                "zh": "ì¤‘êµ­ì–´", "de": "ë…ì¼ì–´", "fr": "í”„ë‘ìŠ¤ì–´",
                "es": "ìŠ¤í˜ì¸ì–´", "ru": "ëŸ¬ì‹œì•„ì–´"
            }.get(x, x),
            index=0
        )

    # ë²ˆì—­ ì˜µì…˜
    col1, col2 = st.columns(2)
    with col1:
        translate_text = st.checkbox("í…ìŠ¤íŠ¸ ë¸”ë¡ ë²ˆì—­", value=True,
                                    help="PDFì˜ í…ìŠ¤íŠ¸ ë¸”ë¡ì„ ì¶”ì¶œí•˜ì—¬ ë²ˆì—­í•©ë‹ˆë‹¤")
    with col2:
        translate_images = st.checkbox("ì´ë¯¸ì§€ OCR ë²ˆì—­", value=False,
                                      help="ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ OCRë¡œ ì¶”ì¶œí•˜ì—¬ ë²ˆì—­í•©ë‹ˆë‹¤ (Tesseract í•„ìš”)")

    st.divider()

    # PDF íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader(
        "PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
        type=["pdf"],
        help="ìµœëŒ€ 200MBê¹Œì§€ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤"
    )

    if uploaded_file is not None:
        # íŒŒì¼ ì •ë³´ í‘œì‹œ
        st.markdown(f"**íŒŒì¼ëª…:** {uploaded_file.name}")
        st.markdown(f"**íŒŒì¼ í¬ê¸°:** {uploaded_file.size / 1024 / 1024:.2f} MB")

        # PDF ì •ë³´ ë¯¸ë¦¬ë³´ê¸°
        pdf_bytes = uploaded_file.read()
        uploaded_file.seek(0)  # íŒŒì¼ í¬ì¸í„° ë¦¬ì…‹

        try:
            translator = PDFTranslator(get_openai_client()) if PDF_TRANSLATOR_AVAILABLE else None
            if translator:
                pdf_info = translator.get_pdf_info(pdf_bytes)
            else:
                st.error("PDF ë²ˆì—­ê¸°ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return

            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("í˜ì´ì§€ ìˆ˜", pdf_info['page_count'])
            with col2:
                st.metric("í…ìŠ¤íŠ¸ ë¸”ë¡", pdf_info['text_blocks_count'])
            with col3:
                st.metric("ì´ë¯¸ì§€ ìˆ˜", pdf_info['images_count'])

        except Exception as e:
            st.error(f"PDF ë¶„ì„ ì˜¤ë¥˜: {e}")
            return

        st.divider()

        # ë²ˆì—­ ì‹¤í–‰ ë²„íŠ¼
        if st.button("ğŸ”„ PDF ë²ˆì—­ ì‹œì‘", type="primary", use_container_width=True):
            if not openai_key:
                st.error("OpenAI API í‚¤ë¥¼ ë¨¼ì € ì„¤ì •í•´ì£¼ì„¸ìš”.")
                return

            # ì§„í–‰ ìƒíƒœ í‘œì‹œ
            progress_bar = st.progress(0)
            status_text = st.empty()

            def update_progress(progress, message="ì²˜ë¦¬ ì¤‘..."):
                progress_bar.progress(progress)
                status_text.text(message)

            try:
                with st.spinner("PDF ë²ˆì—­ ì¤‘..."):
                    # ë²ˆì—­ ì‹¤í–‰
                    translated_bytes = translate_pdf_file(
                        pdf_bytes,
                        openai_client=get_openai_client(),
                        source_lang=source_lang,
                        target_lang=target_lang,
                        translate_text=translate_text,
                        translate_images=translate_images,
                        progress_callback=update_progress
                    )

                progress_bar.progress(100)
                status_text.text("ë²ˆì—­ ì™„ë£Œ!")

                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                output_filename = f"translated_{uploaded_file.name}"
                st.success("PDF ë²ˆì—­ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

                st.download_button(
                    label="ğŸ“¥ ë²ˆì—­ëœ PDF ë‹¤ìš´ë¡œë“œ",
                    data=translated_bytes,
                    file_name=output_filename,
                    mime="application/pdf",
                    use_container_width=True
                )

                # ì„¸ì…˜ì— ê²°ê³¼ ì €ì¥
                st.session_state['translated_pdf'] = translated_bytes
                st.session_state['translated_pdf_name'] = output_filename

            except Exception as e:
                st.error(f"ë²ˆì—­ ì˜¤ë¥˜: {e}")
                logger.error(f"PDF ë²ˆì—­ ì‹¤íŒ¨: {e}")

    # ì´ì „ ë²ˆì—­ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ í‘œì‹œ
    if 'translated_pdf' in st.session_state and st.session_state.get('translated_pdf'):
        st.divider()
        st.markdown("### ì´ì „ ë²ˆì—­ ê²°ê³¼")
        st.download_button(
            label="ğŸ“¥ ë§ˆì§€ë§‰ ë²ˆì—­ëœ PDF ë‹¤ìš´ë¡œë“œ",
            data=st.session_state['translated_pdf'],
            file_name=st.session_state.get('translated_pdf_name', 'translated.pdf'),
            mime="application/pdf"
        )


# ===== ë©”ì¸ ì•± =====
def main():
    # í—¤ë”
    col1, col2 = st.columns([3, 1])
    with col1:
        st.title("âš–ï¸ AI ë²•ë¥  ë„ìš°ë¯¸ & PDF ë²ˆì—­")
        st.markdown("ë²•ë¥  ê²€ìƒ‰ + PDF ë¬¸ì„œ ë²ˆì—­ ì„œë¹„ìŠ¤")
    with col2:
        st.markdown("""
        <div style="text-align: right; padding: 1rem;">
            <small>v5.0 | GPT-5 + ë²•ì œì²˜ API ì „ì²´ ì—°ë™</small>
        </div>
        """, unsafe_allow_html=True)

    # ===== ì‚¬ì´ë“œë°” =====
    with st.sidebar:
        st.header("ğŸ”‘ API ì„¤ì •")

        # API í‚¤ ì…ë ¥ ì„¹ì…˜
        with st.expander("API í‚¤ ì…ë ¥", expanded=not st.session_state.api_keys_set):
            st.markdown("#### ë²•ì œì²˜ Open API")
            st.caption("https://open.law.go.kr ì—ì„œ ë°œê¸‰")
            law_api_input = st.text_input(
                "ë²•ì œì²˜ API í‚¤",
                value=st.session_state.law_api_key,
                type="password",
                key="law_api_input",
                placeholder="ë²•ì œì²˜ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
            )

            st.markdown("#### OpenAI API")
            st.caption("https://platform.openai.com ì—ì„œ ë°œê¸‰")
            openai_api_input = st.text_input(
                "OpenAI API í‚¤",
                value=st.session_state.openai_api_key,
                type="password",
                key="openai_api_input",
                placeholder="OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì„ íƒ)"
            )

            if st.button("API í‚¤ ì €ì¥", use_container_width=True):
                # OpenAI API í‚¤ í˜•ì‹ ê²€ì¦
                if openai_api_input and not openai_api_input.startswith('sk-'):
                    st.error("âš ï¸ OpenAI API í‚¤ëŠ” 'sk-'ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤. https://platform.openai.com ì—ì„œ ì˜¬ë°”ë¥¸ API í‚¤ë¥¼ ë³µì‚¬í•´ì£¼ì„¸ìš”.")
                else:
                    st.session_state.law_api_key = law_api_input
                    st.session_state.openai_api_key = openai_api_input
                    st.session_state.api_keys_set = True
                    st.success("API í‚¤ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.rerun()

        st.divider()

        # API ìƒíƒœ í‘œì‹œ
        st.header("ğŸ”Œ API ìƒíƒœ")
        law_key = get_law_api_key()
        openai_key = get_openai_api_key()

        if law_key:
            st.success("âœ… ë²•ì œì²˜ API ì—°ê²°ë¨")
        else:
            st.error("âŒ ë²•ì œì²˜ API í‚¤ í•„ìš”")
            st.caption("ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë²•ì œì²˜ API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

        if openai_key:
            if openai_key.startswith('sk-'):
                st.success("âœ… GPT-5.1 AI ì—”ì§„ í™œì„±í™”")
            else:
                st.error("âš ï¸ OpenAI API í‚¤ í˜•ì‹ ì˜¤ë¥˜ (sk-ë¡œ ì‹œì‘í•´ì•¼ í•¨)")
        else:
            st.warning("âš ï¸ OpenAI API ë¯¸ì„¤ì •")
            st.caption("AI ë¶„ì„ ì—†ì´ ê²€ìƒ‰ ê²°ê³¼ë§Œ í‘œì‹œë©ë‹ˆë‹¤.")

        st.divider()

        # ê²€ìƒ‰ ì˜µì…˜
        st.header("ğŸ” ê²€ìƒ‰ ì˜µì…˜")

        # ì—”ì§„ ì´ˆê¸°í™” (ì˜µì…˜ í‘œì‹œìš©)
        engine = LegalAIEngine()

        # ê¸°ë³¸ ë°ì´í„° ê²€ìƒ‰
        search_basic = st.checkbox("ğŸ“š ê¸°ë³¸ ë²•ë¥  ë°ì´í„°", value=True,
                                   help="ë²•ë ¹, íŒë¡€, í–‰ì •ê·œì¹™, ìì¹˜ë²•ê·œ, í—Œì¬ê²°ì •ë¡€, ë²•ë ¹í•´ì„ë¡€, í–‰ì •ì‹¬íŒë¡€, ì¡°ì•½")

        # ìœ„ì›íšŒ ê²°ì •ë¬¸ - ì „ì²´ ì„ íƒ ë°”ê¹¥ì— ë°°ì¹˜
        select_all_comm = st.checkbox("ğŸ¢ ìœ„ì›íšŒ ê²°ì •ë¬¸ (ì „ì²´)", key="select_all_comm",
                                      help="ê³µì •ê±°ë˜ìœ„, ë…¸ë™ìœ„, ê¸ˆìœµìœ„ ë“± 12ê°œ ìœ„ì›íšŒ")
        if not select_all_comm:
            with st.expander("ìœ„ì›íšŒ ê°œë³„ ì„ íƒ", expanded=False):
                col1, col2 = st.columns(2)
                committees_list = list(engine.committee_targets.items())
                half = len(committees_list) // 2
                with col1:
                    for key, info in committees_list[:half]:
                        st.checkbox(info['name'], key=f"comm_{key}")
                with col2:
                    for key, info in committees_list[half:]:
                        st.checkbox(info['name'], key=f"comm_{key}")

        # ë¶€ì²˜ë³„ ë²•ë ¹í•´ì„ - ì „ì²´ ì„ íƒ ë°”ê¹¥ì— ë°°ì¹˜
        select_all_ministry = st.checkbox("ğŸ›ï¸ ë¶€ì²˜ë³„ ë²•ë ¹í•´ì„ (ì „ì²´)", key="select_all_ministry",
                                          help="ê³ ìš©ë…¸ë™ë¶€, êµ­í† ë¶€, ë²•ì œì²˜ ë“± 30ê°œ ë¶€ì²˜")

        if not select_all_ministry:
            # ë¶€ì²˜ë³„ ë²•ë ¹í•´ì„ (ì£¼ìš”)
            major_ministries = [
                ('moelCgmExpc', 'ê³ ìš©ë…¸ë™ë¶€'),
                ('molitCgmExpc', 'êµ­í† êµí†µë¶€'),
                ('moisCgmExpc', 'í–‰ì •ì•ˆì „ë¶€'),
                ('mohwCgmExpc', 'ë³´ê±´ë³µì§€ë¶€'),
                ('molegCgmExpc', 'ë²•ì œì²˜'),
                ('mojCgmExpc', 'ë²•ë¬´ë¶€'),
            ]

            select_all_major_min = st.checkbox("  â”” ì£¼ìš” ë¶€ì²˜ (6ê°œ)", key="select_all_major_min")
            if not select_all_major_min:
                with st.expander("ì£¼ìš” ë¶€ì²˜ ê°œë³„ ì„ íƒ", expanded=False):
                    for key, name in major_ministries:
                        st.checkbox(name, key=f"min_{key}")

            # ë¶€ì²˜ë³„ ë²•ë ¹í•´ì„ (ê¸°íƒ€)
            other_ministries = [(k, v['name']) for k, v in engine.ministry_targets.items()
                               if k not in [m[0] for m in major_ministries]]

            select_all_other_min = st.checkbox("  â”” ê¸°íƒ€ ë¶€ì²˜", key="select_all_other_min")
            if not select_all_other_min:
                with st.expander("ê¸°íƒ€ ë¶€ì²˜ ê°œë³„ ì„ íƒ", expanded=False):
                    col1, col2 = st.columns(2)
                    for idx, (key, name) in enumerate(other_ministries):
                        with col1 if idx % 2 == 0 else col2:
                            st.checkbox(name, key=f"min_{key}")
        else:
            # ì „ì²´ ì„ íƒ ì‹œ major_ministries ë³€ìˆ˜ ì •ì˜ í•„ìš”
            major_ministries = [
                ('moelCgmExpc', 'ê³ ìš©ë…¸ë™ë¶€'),
                ('molitCgmExpc', 'êµ­í† êµí†µë¶€'),
                ('moisCgmExpc', 'í–‰ì •ì•ˆì „ë¶€'),
                ('mohwCgmExpc', 'ë³´ê±´ë³µì§€ë¶€'),
                ('molegCgmExpc', 'ë²•ì œì²˜'),
                ('mojCgmExpc', 'ë²•ë¬´ë¶€'),
            ]
            other_ministries = [(k, v['name']) for k, v in engine.ministry_targets.items()
                               if k not in [m[0] for m in major_ministries]]

        # íŠ¹ë³„í–‰ì •ì‹¬íŒë¡€
        search_special_tribunals = st.checkbox(
            "âš–ï¸ íŠ¹ë³„í–‰ì •ì‹¬íŒë¡€",
            value=False,
            help="ì¡°ì„¸ì‹¬íŒì›, í•´ì–‘ì•ˆì „ì‹¬íŒì›, êµ­ë¯¼ê¶Œìµìœ„ì›íšŒ, ì†Œì²­ì‹¬ì‚¬ìœ„ì›íšŒ"
        )

        st.divider()

        # ìƒˆ ëŒ€í™” ì‹œì‘ ë²„íŠ¼
        if st.button("ğŸ”„ ìƒˆ ê²€ìƒ‰ ì‹œì‘", use_container_width=True):
            st.session_state.chat_history = []
            st.session_state.search_results = None
            st.session_state.fact_sheet = {}
            st.rerun()

    # ===== ë©”ì¸ ì»¨í…ì¸  (íƒ­ ê¸°ë°˜) =====
    tab1, tab2 = st.tabs(["âš–ï¸ ë²•ë¥  ì—°êµ¬", "ğŸ“„ PDF ë²ˆì—­"])

    # ===== íƒ­ 1: ë²•ë¥  ì—°êµ¬ =====
    with tab1:
        # ì›°ì»´ ë©”ì‹œì§€
        if not st.session_state.chat_history:
            st.markdown("""
            <div class="chat-message assistant-message">
                <strong>âš–ï¸ AI ë³€í˜¸ì‚¬ (GPT-5):</strong><br>
                ì•ˆë…•í•˜ì„¸ìš”, AI ë³€í˜¸ì‚¬ì…ë‹ˆë‹¤.<br><br>

                <b>ğŸ” ê²€ìƒ‰ ê°€ëŠ¥í•œ ë²•ë¥  ë°ì´í„°:</b><br>
                â€¢ <b>ê¸°ë³¸:</b> ë²•ë ¹, íŒë¡€, í–‰ì •ê·œì¹™, ìì¹˜ë²•ê·œ, í—Œì¬ê²°ì •ë¡€, ë²•ë ¹í•´ì„ë¡€, í–‰ì •ì‹¬íŒë¡€, ì¡°ì•½<br>
                â€¢ <b>ìœ„ì›íšŒ ê²°ì •ë¬¸:</b> ê³µì •ê±°ë˜ìœ„ì›íšŒ, ë…¸ë™ìœ„ì›íšŒ, ê¸ˆìœµìœ„ì›íšŒ ë“± 12ê°œ ìœ„ì›íšŒ<br>
                â€¢ <b>ë¶€ì²˜ë³„ ë²•ë ¹í•´ì„:</b> ê³ ìš©ë…¸ë™ë¶€, êµ­í† êµí†µë¶€ ë“± 30ê°œ ì´ìƒ ë¶€ì²˜<br>
                â€¢ <b>íŠ¹ë³„í–‰ì •ì‹¬íŒ:</b> ì¡°ì„¸ì‹¬íŒì›, í•´ì–‘ì•ˆì „ì‹¬íŒì› ë“±<br><br>

                <b>ğŸ”¢ ì‚¬ê±´ë²ˆí˜¸/ì•ˆê±´ë²ˆí˜¸ ì§ì ‘ ê²€ìƒ‰:</b><br>
                â€¢ <b>íŒë¡€:</b> 2020ë‹¤12345, 2021êµ¬í•©12345 í˜•ì‹<br>
                â€¢ <b>ë²•ë ¹í•´ì„ë¡€:</b> 18-0701, 22-0123 í˜•ì‹<br>
                â€¢ <b>í–‰ì •ì‹¬íŒë¡€:</b> 2023-12345 í˜•ì‹<br><br>

                <b>ğŸ’¡ ì‚¬ìš© ë°©ë²•:</b><br>
                1. ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”<br>
                2. ê²€ìƒ‰í•  ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”<br>
                3. ì•„ë˜ ì…ë ¥ì°½ì— ê²€ìƒ‰ì–´ ë˜ëŠ” ì‚¬ê±´ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”<br><br>

                ì–´ë–¤ ë²•ë¥  ìë£Œë¥¼ ì°¾ì•„ë“œë¦´ê¹Œìš”?
            </div>
            """, unsafe_allow_html=True)
        else:
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ
            for msg in st.session_state.chat_history:
                display_chat_message(msg["role"], msg["content"])

        st.divider()

        # ì˜ˆì‹œ ê²€ìƒ‰ì–´
        st.markdown("### ğŸ’¡ ì˜ˆì‹œ ê²€ìƒ‰ì–´")
        col1, col2, col3, col4 = st.columns(4)

        examples = {
            "ë¶€ë‹¹í•´ê³  êµ¬ì œ": "ë¶€ë‹¹í•´ê³  êµ¬ì œ ì ˆì°¨ì™€ ê´€ë ¨ íŒë¡€",
            "ì„ëŒ€ì°¨ ë³´ì¦ê¸ˆ": "ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ë³´ì¦ê¸ˆ ë°˜í™˜",
            "ê°œì¸ì •ë³´ ì¹¨í•´": "ê°œì¸ì •ë³´ ì¹¨í•´ ì†í•´ë°°ìƒ",
            "18-0701": "18-0701"  # ë²•ë ¹í•´ì„ë¡€ ì•ˆê±´ë²ˆí˜¸ ì˜ˆì‹œ
        }

        clicked_example = None
        for idx, (btn_text, query) in enumerate(examples.items()):
            with [col1, col2, col3, col4][idx]:
                if st.button(btn_text, use_container_width=True, key=f"example_{idx}"):
                    clicked_example = query

        # ì‚¬ìš©ì ì…ë ¥
        user_input = st.text_area(
            "ê²€ìƒ‰ì–´ ì…ë ¥",
            value=clicked_example if clicked_example else "",
            placeholder="ì˜ˆ: ë¶€ë‹¹í•´ê³  êµ¬ì œ ì ˆì°¨, ì„ëŒ€ì°¨ ë³´ì¦ê¸ˆ ë°˜í™˜ íŒë¡€ ë“±",
            height=100,
            key="search_input"
        )

        col1, col2 = st.columns([3, 1])
        with col1:
            search_button = st.button("ğŸ” ë²•ë¥  ìë£Œ ê²€ìƒ‰", type="primary", use_container_width=True)
        with col2:
            if st.session_state.chat_history:
                if st.button("ğŸ“„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ"):
                    last_response = st.session_state.chat_history[-1]
                    if last_response["role"] == "assistant":
                        st.download_button(
                            label="ğŸ’¾ ë‹¤ìš´ë¡œë“œ",
                            data=last_response["content"],
                            file_name=f"ë²•ë¥ ì—°êµ¬_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                            mime="text/plain"
                        )

        # ê²€ìƒ‰ ì‹¤í–‰
        if search_button or clicked_example:
            query = user_input if user_input else clicked_example

            if not query:
                st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            elif not get_law_api_key():
                st.error("ë²•ì œì²˜ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                # ì„¸ì…˜ ìƒíƒœì—ì„œ ì„ íƒëœ ìœ„ì›íšŒ ìˆ˜ì§‘
                engine_for_options = LegalAIEngine()

                # ìœ„ì›íšŒ ì „ì²´ ì„ íƒ ì²´í¬ ì‹œ ëª¨ë“  ìœ„ì›íšŒ ì„ íƒ
                if st.session_state.get("select_all_comm", False):
                    selected_committees = list(engine_for_options.committee_targets.keys())
                else:
                    selected_committees = [
                        key for key in engine_for_options.committee_targets.keys()
                        if st.session_state.get(f"comm_{key}", False)
                    ]

                # ì„¸ì…˜ ìƒíƒœì—ì„œ ì„ íƒëœ ë¶€ì²˜ ìˆ˜ì§‘
                major_ministry_keys = ['moelCgmExpc', 'molitCgmExpc', 'moisCgmExpc',
                                       'mohwCgmExpc', 'molegCgmExpc', 'mojCgmExpc']
                other_ministry_keys = [k for k in engine_for_options.ministry_targets.keys()
                                       if k not in major_ministry_keys]

                selected_ministries = []

                # ë¶€ì²˜ ì „ì²´ ì„ íƒ ì²´í¬ ì‹œ ëª¨ë“  ë¶€ì²˜ ì„ íƒ
                if st.session_state.get("select_all_ministry", False):
                    selected_ministries = list(engine_for_options.ministry_targets.keys())
                else:
                    # ì£¼ìš” ë¶€ì²˜ ì „ì²´ ì„ íƒ ì²´í¬ ì‹œ
                    if st.session_state.get("select_all_major_min", False):
                        selected_ministries.extend(major_ministry_keys)
                    else:
                        selected_ministries.extend([
                            key for key in major_ministry_keys
                            if st.session_state.get(f"min_{key}", False)
                        ])

                    # ê¸°íƒ€ ë¶€ì²˜ ì „ì²´ ì„ íƒ ì²´í¬ ì‹œ
                    if st.session_state.get("select_all_other_min", False):
                        selected_ministries.extend(other_ministry_keys)
                    else:
                        selected_ministries.extend([
                            key for key in other_ministry_keys
                            if st.session_state.get(f"min_{key}", False)
                        ])

                # ê²€ìƒ‰ ì˜µì…˜ êµ¬ì„±
                search_options = {
                    'basic': search_basic,
                    'committees': selected_committees,
                    'ministries': selected_ministries,
                    'special_tribunals': search_special_tribunals
                }

                # ê²€ìƒ‰ ì‹¤í–‰
                legal_data, fact_sheet, advice, engine = asyncio.run(
                    process_search(query, search_options)
                )

                # ê²°ê³¼ ì €ì¥
                st.session_state.search_results = legal_data
                st.session_state.fact_sheet = fact_sheet

                # ì±„íŒ… íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                st.session_state.chat_history.append({
                    "role": "user",
                    "content": query,
                    "timestamp": datetime.now().isoformat()
                })

                st.session_state.chat_history.append({
                    "role": "assistant",
                    "content": advice,
                    "legal_data": legal_data,
                    "fact_sheet": fact_sheet,
                    "timestamp": datetime.now().isoformat()
                })

                st.rerun()

        # ê²€ìƒ‰ í†µê³„ í‘œì‹œ
        if st.session_state.fact_sheet:
            engine = LegalAIEngine()
            display_search_statistics(st.session_state.fact_sheet, engine)

    # ê²€ìƒ‰ ê²°ê³¼ ìƒì„¸ í‘œì‹œ (íŒë¡€, ìœ ê¶Œí•´ì„ ë“±)
    if st.session_state.search_results:
        engine = LegalAIEngine()
        st.markdown("---")
        st.markdown("## ğŸ“‘ ê²€ìƒ‰ëœ ë²•ë¥  ìë£Œ")
        # fact_sheetì—ì„œ ì¿¼ë¦¬ ê°€ì ¸ì˜¤ê¸°
        current_query = st.session_state.fact_sheet.get('query', '') if st.session_state.fact_sheet else ''
        display_search_results_detail(st.session_state.search_results, engine, query=current_query)

        # ë‹¤ìš´ë¡œë“œ ì„¹ì…˜ í‘œì‹œ
        display_download_section(st.session_state.search_results, engine)

    # ê²€ìƒ‰ í†µê³„ í‘œì‹œ
    if st.session_state.fact_sheet:
        engine = LegalAIEngine()
        display_search_statistics(st.session_state.fact_sheet, engine)

# ===== ì•± ì‹¤í–‰ =====
if __name__ == "__main__":
    main()
