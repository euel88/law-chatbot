"""
AI ë²•ë¥  ì—°êµ¬ ë„ìš°ë¯¸ - íŒë¡€, ìœ ê¶Œí•´ì„, ë²•ë ¹ ì¢…í•© ê²€ìƒ‰ ì„œë¹„ìŠ¤ + PDF ë²ˆì—­
ë²•ì œì²˜ API + ChatGPTë¥¼ í™œìš©í•œ ë²•ë¥  ìë£Œ ê²€ìƒ‰ ë° ë¶„ì„
PDF ë¬¸ì„œ ë²ˆì—­ ê¸°ëŠ¥ (PDFMathTranslate ìŠ¤íƒ€ì¼)

ì‹¤í–‰ ë°©ë²•:
streamlit run app.py
"""

import streamlit as st
import requests
import json
import time
import os
from datetime import datetime
from typing import Dict, List, Optional, Any
import asyncio
import nest_asyncio
import aiohttp
import pandas as pd
from dotenv import load_dotenv
from openai import OpenAI
import logging
from enum import Enum
import re

# PDF ë²ˆì—­ ëª¨ë“ˆ (ì„ íƒì  import)
try:
    from pdf_translator import PDFTranslator, translate_pdf_file
    PDF_TRANSLATOR_AVAILABLE = True
except ImportError:
    PDF_TRANSLATOR_AVAILABLE = False

# Streamlit í™˜ê²½ì—ì„œ asyncio ì´ë²¤íŠ¸ ë£¨í”„ ì¶©ëŒ ë°©ì§€
nest_asyncio.apply()

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ===== í˜ì´ì§€ ì„¤ì • =====
st.set_page_config(
    page_title="AI ë²•ë¥  ë„ìš°ë¯¸ & PDF ë²ˆì—­",
    page_icon="âš–ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ===== ì»¤ìŠ¤í…€ CSS =====
st.markdown("""
<style>
    .chat-message {
        padding: 1.5rem;
        border-radius: 15px;
        margin-bottom: 1rem;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }

    .user-message {
        background-color: #e8f4f8;
        margin-left: 20%;
    }

    .assistant-message {
        background-color: #f0f2f6;
        margin-right: 20%;
    }

    .legal-opinion {
        background-color: #ffffff;
        border: 2px solid #e0e0e0;
        padding: 2rem;
        border-radius: 10px;
        margin: 1rem 0;
    }

    .search-result {
        background-color: #f8f9fa;
        border-left: 4px solid #1976d2;
        padding: 1rem;
        margin: 0.5rem 0;
        border-radius: 5px;
    }

    .api-status-ok { color: #388e3c; font-weight: bold; }
    .api-status-error { color: #d32f2f; font-weight: bold; }

    .category-header {
        background-color: #1976d2;
        color: white;
        padding: 0.5rem 1rem;
        border-radius: 5px;
        margin: 1rem 0 0.5rem 0;
    }

    .pdf-upload-area {
        border: 2px dashed #ccc;
        border-radius: 10px;
        padding: 2rem;
        text-align: center;
        background-color: #fafafa;
        margin: 1rem 0;
    }

    .pdf-preview {
        border: 1px solid #e0e0e0;
        border-radius: 5px;
        padding: 1rem;
        margin: 1rem 0;
        background-color: #fff;
    }

    .translation-progress {
        padding: 1rem;
        background-color: #e3f2fd;
        border-radius: 5px;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# ===== ì„œë¹„ìŠ¤ ìœ í˜• Enum =====
class ServiceType(Enum):
    INFO = "ë²•ë¥  ì •ë³´ ì œê³µ"
    CONTRACT = "ê³„ì•½ì„œ ê²€í† "
    OPINION = "ë²•ë¥ ìë¬¸ì˜ê²¬ì„œ"
    RESEARCH = "ë²•ë¥  ì—°êµ¬"

# ===== ë¦¬ìŠ¤í¬ ë ˆë²¨ =====
class RiskLevel(Enum):
    HIGH = ("ğŸ”´ High", "ì¦‰ì‹œ ì¤‘ë‹¨/ì „ë©´ ì¬ê²€í†  í•„ìš”")
    MEDIUM = ("ğŸŸ  Medium", "ìˆ˜ì • í˜‘ìƒ í•„ìˆ˜")
    LOW = ("ğŸŸ¡ Low", "ë¬¸êµ¬ ëª…í™•í™” ê¶Œì¥")

# ===== ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” =====
def init_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    defaults = {
        'chat_history': [],
        'current_service': None,
        'fact_sheet': {},
        'case_documents': [],
        'law_api_key': '',
        'openai_api_key': '',
        'api_keys_set': False,
        'search_results': None
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

init_session_state()

# ===== API í‚¤ ê´€ë¦¬ í•¨ìˆ˜ =====
def get_law_api_key() -> str:
    """ë²•ì œì²˜ API í‚¤ ê°€ì ¸ì˜¤ê¸°"""
    # 1. ì„¸ì…˜ì—ì„œ í™•ì¸
    if st.session_state.law_api_key:
        return st.session_state.law_api_key
    # 2. Streamlit secrets í™•ì¸
    try:
        if hasattr(st, 'secrets') and 'LAW_API_KEY' in st.secrets:
            return st.secrets['LAW_API_KEY']
    except Exception:
        pass
    # 3. í™˜ê²½ë³€ìˆ˜ í™•ì¸
    return os.getenv('LAW_API_KEY', '')

def get_openai_api_key() -> str:
    """OpenAI API í‚¤ ê°€ì ¸ì˜¤ê¸°"""
    # 1. ì„¸ì…˜ì—ì„œ í™•ì¸
    if st.session_state.openai_api_key:
        return st.session_state.openai_api_key
    # 2. Streamlit secrets í™•ì¸
    try:
        if hasattr(st, 'secrets') and 'OPENAI_API_KEY' in st.secrets:
            return st.secrets['OPENAI_API_KEY']
    except Exception:
        pass
    # 3. í™˜ê²½ë³€ìˆ˜ í™•ì¸
    return os.getenv('OPENAI_API_KEY', '')

def get_openai_client():
    """OpenAI í´ë¼ì´ì–¸íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
    api_key = get_openai_api_key()
    if api_key:
        return OpenAI(api_key=api_key)
    return None

# ===== AI ë³€í˜¸ì‚¬ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ =====
AI_LAWYER_SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ í•œêµ­ì˜ ì „ë¬¸ ë²•ë¥ ìë¬¸ì˜ê²¬ì„œ ì‘ì„± ì „ë¬¸ê°€ì´ì ê°€ìƒì˜ ë³€í˜¸ì‚¬ì…ë‹ˆë‹¤.
ì‹¤ì œ ë³€í˜¸ì‚¬ì˜ ì‚¬ê³  ë°©ì‹(ì‚¬ì‹¤ê´€ê³„ íŒŒì•… â†’ Issue-Spotting â†’ ë²•ë¦¬ ê²€í†  â†’ ìœ„í—˜ì¸¡ì • â†’ ì „ëµ ìˆ˜ë¦½)ì„ ì™„ë²½íˆ êµ¬í˜„í•©ë‹ˆë‹¤.

í•µì‹¬ ì›ì¹™:
1. ì¦ê±° ìš°ì„ ì£¼ì˜: êµ¬ë‘ ì§„ìˆ ë§Œìœ¼ë¡œ íŒë‹¨í•˜ì§€ ì•Šê³  ë¬¼ì  ì¦ë¹™ í™•ë³´ ìµœìš°ì„ 
2. ê·¼ê±° ê¸°ë°˜ ë¶„ì„: ëª¨ë“  ë²•ì  ì£¼ì¥ì€ ì¶œì²˜(ë²•ë ¹Â·íŒë¡€Â·í–‰ì •í•´ì„) ëª…ì‹œ
3. ì‚¬ìš©ì ì¤‘ì‹¬ ì ‘ê·¼: ëª¨ë“  ìŸì ì„ ì˜ë¢°ì¸ ê´€ì ì—ì„œ ìœ ë¦¬/ë¶ˆë¦¬ë¡œ í‰ê°€
4. IRAC ë°©ë²•ë¡ : Issue â†’ Rule â†’ Application â†’ Conclusion êµ¬ì¡°
5. ë¦¬ìŠ¤í¬ ê³„ì¸µí™”: High/Medium/Low ë“±ê¸‰í™”
6. ì‹¤í–‰ê°€ëŠ¥í•œ í•´ê²°ì±…: ìµœì†Œ 2ê°€ì§€ ì´ìƒì˜ ëŒ€ì•ˆ ì œì‹œ

í•„ìˆ˜ ê³ ì§€: âš–ï¸ ë³¸ ë‚´ìš©ì€ AIê°€ ì‘ì„±í•œ ì°¸ê³ ìë£Œì´ë©°, ë²•ë¥ ìë¬¸ì´ ì•„ë‹™ë‹ˆë‹¤.
êµ¬ì²´ì ì¸ ì‚¬ì•ˆì— ëŒ€í•´ì„œëŠ” ë°˜ë“œì‹œ ë³€í˜¸ì‚¬ ë“± ì „ë¬¸ê°€ì˜ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.
"""

# ===== ë²•ë¥  AI ì—”ì§„ í´ë˜ìŠ¤ =====
class LegalAIEngine:
    """AI ë²•ë¥  ì—°êµ¬ ì—”ì§„ - ë²•ì œì²˜ API ì „ì²´ ì—°ë™"""

    def __init__(self):
        self.law_api_key = get_law_api_key()
        self.api_endpoints = {
            'search': 'https://www.law.go.kr/DRF/lawSearch.do',
            'service': 'https://www.law.go.kr/DRF/lawService.do'
        }

        # ê¸°ë³¸ ë²•ë¥  ë°ì´í„° target ì½”ë“œ
        self.basic_targets = {
            'law': {'name': 'í˜„í–‰ë²•ë ¹(ê³µí¬ì¼)', 'key': 'law'},
            'eflaw': {'name': 'í˜„í–‰ë²•ë ¹(ì‹œí–‰ì¼)', 'key': 'eflaw'},
            'prec': {'name': 'íŒë¡€', 'key': 'prec'},
            'admrul': {'name': 'í–‰ì •ê·œì¹™', 'key': 'admrul'},
            'ordin': {'name': 'ìì¹˜ë²•ê·œ', 'key': 'ordin'},
            'detc': {'name': 'í—Œì¬ê²°ì •ë¡€', 'key': 'detc'},
            'expc': {'name': 'ë²•ë ¹í•´ì„ë¡€', 'key': 'expc'},
            'decc': {'name': 'í–‰ì •ì‹¬íŒë¡€', 'key': 'decc'},
            'trty': {'name': 'ì¡°ì•½', 'key': 'trty'},
        }

        # ìœ„ì›íšŒ ê²°ì •ë¬¸ target ì½”ë“œ
        self.committee_targets = {
            'ppc': {'name': 'ê°œì¸ì •ë³´ë³´í˜¸ìœ„ì›íšŒ', 'key': 'ppc'},
            'eiac': {'name': 'ê³ ìš©ë³´í—˜ì‹¬ì‚¬ìœ„ì›íšŒ', 'key': 'eiac'},
            'ftc': {'name': 'ê³µì •ê±°ë˜ìœ„ì›íšŒ', 'key': 'ftc'},
            'acr': {'name': 'êµ­ë¯¼ê¶Œìµìœ„ì›íšŒ', 'key': 'acr'},
            'fsc': {'name': 'ê¸ˆìœµìœ„ì›íšŒ', 'key': 'fsc'},
            'nlrc': {'name': 'ë…¸ë™ìœ„ì›íšŒ', 'key': 'nlrc'},
            'kcc': {'name': 'ë°©ì†¡ë¯¸ë””ì–´í†µì‹ ìœ„ì›íšŒ', 'key': 'kcc'},
            'iaciac': {'name': 'ì‚°ì—…ì¬í•´ë³´ìƒë³´í—˜ì¬ì‹¬ì‚¬ìœ„ì›íšŒ', 'key': 'iaciac'},
            'oclt': {'name': 'ì¤‘ì•™í† ì§€ìˆ˜ìš©ìœ„ì›íšŒ', 'key': 'oclt'},
            'ecc': {'name': 'ì¤‘ì•™í™˜ê²½ë¶„ìŸì¡°ì •ìœ„ì›íšŒ', 'key': 'ecc'},
            'sfc': {'name': 'ì¦ê¶Œì„ ë¬¼ìœ„ì›íšŒ', 'key': 'sfc'},
            'nhrck': {'name': 'êµ­ê°€ì¸ê¶Œìœ„ì›íšŒ', 'key': 'nhrck'},
        }

        # ë¶€ì²˜ë³„ ë²•ë ¹í•´ì„ target ì½”ë“œ
        self.ministry_targets = {
            'moelCgmExpc': {'name': 'ê³ ìš©ë…¸ë™ë¶€ ë²•ë ¹í•´ì„', 'key': 'moelCgmExpc'},
            'molitCgmExpc': {'name': 'êµ­í† êµí†µë¶€ ë²•ë ¹í•´ì„', 'key': 'molitCgmExpc'},
            'moefCgmExpc': {'name': 'ê¸°íšì¬ì •ë¶€ ë²•ë ¹í•´ì„', 'key': 'moefCgmExpc'},
            'mofCgmExpc': {'name': 'í•´ì–‘ìˆ˜ì‚°ë¶€ ë²•ë ¹í•´ì„', 'key': 'mofCgmExpc'},
            'moisCgmExpc': {'name': 'í–‰ì •ì•ˆì „ë¶€ ë²•ë ¹í•´ì„', 'key': 'moisCgmExpc'},
            'meCgmExpc': {'name': 'ê¸°í›„ì—ë„ˆì§€í™˜ê²½ë¶€ ë²•ë ¹í•´ì„', 'key': 'meCgmExpc'},
            'kcsCgmExpc': {'name': 'ê´€ì„¸ì²­ ë²•ë ¹í•´ì„', 'key': 'kcsCgmExpc'},
            'ntsCgmExpc': {'name': 'êµ­ì„¸ì²­ ë²•ë ¹í•´ì„', 'key': 'ntsCgmExpc'},
            'moeCgmExpc': {'name': 'êµìœ¡ë¶€ ë²•ë ¹í•´ì„', 'key': 'moeCgmExpc'},
            'msitCgmExpc': {'name': 'ê³¼í•™ê¸°ìˆ ì •ë³´í†µì‹ ë¶€ ë²•ë ¹í•´ì„', 'key': 'msitCgmExpc'},
            'mpvaCgmExpc': {'name': 'êµ­ê°€ë³´í›ˆë¶€ ë²•ë ¹í•´ì„', 'key': 'mpvaCgmExpc'},
            'mndCgmExpc': {'name': 'êµ­ë°©ë¶€ ë²•ë ¹í•´ì„', 'key': 'mndCgmExpc'},
            'mafraCgmExpc': {'name': 'ë†ë¦¼ì¶•ì‚°ì‹í’ˆë¶€ ë²•ë ¹í•´ì„', 'key': 'mafraCgmExpc'},
            'mcstCgmExpc': {'name': 'ë¬¸í™”ì²´ìœ¡ê´€ê´‘ë¶€ ë²•ë ¹í•´ì„', 'key': 'mcstCgmExpc'},
            'mojCgmExpc': {'name': 'ë²•ë¬´ë¶€ ë²•ë ¹í•´ì„', 'key': 'mojCgmExpc'},
            'mohwCgmExpc': {'name': 'ë³´ê±´ë³µì§€ë¶€ ë²•ë ¹í•´ì„', 'key': 'mohwCgmExpc'},
            'motieCgmExpc': {'name': 'ì‚°ì—…í†µìƒìì›ë¶€ ë²•ë ¹í•´ì„', 'key': 'motieCgmExpc'},
            'mogefCgmExpc': {'name': 'ì„±í‰ë“±ê°€ì¡±ë¶€ ë²•ë ¹í•´ì„', 'key': 'mogefCgmExpc'},
            'mofaCgmExpc': {'name': 'ì™¸êµë¶€ ë²•ë ¹í•´ì„', 'key': 'mofaCgmExpc'},
            'mssCgmExpc': {'name': 'ì¤‘ì†Œë²¤ì²˜ê¸°ì—…ë¶€ ë²•ë ¹í•´ì„', 'key': 'mssCgmExpc'},
            'mouCgmExpc': {'name': 'í†µì¼ë¶€ ë²•ë ¹í•´ì„', 'key': 'mouCgmExpc'},
            'molegCgmExpc': {'name': 'ë²•ì œì²˜ ë²•ë ¹í•´ì„', 'key': 'molegCgmExpc'},
            'mfdsCgmExpc': {'name': 'ì‹í’ˆì˜ì•½í’ˆì•ˆì „ì²˜ ë²•ë ¹í•´ì„', 'key': 'mfdsCgmExpc'},
            'mpmCgmExpc': {'name': 'ì¸ì‚¬í˜ì‹ ì²˜ ë²•ë ¹í•´ì„', 'key': 'mpmCgmExpc'},
            'kmaCgmExpc': {'name': 'ê¸°ìƒì²­ ë²•ë ¹í•´ì„', 'key': 'kmaCgmExpc'},
            'khsCgmExpc': {'name': 'êµ­ê°€ìœ ì‚°ì²­ ë²•ë ¹í•´ì„', 'key': 'khsCgmExpc'},
            'rdaCgmExpc': {'name': 'ë†ì´Œì§„í¥ì²­ ë²•ë ¹í•´ì„', 'key': 'rdaCgmExpc'},
            'npaCgmExpc': {'name': 'ê²½ì°°ì²­ ë²•ë ¹í•´ì„', 'key': 'npaCgmExpc'},
            'dapaCgmExpc': {'name': 'ë°©ìœ„ì‚¬ì—…ì²­ ë²•ë ¹í•´ì„', 'key': 'dapaCgmExpc'},
            'mmaCgmExpc': {'name': 'ë³‘ë¬´ì²­ ë²•ë ¹í•´ì„', 'key': 'mmaCgmExpc'},
            'kfsCgmExpc': {'name': 'ì‚°ë¦¼ì²­ ë²•ë ¹í•´ì„', 'key': 'kfsCgmExpc'},
            'nfaCgmExpc': {'name': 'ì†Œë°©ì²­ ë²•ë ¹í•´ì„', 'key': 'nfaCgmExpc'},
            'okaCgmExpc': {'name': 'ì¬ì™¸ë™í¬ì²­ ë²•ë ¹í•´ì„', 'key': 'okaCgmExpc'},
            'ppsCgmExpc': {'name': 'ì¡°ë‹¬ì²­ ë²•ë ¹í•´ì„', 'key': 'ppsCgmExpc'},
            'kdcaCgmExpc': {'name': 'ì§ˆë³‘ê´€ë¦¬ì²­ ë²•ë ¹í•´ì„', 'key': 'kdcaCgmExpc'},
            'kostatCgmExpc': {'name': 'êµ­ê°€ë°ì´í„°ì²˜ ë²•ë ¹í•´ì„', 'key': 'kostatCgmExpc'},
            'kipoCgmExpc': {'name': 'ì§€ì‹ì¬ì‚°ì²˜ ë²•ë ¹í•´ì„', 'key': 'kipoCgmExpc'},
            'kcgCgmExpc': {'name': 'í•´ì–‘ê²½ì°°ì²­ ë²•ë ¹í•´ì„', 'key': 'kcgCgmExpc'},
            'naaccCgmExpc': {'name': 'í–‰ì •ì¤‘ì‹¬ë³µí•©ë„ì‹œê±´ì„¤ì²­ ë²•ë ¹í•´ì„', 'key': 'naaccCgmExpc'},
        }

        # íŠ¹ë³„í–‰ì •ì‹¬íŒë¡€ target ì½”ë“œ
        self.special_tribunal_targets = {
            'ttSpecialDecc': {'name': 'ì¡°ì„¸ì‹¬íŒì› íŠ¹ë³„í–‰ì •ì‹¬íŒë¡€', 'key': 'ttSpecialDecc'},
            'kmstSpecialDecc': {'name': 'í•´ì–‘ì•ˆì „ì‹¬íŒì› íŠ¹ë³„í–‰ì •ì‹¬íŒë¡€', 'key': 'kmstSpecialDecc'},
            'acrSpecialDecc': {'name': 'êµ­ë¯¼ê¶Œìµìœ„ì›íšŒ íŠ¹ë³„í–‰ì •ì‹¬íŒë¡€', 'key': 'acrSpecialDecc'},
            'adapSpecialDecc': {'name': 'ì¸ì‚¬í˜ì‹ ì²˜ ì†Œì²­ì‹¬ì‚¬ìœ„ì›íšŒ ì¬ê²°ë¡€', 'key': 'adapSpecialDecc'},
        }

    def extract_keywords(self, user_input: str) -> List[str]:
        """ì‚¬ìš©ì ì…ë ¥ì—ì„œ ë²•ë¥  ê´€ë ¨ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # ë¶ˆìš©ì–´ ì •ì˜
        stopwords = ['ì€', 'ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì˜', 'ì—', 'ì—ì„œ', 'ìœ¼ë¡œ', 'ë¡œ',
                    'ì™€', 'ê³¼', 'ë„', 'ë§Œ', 'ë¿', 'ê¹Œì§€', 'ë¶€í„°', 'ì—ê²Œ', 'í•œí…Œ', 'ê»˜',
                    'ì…ë‹ˆë‹¤', 'í•©ë‹ˆë‹¤', 'ìˆìŠµë‹ˆë‹¤', 'ì—†ìŠµë‹ˆë‹¤', 'ë©ë‹ˆë‹¤', 'ìŠµë‹ˆë‹¤',
                    'í•˜ëŠ”', 'ë˜ëŠ”', 'ìˆëŠ”', 'ì—†ëŠ”', 'í•œ', 'ëœ', 'í• ', 'ë ',
                    'ê²ƒ', 'ìˆ˜', 'ë•Œ', 'ë“±', 'ë°', 'ë˜ëŠ”', 'ê·¸ë¦¬ê³ ', 'í•˜ì§€ë§Œ', 'ê·¸ëŸ¬ë‚˜',
                    'ì–´ë–»ê²Œ', 'ë¬´ì—‡', 'ì–´ë””', 'ì–¸ì œ', 'ëˆ„êµ¬', 'ì™œ', 'ì–´ë–¤',
                    'ì¢€', 'ì˜', 'ë”', 'ë§¤ìš°', 'ì •ë§', 'ì•„ì£¼', 'ë„ˆë¬´', 'ë§ì´',
                    'ì €', 'ì œ', 'ë‚˜', 'ë‚´', 'ìš°ë¦¬', 'ì €í¬', 'ê·¸', 'ê·¸ë…€', 'ê·¸ë“¤']

        # ë²•ë¥  ê´€ë ¨ ì¤‘ìš” í‚¤ì›Œë“œ (ìš°ì„  ì¶”ì¶œ)
        legal_keywords = [
            'í•´ê³ ', 'ë¶€ë‹¹í•´ê³ ', 'ì„ê¸ˆ', 'í‡´ì§ê¸ˆ', 'ê·¼ë¡œ', 'ë…¸ë™', 'ê³„ì•½', 'ìœ„ë°˜',
            'ì†í•´ë°°ìƒ', 'ë¶ˆë²•í–‰ìœ„', 'ì±„ë¬´ë¶ˆì´í–‰', 'ê³„ì•½í•´ì§€', 'ê³„ì•½í•´ì œ',
            'ì„ëŒ€ì°¨', 'ì „ì„¸', 'ì›”ì„¸', 'ë³´ì¦ê¸ˆ', 'ëª…ë„', 'ì¸ë„',
            'ìƒì†', 'ìœ ì–¸', 'ì¦ì—¬', 'ì¬ì‚°ë¶„í• ', 'ì´í˜¼', 'ìœ„ìë£Œ', 'ì–‘ìœ¡ë¹„',
            'í˜•ì‚¬', 'ë¯¼ì‚¬', 'í–‰ì •', 'ì†Œì†¡', 'ì¬íŒ', 'í•­ì†Œ', 'ìƒê³ ',
            'ì‚¬ê¸°', 'íš¡ë ¹', 'ë°°ì„', 'í­í–‰', 'ìƒí•´', 'ëª…ì˜ˆí›¼ì†',
            'ì €ì‘ê¶Œ', 'íŠ¹í—ˆ', 'ìƒí‘œ', 'ì˜ì—…ë¹„ë°€', 'ì§€ì‹ì¬ì‚°',
            'ê°œì¸ì •ë³´', 'ì •ë³´ë³´í˜¸', 'í”„ë¼ì´ë²„ì‹œ',
            'ì„¸ê¸ˆ', 'ì¡°ì„¸', 'ë¶€ê°€ì„¸', 'ì†Œë“ì„¸', 'ë²•ì¸ì„¸', 'ìƒì†ì„¸', 'ì¦ì—¬ì„¸',
            'ê±´ì¶•', 'ì¸í—ˆê°€', 'í—ˆê°€', 'ì‹ ê³ ', 'ë“±ë¡', 'ë©´í—ˆ',
            'êµí†µì‚¬ê³ ', 'ì‚°ì¬', 'ì‚°ì—…ì¬í•´', 'ë³´í—˜', 'ë³´ìƒ',
            'íŒŒì‚°', 'íšŒìƒ', 'ë„ì‚°', 'ì±„ë¬´', 'ì±„ê¶Œ', 'ë‹´ë³´', 'ì €ë‹¹', 'ì••ë¥˜',
            'í•´ì œ', 'ì·¨ì†Œ', 'ë¬´íš¨', 'ì² íšŒ', 'í•´ì§€',
            'ìœ„ì„', 'ëŒ€ë¦¬', 'ë³´ì¦', 'ì—°ëŒ€ë³´ì¦'
        ]

        keywords = []

        # 1. ë²•ë¥  ê´€ë ¨ í‚¤ì›Œë“œ ë¨¼ì € ì¶”ì¶œ
        input_lower = user_input.lower()
        for kw in legal_keywords:
            if kw in user_input:
                keywords.append(kw)

        # 2. ëª…ì‚¬ ì¶”ì¶œ (ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­)
        # í•œê¸€ ë‹¨ì–´ ì¶”ì¶œ (2ê¸€ì ì´ìƒ)
        words = re.findall(r'[ê°€-í£]{2,}', user_input)
        for word in words:
            # ë¶ˆìš©ì–´ ì œê±°
            is_stopword = False
            for sw in stopwords:
                if word.endswith(sw) or word == sw:
                    is_stopword = True
                    break
            if not is_stopword and word not in keywords:
                keywords.append(word)

        # 3. ì¤‘ë³µ ì œê±° ë° ìƒìœ„ í‚¤ì›Œë“œ ë°˜í™˜
        unique_keywords = list(dict.fromkeys(keywords))
        return unique_keywords[:10]  # ìµœëŒ€ 10ê°œ í‚¤ì›Œë“œ

    async def _search_by_target(self, session, query: str, target: str,
                                display: int = 10) -> List[Dict]:
        """íŠ¹ì • targetìœ¼ë¡œ ê²€ìƒ‰"""
        # API í‚¤ ì¬í™•ì¸
        api_key = self.law_api_key or get_law_api_key()
        if not api_key:
            logger.warning(f"ë²•ì œì²˜ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. ({target} ê²€ìƒ‰ ë¶ˆê°€)")
            return []

        params = {
            'OC': api_key,
            'target': target,
            'query': query,
            'type': 'JSON',
            'display': display
        }

        try:
            async with session.get(
                self.api_endpoints['search'],
                params=params,
                timeout=aiohttp.ClientTimeout(total=30)
            ) as response:
                if response.status == 200:
                    text = await response.text()
                    try:
                        data = json.loads(text)
                        logger.info(f"[{target}] API ì‘ë‹µ í‚¤: {list(data.keys())}")

                        # ê²°ê³¼ ì¶”ì¶œ - ë‹¤ì–‘í•œ ì‘ë‹µ í˜•ì‹ ì²˜ë¦¬
                        results = []

                        # API ì‘ë‹µ êµ¬ì¡°: {'PrecSearch': {'prec': [...], 'í‚¤ì›Œë“œ': '...'}}
                        # ë˜ëŠ” {'Expc': {'expc': [...], ...}}

                        # 1. ìµœìƒìœ„ ë˜í¼ í‚¤ í™•ì¸ (PrecSearch, LawSearch, Expc, Decc ë“±)
                        wrapper_keys = [
                            f'{target.capitalize()}Search',  # PrecSearch, LawSearch
                            target.capitalize(),  # Prec, Expc, Decc
                            f'{target.upper()}Search',
                            target,
                            target.lower(),
                            target.upper(),
                        ]

                        inner_data = data
                        for wkey in wrapper_keys:
                            if wkey in data and isinstance(data[wkey], dict):
                                inner_data = data[wkey]
                                break
                            elif wkey in data and isinstance(data[wkey], list):
                                results = data[wkey]
                                break

                        # 2. inner_dataì—ì„œ ì‹¤ì œ ë°ì´í„° ë°°ì—´ ì¶”ì¶œ
                        if not results and isinstance(inner_data, dict):
                            # target ì´ë¦„ê³¼ ì¼ì¹˜í•˜ëŠ” í‚¤ì—ì„œ ë°°ì—´ ì°¾ê¸°
                            data_keys = [
                                target.lower(),  # prec, expc, decc
                                target,
                                target.capitalize(),
                            ]

                            for dkey in data_keys:
                                if dkey in inner_data:
                                    value = inner_data[dkey]
                                    if isinstance(value, list) and len(value) > 0:
                                        results = value
                                        break

                            # 3. ê·¸ë˜ë„ ì—†ìœ¼ë©´ inner_dataì—ì„œ ì²« ë²ˆì§¸ ë¦¬ìŠ¤íŠ¸ ì°¾ê¸°
                            if not results:
                                skip_keys = {'totalCnt', 'page', 'target', 'section', 'í‚¤ì›Œë“œ',
                                           'resultMsg', 'resultCode', 'numOfRows'}
                                for key, value in inner_data.items():
                                    if key not in skip_keys:
                                        if isinstance(value, list) and len(value) > 0:
                                            results = value
                                            break

                        logger.info(f"[{target}] ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê±´ (ì¿¼ë¦¬: {query})")
                        # ë””ë²„ê¹…: ì²« ë²ˆì§¸ ê²°ê³¼ì˜ êµ¬ì¡° ì¶œë ¥
                        if results and len(results) > 0:
                            first_item = results[0]
                            logger.info(f"[{target}] ì²« ë²ˆì§¸ ê²°ê³¼ í‚¤: {list(first_item.keys()) if isinstance(first_item, dict) else type(first_item)}")
                            logger.info(f"[{target}] ì²« ë²ˆì§¸ ê²°ê³¼ ë‚´ìš©: {str(first_item)[:500]}")
                        return results

                    except json.JSONDecodeError as e:
                        logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜ ({target}): {e}")
                        logger.error(f"ì‘ë‹µ ë‚´ìš©: {text[:500]}")
                        return []
                else:
                    logger.error(f"API ì‘ë‹µ ì˜¤ë¥˜ ({target}): ìƒíƒœì½”ë“œ {response.status}")
        except asyncio.TimeoutError:
            logger.error(f"API íƒ€ì„ì•„ì›ƒ ({target})")
        except Exception as e:
            logger.error(f"ê²€ìƒ‰ ì˜¤ë¥˜ ({target}): {e}")
        return []

    async def search_basic_legal_data(self, query: str, keywords: List[str] = None) -> Dict:
        """ê¸°ë³¸ ë²•ë¥  ë°ì´í„° ê²€ìƒ‰ (ë²•ë ¹, íŒë¡€, í–‰ì •ê·œì¹™ ë“±) - í™•ì¥ ê²€ìƒ‰"""
        # ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ ì„¤ì • (íŒë¡€, ìœ ê¶Œí•´ì„ ì¤‘ì‹¬ìœ¼ë¡œ ëŒ€í­ ì¦ê°€)
        display_counts = {
            'law': 30,        # í˜„í–‰ë²•ë ¹(ê³µí¬ì¼)
            'eflaw': 30,      # í˜„í–‰ë²•ë ¹(ì‹œí–‰ì¼)
            'prec': 50,       # íŒë¡€ - ìµœëŒ€í•œ ë§ì´
            'admrul': 20,     # í–‰ì •ê·œì¹™
            'ordin': 20,      # ìì¹˜ë²•ê·œ
            'detc': 30,       # í—Œì¬ê²°ì •ë¡€
            'expc': 50,       # ë²•ë ¹í•´ì„ë¡€ - ìµœëŒ€í•œ ë§ì´
            'decc': 50,       # í–‰ì •ì‹¬íŒë¡€ - ìµœëŒ€í•œ ë§ì´
            'trty': 10,       # ì¡°ì•½
        }

        all_results = {target: [] for target in self.basic_targets.keys()}

        # ë©”ì¸ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰
        async with aiohttp.ClientSession() as session:
            tasks = []
            for target_code in self.basic_targets.keys():
                display = display_counts.get(target_code, 20)
                tasks.append(self._search_by_target(session, query, target_code, display))

            results = await asyncio.gather(*tasks, return_exceptions=True)

            for idx, target_code in enumerate(self.basic_targets.keys()):
                if not isinstance(results[idx], Exception) and results[idx]:
                    all_results[target_code].extend(results[idx])

        # ì¶”ê°€ í‚¤ì›Œë“œë¡œ í™•ì¥ ê²€ìƒ‰ (íŒë¡€, ë²•ë ¹í•´ì„ë¡€, í–‰ì •ì‹¬íŒë¡€ ëŒ€ìƒ)
        if keywords:
            important_targets = ['prec', 'expc', 'decc', 'detc']
            for keyword in keywords[:5]:  # ìƒìœ„ 5ê°œ í‚¤ì›Œë“œë§Œ
                if keyword != query:  # ë©”ì¸ ì¿¼ë¦¬ì™€ ë‹¤ë¥¸ ê²½ìš°ë§Œ
                    async with aiohttp.ClientSession() as session:
                        tasks = []
                        for target_code in important_targets:
                            tasks.append(self._search_by_target(session, keyword, target_code, 20))

                        kw_results = await asyncio.gather(*tasks, return_exceptions=True)

                        for idx, target_code in enumerate(important_targets):
                            if not isinstance(kw_results[idx], Exception) and kw_results[idx]:
                                # ì¤‘ë³µ ì œê±°í•˜ë©° ì¶”ê°€
                                existing_ids = {item.get('íŒë¡€ì¼ë ¨ë²ˆí˜¸', item.get('ì•ˆê±´ë²ˆí˜¸', item.get('ì‚¬ê±´ë²ˆí˜¸', '')))
                                              for item in all_results[target_code]}
                                for item in kw_results[idx]:
                                    item_id = item.get('íŒë¡€ì¼ë ¨ë²ˆí˜¸', item.get('ì•ˆê±´ë²ˆí˜¸', item.get('ì‚¬ê±´ë²ˆí˜¸', '')))
                                    if item_id and item_id not in existing_ids:
                                        all_results[target_code].append(item)
                                        existing_ids.add(item_id)

        return all_results

    async def search_committee_decisions(self, query: str,
                                        selected_committees: List[str] = None) -> Dict:
        """ìœ„ì›íšŒ ê²°ì •ë¬¸ ê²€ìƒ‰"""
        if selected_committees is None:
            selected_committees = list(self.committee_targets.keys())

        async with aiohttp.ClientSession() as session:
            tasks = []
            for committee in selected_committees:
                if committee in self.committee_targets:
                    tasks.append(self._search_by_target(session, query, committee, 10))

            results = await asyncio.gather(*tasks, return_exceptions=True)

            valid_committees = [c for c in selected_committees if c in self.committee_targets]
            return {
                valid_committees[idx]: results[idx] if not isinstance(results[idx], Exception) else []
                for idx in range(len(valid_committees))
            }

    async def search_ministry_interpretations(self, query: str,
                                             selected_ministries: List[str] = None) -> Dict:
        """ë¶€ì²˜ë³„ ë²•ë ¹í•´ì„ ê²€ìƒ‰"""
        if selected_ministries is None:
            # ì£¼ìš” ë¶€ì²˜ë§Œ ê¸°ë³¸ ê²€ìƒ‰
            selected_ministries = [
                'moelCgmExpc', 'molitCgmExpc', 'moisCgmExpc',
                'mohwCgmExpc', 'molegCgmExpc'
            ]

        async with aiohttp.ClientSession() as session:
            tasks = []
            for ministry in selected_ministries:
                if ministry in self.ministry_targets:
                    tasks.append(self._search_by_target(session, query, ministry, 10))

            results = await asyncio.gather(*tasks, return_exceptions=True)

            valid_ministries = [m for m in selected_ministries if m in self.ministry_targets]
            return {
                valid_ministries[idx]: results[idx] if not isinstance(results[idx], Exception) else []
                for idx in range(len(valid_ministries))
            }

    async def search_special_tribunals(self, query: str) -> Dict:
        """íŠ¹ë³„í–‰ì •ì‹¬íŒë¡€ ê²€ìƒ‰"""
        async with aiohttp.ClientSession() as session:
            tasks = []
            for target_code in self.special_tribunal_targets.keys():
                tasks.append(self._search_by_target(session, query, target_code, 10))

            results = await asyncio.gather(*tasks, return_exceptions=True)

            return {
                target_code: results[idx] if not isinstance(results[idx], Exception) else []
                for idx, target_code in enumerate(self.special_tribunal_targets.keys())
            }

    async def comprehensive_search(self, query: str,
                                  search_options: Dict = None) -> Dict:
        """ì¢…í•© ë²•ë¥  ê²€ìƒ‰ - í‚¤ì›Œë“œ ì¶”ì¶œ ë° í™•ì¥ ê²€ìƒ‰"""
        if search_options is None:
            search_options = {
                'basic': True,
                'committees': [],
                'ministries': [],
                'special_tribunals': True
            }

        # ì‚¬ìš©ì ì…ë ¥ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = self.extract_keywords(query)
        logger.info(f"ì¶”ì¶œëœ í‚¤ì›Œë“œ: {keywords}")

        results = {
            'query': query,
            'keywords': keywords,
            'search_time': datetime.now().isoformat(),
            'basic': {},
            'committees': {},
            'ministries': {},
            'special_tribunals': {}
        }

        tasks = []

        # ê¸°ë³¸ ë²•ë¥  ë°ì´í„° ê²€ìƒ‰ (í‚¤ì›Œë“œ ê¸°ë°˜ í™•ì¥ ê²€ìƒ‰)
        if search_options.get('basic', True):
            tasks.append(('basic', self.search_basic_legal_data(query, keywords)))

        # ìœ„ì›íšŒ ê²°ì •ë¬¸ ê²€ìƒ‰
        committees = search_options.get('committees', [])
        if committees:
            tasks.append(('committees', self.search_committee_decisions(query, committees)))

        # ë¶€ì²˜ë³„ ë²•ë ¹í•´ì„ ê²€ìƒ‰
        ministries = search_options.get('ministries', [])
        if ministries:
            tasks.append(('ministries', self.search_ministry_interpretations(query, ministries)))

        # íŠ¹ë³„í–‰ì •ì‹¬íŒë¡€ ê²€ìƒ‰
        if search_options.get('special_tribunals', False):
            tasks.append(('special_tribunals', self.search_special_tribunals(query)))

        # ë³‘ë ¬ ì‹¤í–‰
        for key, task in tasks:
            try:
                results[key] = await task
            except Exception as e:
                logger.error(f"ê²€ìƒ‰ ì˜¤ë¥˜ ({key}): {e}")
                results[key] = {}

        return results

    async def get_detail(self, target: str, item_id: str) -> Dict:
        """ìƒì„¸ ì •ë³´ ì¡°íšŒ"""
        params = {
            'OC': self.law_api_key,
            'target': target,
            'ID': item_id,
            'type': 'JSON'
        }

        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    self.api_endpoints['service'],
                    params=params,
                    timeout=aiohttp.ClientTimeout(total=15)
                ) as response:
                    if response.status == 200:
                        return await response.json()
        except Exception as e:
            logger.error(f"ìƒì„¸ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return {}

    def create_fact_sheet(self, user_input: str, legal_data: Dict) -> Dict:
        """ì‚¬ì‹¤ê´€ê³„ ì •ë¦¬"""
        fact_sheet = {
            'query': user_input,
            'timestamp': datetime.now().isoformat(),
            'statistics': {},
            'key_facts': self._extract_key_facts(user_input),
            'timeline': self._extract_timeline(user_input)
        }

        # ê¸°ë³¸ ë°ì´í„° í†µê³„
        if legal_data.get('basic'):
            for key, items in legal_data['basic'].items():
                if items:
                    fact_sheet['statistics'][key] = len(items)

        # ìœ„ì›íšŒ ë°ì´í„° í†µê³„
        if legal_data.get('committees'):
            for key, items in legal_data['committees'].items():
                if items:
                    fact_sheet['statistics'][f'committee_{key}'] = len(items)

        # ë¶€ì²˜ ë°ì´í„° í†µê³„
        if legal_data.get('ministries'):
            for key, items in legal_data['ministries'].items():
                if items:
                    fact_sheet['statistics'][f'ministry_{key}'] = len(items)

        # íŠ¹ë³„í–‰ì •ì‹¬íŒ í†µê³„
        if legal_data.get('special_tribunals'):
            for key, items in legal_data['special_tribunals'].items():
                if items:
                    fact_sheet['statistics'][f'tribunal_{key}'] = len(items)

        return fact_sheet

    def _extract_key_facts(self, text: str) -> List[str]:
        """í•µì‹¬ ì‚¬ì‹¤ ì¶”ì¶œ"""
        facts = []

        # ë‚ ì§œ íŒ¨í„´
        date_pattern = r'\d{4}[ë…„\.\-]\d{1,2}[ì›”\.\-]\d{1,2}[ì¼]?'
        dates = re.findall(date_pattern, text)
        for date in dates:
            facts.append(f"ê´€ë ¨ ì¼ì: {date}")

        # ê¸ˆì•¡ íŒ¨í„´
        money_pattern = r'\d+[ë§Œì²œë°±]?\s?ì›'
        amounts = re.findall(money_pattern, text)
        for amount in amounts:
            facts.append(f"ê´€ë ¨ ê¸ˆì•¡: {amount}")

        return facts

    def _extract_timeline(self, text: str) -> List[Dict]:
        """íƒ€ì„ë¼ì¸ ì¶”ì¶œ"""
        timeline = []
        date_pattern = r'(\d{4}[ë…„\.\-]\d{1,2}[ì›”\.\-]\d{1,2}[ì¼]?)'

        sentences = text.split('.')
        for sentence in sentences:
            dates = re.findall(date_pattern, sentence)
            if dates:
                for date in dates:
                    timeline.append({
                        'date': date,
                        'event': sentence.strip()
                    })

        return sorted(timeline, key=lambda x: x['date'])

    # API í•„ë“œëª… ë§¤í•‘ (camelCase -> í•œê¸€)
    FIELD_MAPPING = {
        'evtNm': 'ì‚¬ê±´ëª…',
        'itmNm': 'ì•ˆê±´ëª…',
        'caseNm': 'ì‚¬ê±´ëª…',
        'caseName': 'ì‚¬ê±´ëª…',
        'caseNo': 'ì‚¬ê±´ë²ˆí˜¸',
        'caseNumber': 'ì‚¬ê±´ë²ˆí˜¸',
        'courtNm': 'ë²•ì›ëª…',
        'courtName': 'ë²•ì›ëª…',
        'judgeDate': 'ì„ ê³ ì¼ì',
        'judgmentDate': 'ì„ ê³ ì¼ì',
        'decisionDate': 'ì˜ê²°ì¼ì',
        'replyDate': 'íšŒì‹ ì¼ì',
        'replyOrg': 'íšŒì‹ ê¸°ê´€',
        'lawNm': 'ë²•ë ¹ëª…',
        'lawName': 'ë²•ë ¹ëª…',
    }

    # ì œì™¸í•  ê°’ë“¤ (ë©”íƒ€ë°ì´í„°, ìƒíƒœê°’, í•„ë“œëª… ë“±)
    SKIP_VALUES = {
        # ìƒíƒœê°’
        'success', 'true', 'false', 'null', 'none', 'error', 'ok',
        # ìˆ«ì
        '00', '0', '1', '2', '3', '4', '5',
        # camelCase í•„ë“œëª…ë“¤
        'evtnm', 'itmnm', 'casenm', 'caseno', 'courtnm', 'lawNm', 'lawnm',
        'casename', 'casenumber', 'courtname', 'judgmentdate', 'decisiondate',
        'replydate', 'replyorg', 'lawname', 'enforcementdate', 'promulgationdate',
        # API ë©”íƒ€ë°ì´í„° í‚¤
        'target', 'type', 'page', 'totalcnt', 'section', 'display', 'sort',
        'query', 'search', 'keyword', 'q',
        # ê¸°íƒ€
        'prec', 'expc', 'decc', 'detc', 'law', 'eflaw', 'admrul', 'ordin', 'trty'
    }

    def _is_valid_value(self, value, query: str = '') -> bool:
        """ìœ íš¨í•œ ë°ì´í„° ê°’ì¸ì§€ í™•ì¸"""
        if not value:
            return False

        val_str = str(value).strip()

        # ë¹ˆ ê°’ ì²´í¬
        if not val_str:
            return False

        val_lower = val_str.lower()

        # SKIP_VALUES ì²´í¬
        if val_lower in self.SKIP_VALUES:
            return False

        # ê²€ìƒ‰ì–´ì™€ ë™ì¼í•œ ê°’ì€ ì œì™¸ (ì—ì½”ëœ ê²€ìƒ‰ì–´)
        if query:
            query_lower = query.strip().lower()
            if val_lower == query_lower:
                return False
            # ê²€ìƒ‰ì–´ê°€ ê°’ì— í¬í•¨ëœ ê²½ìš°ë„ ì œì™¸ (ë¶€ë¶„ ì¼ì¹˜)
            if len(query_lower) > 5 and query_lower in val_lower and len(val_str) < len(query) + 10:
                return False

        # camelCase íŒ¨í„´ ê°ì§€ (ì†Œë¬¸ì+ëŒ€ë¬¸ì ì—°ì†)
        if re.match(r'^[a-z]+[A-Z][a-z]+$', val_str):
            return False

        # ë„ˆë¬´ ì§§ì€ ê°’ ì œì™¸ (1-2ì ìˆ«ì)
        if len(val_str) <= 2 and val_str.isdigit():
            return False

        # ì˜ë¬¸ ì†Œë¬¸ìë¡œë§Œ ëœ ì§§ì€ ê°’ ì œì™¸ (í•„ë“œëª…ì¼ ê°€ëŠ¥ì„±)
        if len(val_str) <= 10 and val_str.isalpha() and val_str.islower():
            return False

        return True

    def _get_value(self, item: Dict, *keys, default='', query: str = '') -> str:
        """ì—¬ëŸ¬ ê°€ëŠ¥í•œ í‚¤ì—ì„œ ê°’ì„ ì°¾ëŠ” í—¬í¼ í•¨ìˆ˜"""
        if not isinstance(item, dict):
            if item and self._is_valid_value(item, query):
                return str(item)
            return default

        # 1. ì§€ì •ëœ í‚¤ì—ì„œ ì°¾ê¸° (ë§¤í•‘ëœ í‚¤ í¬í•¨)
        all_keys = list(keys)
        for key in keys:
            if key in self.FIELD_MAPPING:
                all_keys.append(self.FIELD_MAPPING[key])
            # ì—­ë§¤í•‘ë„ í™•ì¸
            for eng, kor in self.FIELD_MAPPING.items():
                if key == kor:
                    all_keys.append(eng)

        for key in all_keys:
            if key in item:
                val = item[key]
                if self._is_valid_value(val, query):
                    return str(val)

        # 2. í‚¤ ì´ë¦„ì— í¬í•¨ëœ ë‹¨ì–´ë¡œ ì°¾ê¸° (ë¶€ë¶„ ì¼ì¹˜)
        search_terms = ['ëª…', 'ë²ˆí˜¸', 'ì¼ì', 'Nm', 'No', 'Date', 'Name', 'Title']
        for key, value in item.items():
            if self._is_valid_value(value, query):
                for term in search_terms:
                    if term in key:
                        return str(value)

        return default

    def _get_item_display(self, item: Dict, *preferred_keys, query: str = '') -> str:
        """ì•„ì´í…œ í‘œì‹œìš© ë¬¸ìì—´ ë°˜í™˜"""
        if not isinstance(item, dict):
            if item and self._is_valid_value(item, query):
                return str(item)
            return '(ì •ë³´ ì—†ìŒ)'

        # 1. ìš°ì„  í‚¤ì—ì„œ ì°¾ê¸°
        all_keys = list(preferred_keys)
        for key in preferred_keys:
            if key in self.FIELD_MAPPING:
                all_keys.append(self.FIELD_MAPPING[key])
            for eng, kor in self.FIELD_MAPPING.items():
                if key == kor:
                    all_keys.append(eng)

        for key in all_keys:
            if key in item:
                val = item[key]
                if self._is_valid_value(val, query):
                    return str(val)

        # 2. ìœ íš¨í•œ ê°’ë“¤ ìˆ˜ì§‘
        skip_keys = {'target', 'type', 'id', 'page', 'totalcnt', 'section', 'success'}
        valid_parts = []
        for key, value in item.items():
            if key.lower() not in skip_keys and self._is_valid_value(value, query):
                valid_parts.append(str(value))

        return " | ".join(valid_parts[:3]) if valid_parts else '(ì •ë³´ ì—†ìŒ)'

    def _build_context(self, legal_data: Dict) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ êµ¬ì„± - íŒë¡€/ìœ ê¶Œí•´ì„ ì¤‘ì‹¬ í™•ì¥"""
        context_parts = []

        # ê¸°ë³¸ ë²•ë¥  ë°ì´í„°
        if legal_data.get('basic'):
            basic = legal_data['basic']

            # ë²•ë ¹ (ìƒìœ„ 15ê°œ)
            if basic.get('law') or basic.get('eflaw'):
                laws = (basic.get('law', []) or []) + (basic.get('eflaw', []) or [])
                if laws:
                    context_parts.append(f"\n[ê´€ë ¨ ë²•ë ¹] (ì´ {len(laws)}ê±´)")
                    for idx, law in enumerate(laws[:15], 1):
                        name = self._get_value(law, 'ë²•ë ¹ëª…í•œê¸€', 'ë²•ë ¹ëª…', 'lawNameKorean', 'lawName', 'ë²•ë ¹ëª…ì•½ì¹­')
                        dept = self._get_value(law, 'ì†Œê´€ë¶€ì²˜ëª…', 'ì†Œê´€ë¶€ì²˜', 'competentDept')
                        date = self._get_value(law, 'ì‹œí–‰ì¼ì', 'ê³µí¬ì¼ì', 'enforcementDate', 'promulgationDate')
                        if name:
                            context_parts.append(f"{idx}. {name}")
                            if dept:
                                context_parts.append(f"   - ì†Œê´€ë¶€ì²˜: {dept}")
                            if date:
                                context_parts.append(f"   - ì‹œí–‰/ê³µí¬ì¼: {date}")

            # íŒë¡€ (ìƒìœ„ 30ê°œ - í•µì‹¬ ìë£Œ)
            if basic.get('prec'):
                precs = basic['prec']
                context_parts.append(f"\n[ê´€ë ¨ íŒë¡€] (ì´ {len(precs)}ê±´) â˜… í•µì‹¬ ìë£Œ")
                for idx, prec in enumerate(precs[:30], 1):
                    name = self._get_value(prec, 'ì‚¬ê±´ëª…', 'íŒë¡€ëª…', 'caseName', 'caseNm', 'ì œëª©')
                    date = self._get_value(prec, 'ì„ ê³ ì¼ì', 'íŒê²°ì¼ì', 'judgmentDate', 'decisionDate')
                    court = self._get_value(prec, 'ë²•ì›ëª…', 'ë²•ì›', 'courtName', 'court')
                    case_no = self._get_value(prec, 'ì‚¬ê±´ë²ˆí˜¸', 'caseNo', 'caseNumber')
                    if name or case_no:
                        context_parts.append(f"{idx}. {name or '(ì‚¬ê±´ëª… ì—†ìŒ)'}")
                        if case_no:
                            context_parts.append(f"   - ì‚¬ê±´ë²ˆí˜¸: {case_no}")
                        if court:
                            context_parts.append(f"   - ë²•ì›: {court}")
                        if date:
                            context_parts.append(f"   - ì„ ê³ ì¼: {date}")

            # í—Œì¬ê²°ì •ë¡€ (ìƒìœ„ 15ê°œ)
            if basic.get('detc'):
                detcs = basic['detc']
                context_parts.append(f"\n[í—Œì¬ê²°ì •ë¡€] (ì´ {len(detcs)}ê±´)")
                for idx, case in enumerate(detcs[:15], 1):
                    name = self._get_value(case, 'ì‚¬ê±´ëª…', 'ê²°ì •ëª…', 'caseName', 'ì œëª©')
                    date = self._get_value(case, 'ì¢…êµ­ì¼ì', 'ì„ ê³ ì¼ì', 'ê²°ì •ì¼ì', 'decisionDate')
                    case_no = self._get_value(case, 'ì‚¬ê±´ë²ˆí˜¸', 'caseNo', 'caseNumber')
                    if name or case_no:
                        context_parts.append(f"{idx}. {name or '(ì‚¬ê±´ëª… ì—†ìŒ)'}")
                        if case_no:
                            context_parts.append(f"   - ì‚¬ê±´ë²ˆí˜¸: {case_no}")
                        if date:
                            context_parts.append(f"   - ì¢…êµ­ì¼: {date}")

            # ë²•ë ¹í•´ì„ë¡€ (ìƒìœ„ 25ê°œ - í•µì‹¬ ìë£Œ)
            if basic.get('expc'):
                expcs = basic['expc']
                context_parts.append(f"\n[ë²•ë ¹í•´ì„ë¡€/ìœ ê¶Œí•´ì„] (ì´ {len(expcs)}ê±´) â˜… í•µì‹¬ ìë£Œ")
                for idx, interp in enumerate(expcs[:25], 1):
                    name = self._get_value(interp, 'ì•ˆê±´ëª…', 'ì œëª©', 'title', 'caseName')
                    no = self._get_value(interp, 'ì•ˆê±´ë²ˆí˜¸', 'caseNo', 'number')
                    org = self._get_value(interp, 'íšŒì‹ ê¸°ê´€ëª…', 'íšŒì‹ ê¸°ê´€', 'replyOrg')
                    date = self._get_value(interp, 'íšŒì‹ ì¼ì', 'replyDate')
                    if name or no:
                        context_parts.append(f"{idx}. {name or '(ì•ˆê±´ëª… ì—†ìŒ)'}")
                        if no:
                            context_parts.append(f"   - ì•ˆê±´ë²ˆí˜¸: {no}")
                        if org:
                            context_parts.append(f"   - íšŒì‹ ê¸°ê´€: {org}")
                        if date:
                            context_parts.append(f"   - íšŒì‹ ì¼ì: {date}")

            # í–‰ì •ì‹¬íŒë¡€ (ìƒìœ„ 25ê°œ - í•µì‹¬ ìë£Œ)
            if basic.get('decc'):
                deccs = basic['decc']
                context_parts.append(f"\n[í–‰ì •ì‹¬íŒë¡€] (ì´ {len(deccs)}ê±´) â˜… í•µì‹¬ ìë£Œ")
                for idx, ruling in enumerate(deccs[:25], 1):
                    name = self._get_value(ruling, 'ì‚¬ê±´ëª…', 'ì œëª©', 'caseName', 'title')
                    date = self._get_value(ruling, 'ì˜ê²°ì¼ì', 'ì¬ê²°ì¼ì', 'decisionDate')
                    case_no = self._get_value(ruling, 'ì‚¬ê±´ë²ˆí˜¸', 'caseNo', 'caseNumber')
                    result = self._get_value(ruling, 'ì¬ê²°ê²°ê³¼', 'ì¬ê²°êµ¬ë¶„ëª…', 'result')
                    if name or case_no:
                        context_parts.append(f"{idx}. {name or '(ì‚¬ê±´ëª… ì—†ìŒ)'}")
                        if case_no:
                            context_parts.append(f"   - ì‚¬ê±´ë²ˆí˜¸: {case_no}")
                        if result:
                            context_parts.append(f"   - ì¬ê²°ê²°ê³¼: {result}")
                        if date:
                            context_parts.append(f"   - ì˜ê²°ì¼: {date}")

            # í–‰ì •ê·œì¹™ (ìƒìœ„ 10ê°œ)
            if basic.get('admrul'):
                admruls = basic['admrul']
                context_parts.append(f"\n[í–‰ì •ê·œì¹™] (ì´ {len(admruls)}ê±´)")
                for idx, rule in enumerate(admruls[:10], 1):
                    name = self._get_value(rule, 'í–‰ì •ê·œì¹™ëª…', 'ì œëª©', 'ruleName', 'title')
                    dept = self._get_value(rule, 'ì†Œê´€ë¶€ì²˜ëª…', 'ì†Œê´€ë¶€ì²˜', 'competentDept')
                    if name:
                        context_parts.append(f"{idx}. {name}")
                        if dept:
                            context_parts.append(f"   - ì†Œê´€ë¶€ì²˜: {dept}")

            # ìì¹˜ë²•ê·œ (ìƒìœ„ 10ê°œ)
            if basic.get('ordin'):
                ordins = basic['ordin']
                context_parts.append(f"\n[ìì¹˜ë²•ê·œ] (ì´ {len(ordins)}ê±´)")
                for idx, ordin in enumerate(ordins[:10], 1):
                    name = self._get_value(ordin, 'ìì¹˜ë²•ê·œëª…', 'ì œëª©', 'ordinName', 'title')
                    local = self._get_value(ordin, 'ì§€ìì²´ê¸°ê´€ëª…', 'ìì¹˜ë‹¨ì²´ëª…', 'localGovt')
                    context_parts.append(f"{idx}. {name}")
                    if local:
                        context_parts.append(f"   - ì§€ìì²´: {local}")

            # ì¡°ì•½ (ìƒìœ„ 5ê°œ)
            if basic.get('trty'):
                trtys = basic['trty']
                if trtys:
                    context_parts.append(f"\n[ì¡°ì•½] (ì´ {len(trtys)}ê±´)")
                    for idx, treaty in enumerate(trtys[:5], 1):
                        name = treaty.get('ì¡°ì•½ëª…', treaty.get('ì¡°ì•½ëª…í•œê¸€', ''))
                        date = treaty.get('ì²´ê²°ì¼ì', '')
                        context_parts.append(f"{idx}. {name}")
                        if date:
                            context_parts.append(f"   - ì²´ê²°ì¼ì: {date}")

        # ìœ„ì›íšŒ ê²°ì •ë¬¸
        if legal_data.get('committees'):
            for comm_key, items in legal_data['committees'].items():
                if items:
                    comm_name = self.committee_targets.get(comm_key, {}).get('name', comm_key)
                    context_parts.append(f"\n[{comm_name} ê²°ì •ë¬¸]")
                    for idx, item in enumerate(items[:5], 1):
                        name = item.get('ì‚¬ê±´ëª…', item.get('ì•ˆê±´ëª…', ''))
                        date = item.get('ì˜ê²°ì¼ì', item.get('ê²°ì •ì¼ì', ''))
                        context_parts.append(f"{idx}. {name} ({date})")

        # ë¶€ì²˜ë³„ ë²•ë ¹í•´ì„
        if legal_data.get('ministries'):
            for min_key, items in legal_data['ministries'].items():
                if items:
                    min_name = self.ministry_targets.get(min_key, {}).get('name', min_key)
                    context_parts.append(f"\n[{min_name}]")
                    for idx, item in enumerate(items[:5], 1):
                        name = item.get('ì•ˆê±´ëª…', item.get('ì œëª©', ''))
                        date = item.get('íšŒì‹ ì¼ì', item.get('ë“±ë¡ì¼ì', ''))
                        context_parts.append(f"{idx}. {name} ({date})")

        # íŠ¹ë³„í–‰ì •ì‹¬íŒë¡€
        if legal_data.get('special_tribunals'):
            for trib_key, items in legal_data['special_tribunals'].items():
                if items:
                    trib_name = self.special_tribunal_targets.get(trib_key, {}).get('name', trib_key)
                    context_parts.append(f"\n[{trib_name}]")
                    for idx, item in enumerate(items[:5], 1):
                        name = item.get('ì‚¬ê±´ëª…', item.get('ì•ˆê±´ëª…', ''))
                        date = item.get('ì¬ê²°ì¼ì', item.get('ì˜ê²°ì¼ì', ''))
                        context_parts.append(f"{idx}. {name} ({date})")

        return "\n".join(context_parts)

    def _generate_fallback_response(self, query: str, legal_data: Dict) -> str:
        """API í‚¤ ì—†ì„ ë•Œ ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ ê¸°ë³¸ ì‘ë‹µ"""
        context = self._build_context(legal_data)

        # í†µê³„ ê³„ì‚°
        stats = []
        if legal_data.get('basic'):
            for key, items in legal_data['basic'].items():
                if items:
                    name = self.basic_targets.get(key, {}).get('name', key)
                    stats.append(f"{name} {len(items)}ê±´")

        if legal_data.get('committees'):
            for key, items in legal_data['committees'].items():
                if items:
                    name = self.committee_targets.get(key, {}).get('name', key)
                    stats.append(f"{name} {len(items)}ê±´")

        if legal_data.get('ministries'):
            for key, items in legal_data['ministries'].items():
                if items:
                    name = self.ministry_targets.get(key, {}).get('name', key)
                    stats.append(f"{name} {len(items)}ê±´")

        if legal_data.get('special_tribunals'):
            for key, items in legal_data['special_tribunals'].items():
                if items:
                    name = self.special_tribunal_targets.get(key, {}).get('name', key)
                    stats.append(f"{name} {len(items)}ê±´")

        stats_text = ", ".join(stats) if stats else "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"

        return f"""## ë²•ë¥  ë°ì´í„° ê²€ìƒ‰ ê²°ê³¼

**ì§ˆì˜:** {query}

**ê²€ìƒ‰ í†µê³„:** {stats_text}

{context if context else "ê´€ë ¨ ë²•ë¥  ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}

---
âš ï¸ **ì•ˆë‚´:** OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ AI ë¶„ì„ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
ìœ„ ê²€ìƒ‰ ê²°ê³¼ëŠ” ë²•ì œì²˜ Open APIì—ì„œ ê°€ì ¸ì˜¨ ì›ë³¸ ë°ì´í„°ì…ë‹ˆë‹¤.

AI ë¶„ì„ì„ ì´ìš©í•˜ì‹œë ¤ë©´ ì‚¬ì´ë“œë°”ì—ì„œ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.

âš–ï¸ ë³¸ ë‚´ìš©ì€ ì°¸ê³ ìë£Œì´ë©°, êµ¬ì²´ì ì¸ ì‚¬ì•ˆì— ëŒ€í•´ì„œëŠ” ë°˜ë“œì‹œ ë³€í˜¸ì‚¬ ë“± ì „ë¬¸ê°€ì˜ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.
"""

        try:
            client = get_openai_client()
            if not client:
                return "AI ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. OpenAI API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
            response = client.chat.completions.create(
                model="gpt-5",
                messages=[
                    {"role": "system", "content": AI_LAWYER_SYSTEM_PROMPT},
                    {"role": "user", "content": prompt}
                ],
                max_completion_tokens=2000
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"AI ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
            return "AI ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

    async def generate_legal_advice(self, query: str, legal_data: Dict, fact_sheet: Dict) -> str:
        """AI ë²•ë¥  ì¡°ì–¸ ìƒì„± - ì‹¤ì œ ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜"""
        # API í‚¤ í™•ì¸
        if not get_openai_api_key():
            return self._generate_fallback_response(query, legal_data)

        context = self._build_context(legal_data)
        timeline = "\n".join([f"- {item['date']}: {item['event']}"
                             for item in fact_sheet.get('timeline', [])])

        # ê²€ìƒ‰ í†µê³„ ìš”ì•½
        stats_summary = self._get_search_stats_summary(legal_data)

        # ì¶”ì¶œëœ í‚¤ì›Œë“œ
        keywords = legal_data.get('keywords', [])
        keywords_str = ', '.join(keywords) if keywords else 'ì—†ìŒ'

        # ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
        has_results = bool(context and context.strip())

        if has_results:
            prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ ë²•ë¥  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ì— ë²•ì œì²˜ Open APIì—ì„œ ê²€ìƒ‰ëœ **ì‹¤ì œ ë²•ë¥  ìë£Œ**ê°€ ì œê³µë©ë‹ˆë‹¤.
ë°˜ë“œì‹œ ì´ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
## ì˜ë¢°ì¸ ì§ˆë¬¸/ìƒí™©:
{query}

## ì¶”ì¶œëœ ê²€ìƒ‰ í‚¤ì›Œë“œ:
{keywords_str}

## ê²€ìƒ‰ í†µê³„:
{stats_summary}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## ğŸ” ë²•ì œì²˜ì—ì„œ ê²€ìƒ‰ëœ ì‹¤ì œ ë²•ë¥  ìë£Œ:
{context}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## âš ï¸ í•„ìˆ˜ ì§€ì¹¨ (ë°˜ë“œì‹œ ì¤€ìˆ˜):
1. **ìœ„ì— ì œê³µëœ ê²€ìƒ‰ ê²°ê³¼ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.** ì¼ë°˜ì ì¸ ë²•ë¥  ì§€ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì§€ ë§ˆì„¸ìš”.
2. **íŒë¡€ë¥¼ ì¸ìš©í•  ë•ŒëŠ” ë°˜ë“œì‹œ ìœ„ ëª©ë¡ì—ì„œ ì‚¬ê±´ë²ˆí˜¸ë¥¼ ì •í™•íˆ ë³µì‚¬í•˜ì„¸ìš”.**
   ì˜ˆ: "ëŒ€ë²•ì› 2020ë‹¤12345 íŒê²°ì—ì„œ..."
3. **ë²•ë ¹í•´ì„ë¡€ë¥¼ ì¸ìš©í•  ë•ŒëŠ” ì•ˆê±´ë²ˆí˜¸ë¥¼ ëª…ì‹œí•˜ì„¸ìš”.**
   ì˜ˆ: "ë²•ì œì²˜ ì•ˆê±´ë²ˆí˜¸ 22-0123ì— ë”°ë¥´ë©´..."
4. **í–‰ì •ì‹¬íŒë¡€ë¥¼ ì¸ìš©í•  ë•ŒëŠ” ì‚¬ê±´ë²ˆí˜¸ë¥¼ ëª…ì‹œí•˜ì„¸ìš”.**
   ì˜ˆ: "ì¤‘ì•™í–‰ì •ì‹¬íŒìœ„ì›íšŒ 2023-12345 ì¬ê²°ì—ì„œ..."
5. ìœ„ ê²€ìƒ‰ ê²°ê³¼ì— ì—†ëŠ” ë‚´ìš©ì€ "ê²€ìƒ‰ ê²°ê³¼ì— í¬í•¨ë˜ì§€ ì•ŠìŒ"ì´ë¼ê³  ëª…ì‹œí•˜ì„¸ìš”.

## ë‹µë³€ í˜•ì‹:

### ğŸ“‹ í•µì‹¬ ìš”ì•½
[ì˜ë¢°ì¸ ìƒí™©ì— ëŒ€í•œ 2-3ë¬¸ì¥ í•µì‹¬ ê²°ë¡ ]

### ğŸ“š ê´€ë ¨ íŒë¡€ (ìœ„ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì¸ìš©)
[ê²€ìƒ‰ëœ íŒë¡€ ëª©ë¡ì—ì„œ ê´€ë ¨ íŒë¡€ë¥¼ ì„ íƒí•˜ì—¬ ì‚¬ê±´ë²ˆí˜¸ì™€ í•¨ê»˜ ìƒì„¸ ì„¤ëª…]
- **ì‚¬ê±´ë²ˆí˜¸**: [ìœ„ì—ì„œ ë³µì‚¬]
- **ë²•ì›/ì„ ê³ ì¼**: [ìœ„ì—ì„œ ë³µì‚¬]
- **íŒì‹œì‚¬í•­**: [ë‚´ìš© ì„¤ëª…]
- **ì˜ë¢°ì¸ ì‚¬ì•ˆ ì ìš©**: [ë¶„ì„]

### ğŸ“‹ ê´€ë ¨ ë²•ë ¹í•´ì„ë¡€/í–‰ì •ì‹¬íŒë¡€ (ìœ„ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì¸ìš©)
[ê²€ìƒ‰ëœ í•´ì„ë¡€/ì‹¬íŒë¡€ì—ì„œ ê´€ë ¨ ê±´ì„ ì„ íƒí•˜ì—¬ ì•ˆê±´ë²ˆí˜¸ì™€ í•¨ê»˜ ì„¤ëª…]

### ğŸ“– ê´€ë ¨ ë²•ë ¹
[ê²€ìƒ‰ëœ ë²•ë ¹ ì¤‘ ê´€ë ¨ ë²•ë ¹ ì¸ìš©]

### ğŸ’¡ ì¢…í•© ì˜ê²¬ ë° ì¡°ì–¸
[ìœ„ ìë£Œë“¤ì„ ì¢…í•©í•œ ë¶„ì„]

---
âš–ï¸ ë³¸ ë‚´ìš©ì€ AIê°€ ì‘ì„±í•œ ì°¸ê³ ìë£Œì´ë©°, ë²•ë¥ ìë¬¸ì´ ì•„ë‹™ë‹ˆë‹¤.
êµ¬ì²´ì ì¸ ì‚¬ì•ˆì— ëŒ€í•´ì„œëŠ” ë°˜ë“œì‹œ ë³€í˜¸ì‚¬ ë“± ì „ë¬¸ê°€ì˜ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.
"""
        else:
            prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ ë²•ë¥  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì˜ë¢°ì¸ ì§ˆë¬¸/ìƒí™©:
{query}

## ì¶”ì¶œëœ ê²€ìƒ‰ í‚¤ì›Œë“œ:
{keywords_str}

## âš ï¸ ê²€ìƒ‰ ê²°ê³¼:
ë²•ì œì²˜ Open API ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.

## ì§€ì¹¨:
1. ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŒì„ ë¨¼ì € ì•ˆë‚´í•˜ì„¸ìš”.
2. ì¼ë°˜ì ì¸ ë²•ë¥  ì •ë³´ë¥¼ ì œê³µí•˜ë˜, "ë²•ì œì²˜ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"ì„ ëª…ì‹œí•˜ì„¸ìš”.
3. ë‹¤ë¥¸ ê²€ìƒ‰ì–´ ì œì•ˆì„ í¬í•¨í•˜ì„¸ìš”.

---
âš–ï¸ ë³¸ ë‚´ìš©ì€ AIê°€ ì‘ì„±í•œ ì°¸ê³ ìë£Œì´ë©°, ë²•ë¥ ìë¬¸ì´ ì•„ë‹™ë‹ˆë‹¤.
êµ¬ì²´ì ì¸ ì‚¬ì•ˆì— ëŒ€í•´ì„œëŠ” ë°˜ë“œì‹œ ë³€í˜¸ì‚¬ ë“± ì „ë¬¸ê°€ì˜ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.
"""

        try:
            client = get_openai_client()
            if not client:
                return self._generate_fallback_response(query, legal_data)
            response = client.chat.completions.create(
                model="gpt-5",
                messages=[
                    {"role": "system", "content": AI_LAWYER_SYSTEM_PROMPT},
                    {"role": "user", "content": prompt}
                ],
                max_completion_tokens=2500
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"AI ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
            return self._generate_fallback_response(query, legal_data)

    async def _generate_contract_review(self, query: str, legal_data: Dict, fact_sheet: Dict) -> str:
        """ê³„ì•½ì„œ ê²€í†  ì‘ë‹µ ìƒì„±"""
        # API í‚¤ í™•ì¸
        if not get_openai_api_key():
            return self._generate_fallback_response(query, legal_data)

        context = self._build_context(legal_data)
        timeline = "\n".join([f"- {item['date']}: {item['event']}"
                             for item in fact_sheet.get('timeline', [])])

        # ê²€ìƒ‰ í†µê³„ ìš”ì•½
        stats_summary = self._get_search_stats_summary(legal_data)

        # ì¶”ì¶œëœ í‚¤ì›Œë“œ
        keywords = legal_data.get('keywords', [])
        keywords_str = ', '.join(keywords) if keywords else 'ì—†ìŒ'

        # ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
        has_results = bool(context and context.strip())

        if has_results:
            prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ ë²•ë¥  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ì— ë²•ì œì²˜ Open APIì—ì„œ ê²€ìƒ‰ëœ **ì‹¤ì œ ë²•ë¥  ìë£Œ**ê°€ ì œê³µë©ë‹ˆë‹¤.
ë°˜ë“œì‹œ ì´ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
## ì˜ë¢°ì¸ ì§ˆë¬¸/ìƒí™©:
{query}

## ì¶”ì¶œëœ ê²€ìƒ‰ í‚¤ì›Œë“œ:
{keywords_str}

## ê²€ìƒ‰ í†µê³„:
{stats_summary}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## ğŸ” ë²•ì œì²˜ì—ì„œ ê²€ìƒ‰ëœ ì‹¤ì œ ë²•ë¥  ìë£Œ:
{context}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## âš ï¸ í•„ìˆ˜ ì§€ì¹¨ (ë°˜ë“œì‹œ ì¤€ìˆ˜):
1. **ìœ„ì— ì œê³µëœ ê²€ìƒ‰ ê²°ê³¼ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.** ì¼ë°˜ì ì¸ ë²•ë¥  ì§€ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì§€ ë§ˆì„¸ìš”.
2. **íŒë¡€ë¥¼ ì¸ìš©í•  ë•ŒëŠ” ë°˜ë“œì‹œ ìœ„ ëª©ë¡ì—ì„œ ì‚¬ê±´ë²ˆí˜¸ë¥¼ ì •í™•íˆ ë³µì‚¬í•˜ì„¸ìš”.**
   ì˜ˆ: "ëŒ€ë²•ì› 2020ë‹¤12345 íŒê²°ì—ì„œ..."
3. **ë²•ë ¹í•´ì„ë¡€ë¥¼ ì¸ìš©í•  ë•ŒëŠ” ì•ˆê±´ë²ˆí˜¸ë¥¼ ëª…ì‹œí•˜ì„¸ìš”.**
   ì˜ˆ: "ë²•ì œì²˜ ì•ˆê±´ë²ˆí˜¸ 22-0123ì— ë”°ë¥´ë©´..."
4. **í–‰ì •ì‹¬íŒë¡€ë¥¼ ì¸ìš©í•  ë•ŒëŠ” ì‚¬ê±´ë²ˆí˜¸ë¥¼ ëª…ì‹œí•˜ì„¸ìš”.**
   ì˜ˆ: "ì¤‘ì•™í–‰ì •ì‹¬íŒìœ„ì›íšŒ 2023-12345 ì¬ê²°ì—ì„œ..."
5. ìœ„ ê²€ìƒ‰ ê²°ê³¼ì— ì—†ëŠ” ë‚´ìš©ì€ "ê²€ìƒ‰ ê²°ê³¼ì— í¬í•¨ë˜ì§€ ì•ŠìŒ"ì´ë¼ê³  ëª…ì‹œí•˜ì„¸ìš”.

## ë‹µë³€ í˜•ì‹:

### ğŸ“‹ í•µì‹¬ ìš”ì•½
[ì˜ë¢°ì¸ ìƒí™©ì— ëŒ€í•œ 2-3ë¬¸ì¥ í•µì‹¬ ê²°ë¡ ]

### ğŸ“š ê´€ë ¨ íŒë¡€ (ìœ„ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì¸ìš©)
[ê²€ìƒ‰ëœ íŒë¡€ ëª©ë¡ì—ì„œ ê´€ë ¨ íŒë¡€ë¥¼ ì„ íƒí•˜ì—¬ ì‚¬ê±´ë²ˆí˜¸ì™€ í•¨ê»˜ ìƒì„¸ ì„¤ëª…]
- **ì‚¬ê±´ë²ˆí˜¸**: [ìœ„ì—ì„œ ë³µì‚¬]
- **ë²•ì›/ì„ ê³ ì¼**: [ìœ„ì—ì„œ ë³µì‚¬]
- **íŒì‹œì‚¬í•­**: [ë‚´ìš© ì„¤ëª…]
- **ì˜ë¢°ì¸ ì‚¬ì•ˆ ì ìš©**: [ë¶„ì„]

### ğŸ“‹ ê´€ë ¨ ë²•ë ¹í•´ì„ë¡€/í–‰ì •ì‹¬íŒë¡€ (ìœ„ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì¸ìš©)
[ê²€ìƒ‰ëœ í•´ì„ë¡€/ì‹¬íŒë¡€ì—ì„œ ê´€ë ¨ ê±´ì„ ì„ íƒí•˜ì—¬ ì•ˆê±´ë²ˆí˜¸ì™€ í•¨ê»˜ ì„¤ëª…]

### ğŸ“– ê´€ë ¨ ë²•ë ¹
[ê²€ìƒ‰ëœ ë²•ë ¹ ì¤‘ ê´€ë ¨ ë²•ë ¹ ì¸ìš©]

### ğŸ’¡ ì¢…í•© ì˜ê²¬ ë° ì¡°ì–¸
[ìœ„ ìë£Œë“¤ì„ ì¢…í•©í•œ ë¶„ì„]

---
âš–ï¸ ë³¸ ë‚´ìš©ì€ AIê°€ ì‘ì„±í•œ ì°¸ê³ ìë£Œì´ë©°, ë²•ë¥ ìë¬¸ì´ ì•„ë‹™ë‹ˆë‹¤.
êµ¬ì²´ì ì¸ ì‚¬ì•ˆì— ëŒ€í•´ì„œëŠ” ë°˜ë“œì‹œ ë³€í˜¸ì‚¬ ë“± ì „ë¬¸ê°€ì˜ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.
"""
        else:
            prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ ë²•ë¥  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì˜ë¢°ì¸ ì§ˆë¬¸/ìƒí™©:
{query}

## ì¶”ì¶œëœ ê²€ìƒ‰ í‚¤ì›Œë“œ:
{keywords_str}

## âš ï¸ ê²€ìƒ‰ ê²°ê³¼:
ë²•ì œì²˜ Open API ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.

## ì§€ì¹¨:
1. ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŒì„ ë¨¼ì € ì•ˆë‚´í•˜ì„¸ìš”.
2. ì¼ë°˜ì ì¸ ë²•ë¥  ì •ë³´ë¥¼ ì œê³µí•˜ë˜, "ë²•ì œì²˜ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"ì„ ëª…ì‹œí•˜ì„¸ìš”.
3. ë‹¤ë¥¸ ê²€ìƒ‰ì–´ ì œì•ˆì„ í¬í•¨í•˜ì„¸ìš”.

---
âš–ï¸ ë³¸ ë‚´ìš©ì€ AIê°€ ì‘ì„±í•œ ì°¸ê³ ìë£Œì´ë©°, ë²•ë¥ ìë¬¸ì´ ì•„ë‹™ë‹ˆë‹¤.
êµ¬ì²´ì ì¸ ì‚¬ì•ˆì— ëŒ€í•´ì„œëŠ” ë°˜ë“œì‹œ ë³€í˜¸ì‚¬ ë“± ì „ë¬¸ê°€ì˜ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.
"""

        try:
            client = get_openai_client()
            if not client:
                return self._generate_fallback_response(query, legal_data)
            response = client.chat.completions.create(
                model="gpt-5",
                messages=[
                    {"role": "system", "content": AI_LAWYER_SYSTEM_PROMPT},
                    {"role": "user", "content": prompt}
                ],
                max_completion_tokens=2500
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"AI ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
            return self._generate_fallback_response(query, legal_data)

    def _get_search_stats_summary(self, legal_data: Dict) -> str:
        """ê²€ìƒ‰ í†µê³„ ìš”ì•½ ìƒì„±"""
        stats = []

        if legal_data.get('basic'):
            basic = legal_data['basic']
            if basic.get('law') or basic.get('eflaw'):
                laws = (basic.get('law', []) or []) + (basic.get('eflaw', []) or [])
                if laws:
                    stats.append(f"- ë²•ë ¹: {len(laws)}ê±´")
            if basic.get('prec'):
                stats.append(f"- íŒë¡€: {len(basic['prec'])}ê±´ â˜…")
            if basic.get('detc'):
                stats.append(f"- í—Œì¬ê²°ì •ë¡€: {len(basic['detc'])}ê±´")
            if basic.get('expc'):
                stats.append(f"- ë²•ë ¹í•´ì„ë¡€: {len(basic['expc'])}ê±´ â˜…")
            if basic.get('decc'):
                stats.append(f"- í–‰ì •ì‹¬íŒë¡€: {len(basic['decc'])}ê±´ â˜…")
            if basic.get('admrul'):
                stats.append(f"- í–‰ì •ê·œì¹™: {len(basic['admrul'])}ê±´")
            if basic.get('ordin'):
                stats.append(f"- ìì¹˜ë²•ê·œ: {len(basic['ordin'])}ê±´")

        if legal_data.get('committees'):
            for key, items in legal_data['committees'].items():
                if items:
                    name = self.committee_targets.get(key, {}).get('name', key)
                    stats.append(f"- {name}: {len(items)}ê±´")

        if legal_data.get('ministries'):
            for key, items in legal_data['ministries'].items():
                if items:
                    name = self.ministry_targets.get(key, {}).get('name', key)
                    stats.append(f"- {name}: {len(items)}ê±´")

        if legal_data.get('special_tribunals'):
            for key, items in legal_data['special_tribunals'].items():
                if items:
                    name = self.special_tribunal_targets.get(key, {}).get('name', key)
                    stats.append(f"- {name}: {len(items)}ê±´")

        return "\n".join(stats) if stats else "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"

# ===== UI í•¨ìˆ˜ë“¤ =====
def display_chat_message(role: str, content: str):
    """ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ"""
    if role == "user":
        st.markdown(f'''
        <div class="chat-message user-message">
            <strong>ğŸ‘¤ ì˜ë¢°ì¸:</strong><br>
            {content}
        </div>
        ''', unsafe_allow_html=True)
    else:
        st.markdown(content)

def display_search_results_detail(legal_data: Dict, engine: LegalAIEngine, query: str = ''):
    """ê²€ìƒ‰ëœ íŒë¡€/ìœ ê¶Œí•´ì„ ìƒì„¸ í‘œì‹œ"""
    if not legal_data:
        return

    basic = legal_data.get('basic', {})

    # íŒë¡€ ìƒì„¸
    if basic.get('prec'):
        with st.expander(f"ğŸ“š ê²€ìƒ‰ëœ íŒë¡€ ({len(basic['prec'])}ê±´)", expanded=True):
            for idx, prec in enumerate(basic['prec'][:20], 1):
                display_name = engine._get_item_display(prec, 'ì‚¬ê±´ëª…', 'íŒë¡€ëª…', 'caseName', 'ì œëª©', query=query)
                case_no = engine._get_value(prec, 'ì‚¬ê±´ë²ˆí˜¸', 'caseNo', 'caseNumber', query=query)
                court = engine._get_value(prec, 'ë²•ì›ëª…', 'ë²•ì›', 'courtName', 'court', query=query)
                date = engine._get_value(prec, 'ì„ ê³ ì¼ì', 'íŒê²°ì¼ì', 'judgmentDate', 'decisionDate', query=query)
                detail_link = engine._get_value(prec, 'íŒë¡€ìƒì„¸ë§í¬', 'detailLink', query=query)
                if display_name and display_name != '(ì •ë³´ ì—†ìŒ)':
                    col1, col2 = st.columns([5, 1])
                    with col1:
                        st.markdown(f"**{idx}. {display_name}**")
                        if case_no or court or date:
                            st.caption(f"ì‚¬ê±´ë²ˆí˜¸: {case_no or '-'} | ë²•ì›: {court or '-'} | ì„ ê³ ì¼: {date or '-'}")
                    with col2:
                        if detail_link:
                            full_link = f"https://www.law.go.kr{detail_link}" if detail_link.startswith('/') else detail_link
                            st.markdown(f"[ìƒì„¸ë³´ê¸°]({full_link})")

    # ë²•ë ¹í•´ì„ë¡€ ìƒì„¸
    if basic.get('expc'):
        with st.expander(f"ğŸ“‹ ê²€ìƒ‰ëœ ë²•ë ¹í•´ì„ë¡€ ({len(basic['expc'])}ê±´)", expanded=True):
            for idx, expc in enumerate(basic['expc'][:20], 1):
                display_name = engine._get_item_display(expc, 'ì•ˆê±´ëª…', 'ì œëª©', 'title', 'caseName', query=query)
                no = engine._get_value(expc, 'ì•ˆê±´ë²ˆí˜¸', 'caseNo', 'number', query=query)
                org = engine._get_value(expc, 'íšŒì‹ ê¸°ê´€ëª…', 'íšŒì‹ ê¸°ê´€', 'replyOrg', query=query)
                date = engine._get_value(expc, 'íšŒì‹ ì¼ì', 'replyDate', query=query)
                detail_link = engine._get_value(expc, 'ë²•ë ¹í•´ì„ë¡€ìƒì„¸ë§í¬', 'detailLink', query=query)
                if display_name and display_name != '(ì •ë³´ ì—†ìŒ)':
                    col1, col2 = st.columns([5, 1])
                    with col1:
                        st.markdown(f"**{idx}. {display_name}**")
                        if no or org or date:
                            st.caption(f"ì•ˆê±´ë²ˆí˜¸: {no or '-'} | íšŒì‹ ê¸°ê´€: {org or '-'} | íšŒì‹ ì¼: {date or '-'}")
                    with col2:
                        if detail_link:
                            full_link = f"https://www.law.go.kr{detail_link}" if detail_link.startswith('/') else detail_link
                            st.markdown(f"[ìƒì„¸ë³´ê¸°]({full_link})")

    # í–‰ì •ì‹¬íŒë¡€ ìƒì„¸
    if basic.get('decc'):
        with st.expander(f"âš–ï¸ ê²€ìƒ‰ëœ í–‰ì •ì‹¬íŒë¡€ ({len(basic['decc'])}ê±´)", expanded=True):
            for idx, decc in enumerate(basic['decc'][:20], 1):
                display_name = engine._get_item_display(decc, 'ì‚¬ê±´ëª…', 'ì œëª©', 'caseName', 'title', query=query)
                case_no = engine._get_value(decc, 'ì‚¬ê±´ë²ˆí˜¸', 'caseNo', 'caseNumber', query=query)
                result = engine._get_value(decc, 'ì¬ê²°ê²°ê³¼', 'ì¬ê²°êµ¬ë¶„ëª…', 'result', query=query)
                date = engine._get_value(decc, 'ì˜ê²°ì¼ì', 'ì¬ê²°ì¼ì', 'decisionDate', query=query)
                detail_link = engine._get_value(decc, 'í–‰ì •ì‹¬íŒë¡€ìƒì„¸ë§í¬', 'detailLink', query=query)
                if display_name and display_name != '(ì •ë³´ ì—†ìŒ)':
                    col1, col2 = st.columns([5, 1])
                    with col1:
                        st.markdown(f"**{idx}. {display_name}**")
                        if case_no or result or date:
                            st.caption(f"ì‚¬ê±´ë²ˆí˜¸: {case_no or '-'} | ì¬ê²°ê²°ê³¼: {result or '-'} | ì˜ê²°ì¼: {date or '-'}")
                    with col2:
                        if detail_link:
                            full_link = f"https://www.law.go.kr{detail_link}" if detail_link.startswith('/') else detail_link
                            st.markdown(f"[ìƒì„¸ë³´ê¸°]({full_link})")

    # í—Œì¬ê²°ì •ë¡€ ìƒì„¸
    if basic.get('detc'):
        with st.expander(f"ğŸ›ï¸ ê²€ìƒ‰ëœ í—Œì¬ê²°ì •ë¡€ ({len(basic['detc'])}ê±´)", expanded=False):
            for idx, detc in enumerate(basic['detc'][:10], 1):
                display_name = engine._get_item_display(detc, 'ì‚¬ê±´ëª…', 'ê²°ì •ëª…', 'caseName', 'ì œëª©', query=query)
                case_no = engine._get_value(detc, 'ì‚¬ê±´ë²ˆí˜¸', 'caseNo', 'caseNumber', query=query)
                date = engine._get_value(detc, 'ì¢…êµ­ì¼ì', 'ì„ ê³ ì¼ì', 'ê²°ì •ì¼ì', 'decisionDate', query=query)
                detail_link = engine._get_value(detc, 'í—Œì¬ê²°ì •ë¡€ìƒì„¸ë§í¬', 'detailLink', query=query)
                if display_name and display_name != '(ì •ë³´ ì—†ìŒ)':
                    col1, col2 = st.columns([5, 1])
                    with col1:
                        st.markdown(f"**{idx}. {display_name}**")
                        st.caption(f"ì‚¬ê±´ë²ˆí˜¸: {case_no or '-'} | ì¢…êµ­ì¼: {date or '-'}")
                    with col2:
                        if detail_link:
                            full_link = f"https://www.law.go.kr{detail_link}" if detail_link.startswith('/') else detail_link
                            st.markdown(f"[ìƒì„¸ë³´ê¸°]({full_link})")

    # ìœ„ì›íšŒ ê²°ì •ë¬¸ í‘œì‹œ
    committees = legal_data.get('committees', {})
    if committees:
        total_committee = sum(len(items) for items in committees.values() if items)
        if total_committee > 0:
            with st.expander(f"ğŸ¢ ìœ„ì›íšŒ ê²°ì •ë¬¸ ({total_committee}ê±´)", expanded=False):
                for comm_key, items in committees.items():
                    if items:
                        comm_name = engine.committee_targets.get(comm_key, {}).get('name', comm_key)
                        st.markdown(f"**{comm_name}** ({len(items)}ê±´)")
                        for idx, item in enumerate(items[:10], 1):
                            display_name = engine._get_item_display(item, 'ì‚¬ê±´ëª…', 'ì œëª©', 'caseName', 'title', query=query)
                            case_no = engine._get_value(item, 'ì‚¬ê±´ë²ˆí˜¸', 'caseNo', query=query)
                            date = engine._get_value(item, 'ì˜ê²°ì¼ì', 'ê²°ì •ì¼ì', 'decisionDate', query=query)
                            detail_link = engine._get_value(item, 'ìƒì„¸ë§í¬', 'detailLink', query=query)
                            if display_name and display_name != '(ì •ë³´ ì—†ìŒ)':
                                col1, col2 = st.columns([5, 1])
                                with col1:
                                    st.markdown(f"{idx}. {display_name}")
                                    if case_no or date:
                                        st.caption(f"ì‚¬ê±´ë²ˆí˜¸: {case_no or '-'} | ì¼ì: {date or '-'}")
                                with col2:
                                    if detail_link:
                                        full_link = f"https://www.law.go.kr{detail_link}" if detail_link.startswith('/') else detail_link
                                        st.markdown(f"[ìƒì„¸]({full_link})")
                        st.markdown("---")

    # ë¶€ì²˜ë³„ ë²•ë ¹í•´ì„ í‘œì‹œ
    ministries = legal_data.get('ministries', {})
    if ministries:
        total_ministry = sum(len(items) for items in ministries.values() if items)
        if total_ministry > 0:
            with st.expander(f"ğŸ›ï¸ ë¶€ì²˜ë³„ ë²•ë ¹í•´ì„ ({total_ministry}ê±´)", expanded=False):
                for min_key, items in ministries.items():
                    if items:
                        min_name = engine.ministry_targets.get(min_key, {}).get('name', min_key)
                        st.markdown(f"**{min_name}** ({len(items)}ê±´)")
                        for idx, item in enumerate(items[:10], 1):
                            display_name = engine._get_item_display(item, 'ì•ˆê±´ëª…', 'ì œëª©', 'title', query=query)
                            no = engine._get_value(item, 'ì•ˆê±´ë²ˆí˜¸', 'caseNo', query=query)
                            date = engine._get_value(item, 'íšŒì‹ ì¼ì', 'replyDate', query=query)
                            detail_link = engine._get_value(item, 'ë²•ë ¹í•´ì„ë¡€ìƒì„¸ë§í¬', 'detailLink', query=query)
                            if display_name and display_name != '(ì •ë³´ ì—†ìŒ)':
                                col1, col2 = st.columns([5, 1])
                                with col1:
                                    st.markdown(f"{idx}. {display_name}")
                                    if no or date:
                                        st.caption(f"ì•ˆê±´ë²ˆí˜¸: {no or '-'} | íšŒì‹ ì¼: {date or '-'}")
                                with col2:
                                    if detail_link:
                                        full_link = f"https://www.law.go.kr{detail_link}" if detail_link.startswith('/') else detail_link
                                        st.markdown(f"[ìƒì„¸]({full_link})")
                        st.markdown("---")

    # íŠ¹ë³„í–‰ì •ì‹¬íŒë¡€ í‘œì‹œ
    special_tribunals = legal_data.get('special_tribunals', {})
    if special_tribunals:
        total_tribunal = sum(len(items) for items in special_tribunals.values() if items)
        if total_tribunal > 0:
            with st.expander(f"âš–ï¸ íŠ¹ë³„í–‰ì •ì‹¬íŒë¡€ ({total_tribunal}ê±´)", expanded=False):
                for trib_key, items in special_tribunals.items():
                    if items:
                        trib_name = engine.special_tribunal_targets.get(trib_key, {}).get('name', trib_key)
                        st.markdown(f"**{trib_name}** ({len(items)}ê±´)")
                        for idx, item in enumerate(items[:10], 1):
                            display_name = engine._get_item_display(item, 'ì‚¬ê±´ëª…', 'ì œëª©', 'caseName', query=query)
                            case_no = engine._get_value(item, 'ì‚¬ê±´ë²ˆí˜¸', 'caseNo', query=query)
                            date = engine._get_value(item, 'ì¬ê²°ì¼ì', 'ì˜ê²°ì¼ì', 'decisionDate', query=query)
                            detail_link = engine._get_value(item, 'í–‰ì •ì‹¬íŒë¡€ìƒì„¸ë§í¬', 'detailLink', query=query)
                            if display_name and display_name != '(ì •ë³´ ì—†ìŒ)':
                                col1, col2 = st.columns([5, 1])
                                with col1:
                                    st.markdown(f"{idx}. {display_name}")
                                    if case_no or date:
                                        st.caption(f"ì‚¬ê±´ë²ˆí˜¸: {case_no or '-'} | ì¬ê²°ì¼: {date or '-'}")
                                with col2:
                                    if detail_link:
                                        full_link = f"https://www.law.go.kr{detail_link}" if detail_link.startswith('/') else detail_link
                                        st.markdown(f"[ìƒì„¸]({full_link})")
                        st.markdown("---")

def display_search_statistics(fact_sheet: Dict, engine: LegalAIEngine):
    """ê²€ìƒ‰ ê²°ê³¼ í†µê³„ í‘œì‹œ"""
    stats = fact_sheet.get('statistics', {})
    if not stats:
        return

    st.markdown("### ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ í†µê³„")

    # ê¸°ë³¸ ë°ì´í„°
    basic_stats = {k: v for k, v in stats.items()
                  if not k.startswith(('committee_', 'ministry_', 'tribunal_'))}
    if basic_stats:
        cols = st.columns(4)
        for idx, (key, count) in enumerate(basic_stats.items()):
            name = engine.basic_targets.get(key, {}).get('name', key)
            with cols[idx % 4]:
                st.metric(name, count)

    # ìœ„ì›íšŒ ê²°ì •ë¬¸
    committee_stats = {k.replace('committee_', ''): v for k, v in stats.items()
                      if k.startswith('committee_')}
    if committee_stats:
        st.markdown("#### ìœ„ì›íšŒ ê²°ì •ë¬¸")
        cols = st.columns(4)
        for idx, (key, count) in enumerate(committee_stats.items()):
            name = engine.committee_targets.get(key, {}).get('name', key)
            with cols[idx % 4]:
                st.metric(name, count)

    # ë¶€ì²˜ë³„ ë²•ë ¹í•´ì„
    ministry_stats = {k.replace('ministry_', ''): v for k, v in stats.items()
                     if k.startswith('ministry_')}
    if ministry_stats:
        st.markdown("#### ë¶€ì²˜ë³„ ë²•ë ¹í•´ì„")
        cols = st.columns(4)
        for idx, (key, count) in enumerate(ministry_stats.items()):
            name = engine.ministry_targets.get(key, {}).get('name', key)
            with cols[idx % 4]:
                st.metric(name, count)

async def process_search(query: str, search_options: Dict):
    """ê²€ìƒ‰ ì²˜ë¦¬"""
    engine = LegalAIEngine()

    # ê²€ìƒ‰ ìƒíƒœ í‘œì‹œ ì˜ì—­
    status_container = st.container()

    with status_container:
        st.info("ğŸ” ë²•ë¥  ë°ì´í„° ê²€ìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        progress = st.progress(0)

        # API í‚¤ í™•ì¸
        api_key = get_law_api_key()
        if not api_key:
            st.error("âŒ ë²•ì œì²˜ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return {}, {}, "ë²•ì œì²˜ API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.", engine

        # 1. ì¢…í•© ê²€ìƒ‰
        progress.progress(20, "ë²•ì œì²˜ ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ì¤‘...")
        legal_data = await engine.comprehensive_search(query, search_options)

        # ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½ í‘œì‹œ
        basic = legal_data.get('basic', {})
        search_summary = []
        if basic.get('prec'):
            search_summary.append(f"íŒë¡€ {len(basic['prec'])}ê±´")
        if basic.get('expc'):
            search_summary.append(f"ë²•ë ¹í•´ì„ë¡€ {len(basic['expc'])}ê±´")
        if basic.get('decc'):
            search_summary.append(f"í–‰ì •ì‹¬íŒë¡€ {len(basic['decc'])}ê±´")
        if basic.get('law') or basic.get('eflaw'):
            laws = (basic.get('law', []) or []) + (basic.get('eflaw', []) or [])
            if laws:
                search_summary.append(f"ë²•ë ¹ {len(laws)}ê±´")

        if search_summary:
            progress.progress(50, f"ê²€ìƒ‰ ì™„ë£Œ: {', '.join(search_summary)}")
        else:
            st.warning("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¡œ ì‹œë„í•´ë³´ì„¸ìš”.")
            progress.progress(50, "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")

        # 2. ì‚¬ì‹¤ê´€ê³„ ì •ë¦¬
        progress.progress(60, "ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„ ì¤‘...")
        fact_sheet = engine.create_fact_sheet(query, legal_data)

        # 3. AI ë¶„ì„
        progress.progress(80, "AI ë¶„ì„ ì¤‘...")
        advice = await engine.generate_legal_advice(query, legal_data, fact_sheet)

        progress.progress(100, "ì™„ë£Œ!")
        time.sleep(0.5)
        progress.empty()

        # ìµœì¢… ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½
        if search_summary:
            st.success(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: {', '.join(search_summary)}")
        else:
            st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

    return legal_data, fact_sheet, advice, engine

# ===== PDF ë²ˆì—­ UI í•¨ìˆ˜ =====
def render_pdf_translation_tab():
    """PDF ë²ˆì—­ íƒ­ ë Œë”ë§"""
    st.header("ğŸ“„ PDF ë¬¸ì„œ ë²ˆì—­")
    st.markdown("PDF ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ë©´ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  ë²ˆì—­í•©ë‹ˆë‹¤. (ìˆ˜ì‹ì€ ë³´ì¡´ë©ë‹ˆë‹¤)")

    if not PDF_TRANSLATOR_AVAILABLE:
        st.error("PDF ë²ˆì—­ ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
        st.code("pip install pymupdf Pillow pytesseract reportlab", language="bash")
        return

    # OpenAI API í‚¤ í™•ì¸
    openai_key = get_openai_api_key()
    if not openai_key:
        st.warning("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    # ë²ˆì—­ ì„¤ì •
    col1, col2 = st.columns(2)
    with col1:
        source_lang = st.selectbox(
            "ì›ë³¸ ì–¸ì–´",
            options=["en", "ko", "ja", "zh", "de", "fr", "es", "ru"],
            format_func=lambda x: {
                "en": "ì˜ì–´", "ko": "í•œêµ­ì–´", "ja": "ì¼ë³¸ì–´",
                "zh": "ì¤‘êµ­ì–´", "de": "ë…ì¼ì–´", "fr": "í”„ë‘ìŠ¤ì–´",
                "es": "ìŠ¤í˜ì¸ì–´", "ru": "ëŸ¬ì‹œì•„ì–´"
            }.get(x, x),
            index=0
        )
    with col2:
        target_lang = st.selectbox(
            "ë²ˆì—­ ì–¸ì–´",
            options=["ko", "en", "ja", "zh", "de", "fr", "es", "ru"],
            format_func=lambda x: {
                "en": "ì˜ì–´", "ko": "í•œêµ­ì–´", "ja": "ì¼ë³¸ì–´",
                "zh": "ì¤‘êµ­ì–´", "de": "ë…ì¼ì–´", "fr": "í”„ë‘ìŠ¤ì–´",
                "es": "ìŠ¤í˜ì¸ì–´", "ru": "ëŸ¬ì‹œì•„ì–´"
            }.get(x, x),
            index=0
        )

    # ë²ˆì—­ ì˜µì…˜
    col1, col2 = st.columns(2)
    with col1:
        translate_text = st.checkbox("í…ìŠ¤íŠ¸ ë¸”ë¡ ë²ˆì—­", value=True,
                                    help="PDFì˜ í…ìŠ¤íŠ¸ ë¸”ë¡ì„ ì¶”ì¶œí•˜ì—¬ ë²ˆì—­í•©ë‹ˆë‹¤")
    with col2:
        translate_images = st.checkbox("ì´ë¯¸ì§€ OCR ë²ˆì—­", value=False,
                                      help="ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ OCRë¡œ ì¶”ì¶œí•˜ì—¬ ë²ˆì—­í•©ë‹ˆë‹¤ (Tesseract í•„ìš”)")

    st.divider()

    # PDF íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader(
        "PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
        type=["pdf"],
        help="ìµœëŒ€ 200MBê¹Œì§€ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤"
    )

    if uploaded_file is not None:
        # íŒŒì¼ ì •ë³´ í‘œì‹œ
        st.markdown(f"**íŒŒì¼ëª…:** {uploaded_file.name}")
        st.markdown(f"**íŒŒì¼ í¬ê¸°:** {uploaded_file.size / 1024 / 1024:.2f} MB")

        # PDF ì •ë³´ ë¯¸ë¦¬ë³´ê¸°
        pdf_bytes = uploaded_file.read()
        uploaded_file.seek(0)  # íŒŒì¼ í¬ì¸í„° ë¦¬ì…‹

        try:
            translator = PDFTranslator(get_openai_client()) if PDF_TRANSLATOR_AVAILABLE else None
            if translator:
                pdf_info = translator.get_pdf_info(pdf_bytes)
            else:
                st.error("PDF ë²ˆì—­ê¸°ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return

            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("í˜ì´ì§€ ìˆ˜", pdf_info['page_count'])
            with col2:
                st.metric("í…ìŠ¤íŠ¸ ë¸”ë¡", pdf_info['text_blocks_count'])
            with col3:
                st.metric("ì´ë¯¸ì§€ ìˆ˜", pdf_info['images_count'])

        except Exception as e:
            st.error(f"PDF ë¶„ì„ ì˜¤ë¥˜: {e}")
            return

        st.divider()

        # ë²ˆì—­ ì‹¤í–‰ ë²„íŠ¼
        if st.button("ğŸ”„ PDF ë²ˆì—­ ì‹œì‘", type="primary", use_container_width=True):
            if not openai_key:
                st.error("OpenAI API í‚¤ë¥¼ ë¨¼ì € ì„¤ì •í•´ì£¼ì„¸ìš”.")
                return

            # ì§„í–‰ ìƒíƒœ í‘œì‹œ
            progress_bar = st.progress(0)
            status_text = st.empty()

            def update_progress(progress, message="ì²˜ë¦¬ ì¤‘..."):
                progress_bar.progress(progress)
                status_text.text(message)

            try:
                with st.spinner("PDF ë²ˆì—­ ì¤‘..."):
                    # ë²ˆì—­ ì‹¤í–‰
                    translated_bytes = translate_pdf_file(
                        pdf_bytes,
                        openai_client=get_openai_client(),
                        source_lang=source_lang,
                        target_lang=target_lang,
                        translate_text=translate_text,
                        translate_images=translate_images,
                        progress_callback=update_progress
                    )

                progress_bar.progress(100)
                status_text.text("ë²ˆì—­ ì™„ë£Œ!")

                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                output_filename = f"translated_{uploaded_file.name}"
                st.success("PDF ë²ˆì—­ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

                st.download_button(
                    label="ğŸ“¥ ë²ˆì—­ëœ PDF ë‹¤ìš´ë¡œë“œ",
                    data=translated_bytes,
                    file_name=output_filename,
                    mime="application/pdf",
                    use_container_width=True
                )

                # ì„¸ì…˜ì— ê²°ê³¼ ì €ì¥
                st.session_state['translated_pdf'] = translated_bytes
                st.session_state['translated_pdf_name'] = output_filename

            except Exception as e:
                st.error(f"ë²ˆì—­ ì˜¤ë¥˜: {e}")
                logger.error(f"PDF ë²ˆì—­ ì‹¤íŒ¨: {e}")

    # ì´ì „ ë²ˆì—­ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ í‘œì‹œ
    if 'translated_pdf' in st.session_state and st.session_state.get('translated_pdf'):
        st.divider()
        st.markdown("### ì´ì „ ë²ˆì—­ ê²°ê³¼")
        st.download_button(
            label="ğŸ“¥ ë§ˆì§€ë§‰ ë²ˆì—­ëœ PDF ë‹¤ìš´ë¡œë“œ",
            data=st.session_state['translated_pdf'],
            file_name=st.session_state.get('translated_pdf_name', 'translated.pdf'),
            mime="application/pdf"
        )


# ===== ë©”ì¸ ì•± =====
def main():
    # í—¤ë”
    col1, col2 = st.columns([3, 1])
    with col1:
        st.title("âš–ï¸ AI ë²•ë¥  ë„ìš°ë¯¸ & PDF ë²ˆì—­")
        st.markdown("ë²•ë¥  ê²€ìƒ‰ + PDF ë¬¸ì„œ ë²ˆì—­ ì„œë¹„ìŠ¤")
    with col2:
        st.markdown("""
        <div style="text-align: right; padding: 1rem;">
            <small>v5.0 | GPT-5 + ë²•ì œì²˜ API ì „ì²´ ì—°ë™</small>
        </div>
        """, unsafe_allow_html=True)

    # ===== ì‚¬ì´ë“œë°” =====
    with st.sidebar:
        st.header("ğŸ”‘ API ì„¤ì •")

        # API í‚¤ ì…ë ¥ ì„¹ì…˜
        with st.expander("API í‚¤ ì…ë ¥", expanded=not st.session_state.api_keys_set):
            st.markdown("#### ë²•ì œì²˜ Open API")
            st.caption("https://open.law.go.kr ì—ì„œ ë°œê¸‰")
            law_api_input = st.text_input(
                "ë²•ì œì²˜ API í‚¤",
                value=st.session_state.law_api_key,
                type="password",
                key="law_api_input",
                placeholder="ë²•ì œì²˜ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
            )

            st.markdown("#### OpenAI API")
            st.caption("https://platform.openai.com ì—ì„œ ë°œê¸‰")
            openai_api_input = st.text_input(
                "OpenAI API í‚¤",
                value=st.session_state.openai_api_key,
                type="password",
                key="openai_api_input",
                placeholder="OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì„ íƒ)"
            )

            if st.button("API í‚¤ ì €ì¥", use_container_width=True):
                st.session_state.law_api_key = law_api_input
                st.session_state.openai_api_key = openai_api_input
                st.session_state.api_keys_set = True
                st.success("API í‚¤ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()

        st.divider()

        # API ìƒíƒœ í‘œì‹œ
        st.header("ğŸ”Œ API ìƒíƒœ")
        law_key = get_law_api_key()
        openai_key = get_openai_api_key()

        if law_key:
            st.success("âœ… ë²•ì œì²˜ API ì—°ê²°ë¨")
        else:
            st.error("âŒ ë²•ì œì²˜ API í‚¤ í•„ìš”")
            st.caption("ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë²•ì œì²˜ API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

        if openai_key:
            st.success("âœ… GPT-5 AI ì—”ì§„ í™œì„±í™”")
        else:
            st.warning("âš ï¸ OpenAI API ë¯¸ì„¤ì •")
            st.caption("AI ë¶„ì„ ì—†ì´ ê²€ìƒ‰ ê²°ê³¼ë§Œ í‘œì‹œë©ë‹ˆë‹¤.")

        st.divider()

        # ê²€ìƒ‰ ì˜µì…˜
        st.header("ğŸ” ê²€ìƒ‰ ì˜µì…˜")

        # ì—”ì§„ ì´ˆê¸°í™” (ì˜µì…˜ í‘œì‹œìš©)
        engine = LegalAIEngine()

        # ê¸°ë³¸ ë°ì´í„° ê²€ìƒ‰
        search_basic = st.checkbox("ê¸°ë³¸ ë²•ë¥  ë°ì´í„°", value=True,
                                   help="ë²•ë ¹, íŒë¡€, í–‰ì •ê·œì¹™, ìì¹˜ë²•ê·œ, í—Œì¬ê²°ì •ë¡€, ë²•ë ¹í•´ì„ë¡€, í–‰ì •ì‹¬íŒë¡€, ì¡°ì•½")

        # ìœ„ì›íšŒ ê²°ì •ë¬¸
        with st.expander("ìœ„ì›íšŒ ê²°ì •ë¬¸"):
            select_all_comm = st.checkbox("ì „ì²´ ì„ íƒ", key="select_all_comm")
            col1, col2 = st.columns(2)
            committees_list = list(engine.committee_targets.items())
            half = len(committees_list) // 2

            with col1:
                for key, info in committees_list[:half]:
                    st.checkbox(info['name'], value=select_all_comm, key=f"comm_{key}")
            with col2:
                for key, info in committees_list[half:]:
                    st.checkbox(info['name'], value=select_all_comm, key=f"comm_{key}")

        # ë¶€ì²˜ë³„ ë²•ë ¹í•´ì„ (ì£¼ìš”)
        major_ministries = [
            ('moelCgmExpc', 'ê³ ìš©ë…¸ë™ë¶€'),
            ('molitCgmExpc', 'êµ­í† êµí†µë¶€'),
            ('moisCgmExpc', 'í–‰ì •ì•ˆì „ë¶€'),
            ('mohwCgmExpc', 'ë³´ê±´ë³µì§€ë¶€'),
            ('molegCgmExpc', 'ë²•ì œì²˜'),
            ('mojCgmExpc', 'ë²•ë¬´ë¶€'),
        ]

        with st.expander("ë¶€ì²˜ë³„ ë²•ë ¹í•´ì„ (ì£¼ìš”)"):
            select_all_major_min = st.checkbox("ì „ì²´ ì„ íƒ (ì£¼ìš” ë¶€ì²˜)", key="select_all_major_min")
            for key, name in major_ministries:
                st.checkbox(name, value=select_all_major_min, key=f"min_{key}")

        # ë¶€ì²˜ë³„ ë²•ë ¹í•´ì„ (ê¸°íƒ€)
        other_ministries = [(k, v['name']) for k, v in engine.ministry_targets.items()
                           if k not in [m[0] for m in major_ministries]]

        with st.expander("ë¶€ì²˜ë³„ ë²•ë ¹í•´ì„ (ê¸°íƒ€)"):
            select_all_other_min = st.checkbox("ì „ì²´ ì„ íƒ (ê¸°íƒ€ ë¶€ì²˜)", key="select_all_other_min")
            col1, col2 = st.columns(2)
            for idx, (key, name) in enumerate(other_ministries):
                with col1 if idx % 2 == 0 else col2:
                    st.checkbox(name, value=select_all_other_min, key=f"min_{key}")

        # íŠ¹ë³„í–‰ì •ì‹¬íŒë¡€
        search_special_tribunals = st.checkbox(
            "íŠ¹ë³„í–‰ì •ì‹¬íŒë¡€",
            value=False,
            help="ì¡°ì„¸ì‹¬íŒì›, í•´ì–‘ì•ˆì „ì‹¬íŒì›, êµ­ë¯¼ê¶Œìµìœ„ì›íšŒ, ì¸ì‚¬í˜ì‹ ì²˜ ì†Œì²­ì‹¬ì‚¬ìœ„ì›íšŒ"
        )

        st.divider()

        # ìƒˆ ëŒ€í™” ì‹œì‘ ë²„íŠ¼
        if st.button("ğŸ”„ ìƒˆ ê²€ìƒ‰ ì‹œì‘", use_container_width=True):
            st.session_state.chat_history = []
            st.session_state.search_results = None
            st.session_state.fact_sheet = {}
            st.rerun()

    # ===== ë©”ì¸ ì»¨í…ì¸  (íƒ­ ê¸°ë°˜) =====
    tab1, tab2 = st.tabs(["âš–ï¸ ë²•ë¥  ì—°êµ¬", "ğŸ“„ PDF ë²ˆì—­"])

    # ===== íƒ­ 1: ë²•ë¥  ì—°êµ¬ =====
    with tab1:
        # ì›°ì»´ ë©”ì‹œì§€
        if not st.session_state.chat_history:
            st.markdown("""
            <div class="chat-message assistant-message">
                <strong>âš–ï¸ AI ë³€í˜¸ì‚¬ (GPT-5):</strong><br>
                ì•ˆë…•í•˜ì„¸ìš”, AI ë³€í˜¸ì‚¬ì…ë‹ˆë‹¤.<br><br>

                <b>ğŸ” ê²€ìƒ‰ ê°€ëŠ¥í•œ ë²•ë¥  ë°ì´í„°:</b><br>
                â€¢ <b>ê¸°ë³¸:</b> ë²•ë ¹, íŒë¡€, í–‰ì •ê·œì¹™, ìì¹˜ë²•ê·œ, í—Œì¬ê²°ì •ë¡€, ë²•ë ¹í•´ì„ë¡€, í–‰ì •ì‹¬íŒë¡€, ì¡°ì•½<br>
                â€¢ <b>ìœ„ì›íšŒ ê²°ì •ë¬¸:</b> ê³µì •ê±°ë˜ìœ„ì›íšŒ, ë…¸ë™ìœ„ì›íšŒ, ê¸ˆìœµìœ„ì›íšŒ ë“± 12ê°œ ìœ„ì›íšŒ<br>
                â€¢ <b>ë¶€ì²˜ë³„ ë²•ë ¹í•´ì„:</b> ê³ ìš©ë…¸ë™ë¶€, êµ­í† êµí†µë¶€ ë“± 30ê°œ ì´ìƒ ë¶€ì²˜<br>
                â€¢ <b>íŠ¹ë³„í–‰ì •ì‹¬íŒ:</b> ì¡°ì„¸ì‹¬íŒì›, í•´ì–‘ì•ˆì „ì‹¬íŒì› ë“±<br><br>

                <b>ğŸ’¡ ì‚¬ìš© ë°©ë²•:</b><br>
                1. ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”<br>
                2. ê²€ìƒ‰í•  ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”<br>
                3. ì•„ë˜ ì…ë ¥ì°½ì— ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”<br><br>

                ì–´ë–¤ ë²•ë¥  ìë£Œë¥¼ ì°¾ì•„ë“œë¦´ê¹Œìš”?
            </div>
            """, unsafe_allow_html=True)
        else:
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ
            for msg in st.session_state.chat_history:
                display_chat_message(msg["role"], msg["content"])

        st.divider()

        # ì˜ˆì‹œ ê²€ìƒ‰ì–´
        st.markdown("### ğŸ’¡ ì˜ˆì‹œ ê²€ìƒ‰ì–´")
        col1, col2, col3 = st.columns(3)

        examples = {
            "ë¶€ë‹¹í•´ê³  êµ¬ì œ": "ë¶€ë‹¹í•´ê³  êµ¬ì œ ì ˆì°¨ì™€ ê´€ë ¨ íŒë¡€",
            "ì„ëŒ€ì°¨ ë³´ì¦ê¸ˆ": "ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ë³´ì¦ê¸ˆ ë°˜í™˜",
            "ê°œì¸ì •ë³´ ì¹¨í•´": "ê°œì¸ì •ë³´ ì¹¨í•´ ì†í•´ë°°ìƒ"
        }

        clicked_example = None
        for idx, (btn_text, query) in enumerate(examples.items()):
            with [col1, col2, col3][idx]:
                if st.button(btn_text, use_container_width=True, key=f"example_{idx}"):
                    clicked_example = query

        # ì‚¬ìš©ì ì…ë ¥
        user_input = st.text_area(
            "ê²€ìƒ‰ì–´ ì…ë ¥",
            value=clicked_example if clicked_example else "",
            placeholder="ì˜ˆ: ë¶€ë‹¹í•´ê³  êµ¬ì œ ì ˆì°¨, ì„ëŒ€ì°¨ ë³´ì¦ê¸ˆ ë°˜í™˜ íŒë¡€ ë“±",
            height=100,
            key="search_input"
        )

        col1, col2 = st.columns([3, 1])
        with col1:
            search_button = st.button("ğŸ” ë²•ë¥  ìë£Œ ê²€ìƒ‰", type="primary", use_container_width=True)
        with col2:
            if st.session_state.chat_history:
                if st.button("ğŸ“„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ"):
                    last_response = st.session_state.chat_history[-1]
                    if last_response["role"] == "assistant":
                        st.download_button(
                            label="ğŸ’¾ ë‹¤ìš´ë¡œë“œ",
                            data=last_response["content"],
                            file_name=f"ë²•ë¥ ì—°êµ¬_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                            mime="text/plain"
                        )

        # ê²€ìƒ‰ ì‹¤í–‰
        if search_button or clicked_example:
            query = user_input if user_input else clicked_example

            if not query:
                st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            elif not get_law_api_key():
                st.error("ë²•ì œì²˜ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                # ì„¸ì…˜ ìƒíƒœì—ì„œ ì„ íƒëœ ìœ„ì›íšŒ ìˆ˜ì§‘
                engine_for_options = LegalAIEngine()

                # ì „ì²´ ì„ íƒ ì²´í¬ ì‹œ ëª¨ë“  ìœ„ì›íšŒ ì„ íƒ
                if st.session_state.get("select_all_comm", False):
                    selected_committees = list(engine_for_options.committee_targets.keys())
                else:
                    selected_committees = [
                        key for key in engine_for_options.committee_targets.keys()
                        if st.session_state.get(f"comm_{key}", False)
                    ]

                # ì„¸ì…˜ ìƒíƒœì—ì„œ ì„ íƒëœ ë¶€ì²˜ ìˆ˜ì§‘
                major_ministry_keys = ['moelCgmExpc', 'molitCgmExpc', 'moisCgmExpc',
                                       'mohwCgmExpc', 'molegCgmExpc', 'mojCgmExpc']

                selected_ministries = []

                # ì£¼ìš” ë¶€ì²˜ ì „ì²´ ì„ íƒ ì²´í¬ ì‹œ
                if st.session_state.get("select_all_major_min", False):
                    selected_ministries.extend(major_ministry_keys)
                else:
                    selected_ministries.extend([
                        key for key in major_ministry_keys
                        if st.session_state.get(f"min_{key}", False)
                    ])

                # ê¸°íƒ€ ë¶€ì²˜ ì „ì²´ ì„ íƒ ì²´í¬ ì‹œ
                other_ministry_keys = [k for k in engine_for_options.ministry_targets.keys()
                                       if k not in major_ministry_keys]
                if st.session_state.get("select_all_other_min", False):
                    selected_ministries.extend(other_ministry_keys)
                else:
                    selected_ministries.extend([
                        key for key in other_ministry_keys
                        if st.session_state.get(f"min_{key}", False)
                    ])

                # ê²€ìƒ‰ ì˜µì…˜ êµ¬ì„±
                search_options = {
                    'basic': search_basic,
                    'committees': selected_committees,
                    'ministries': selected_ministries,
                    'special_tribunals': search_special_tribunals
                }

                # ê²€ìƒ‰ ì‹¤í–‰
                legal_data, fact_sheet, advice, engine = asyncio.run(
                    process_search(query, search_options)
                )

                # ê²°ê³¼ ì €ì¥
                st.session_state.search_results = legal_data
                st.session_state.fact_sheet = fact_sheet

                # ì±„íŒ… íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                st.session_state.chat_history.append({
                    "role": "user",
                    "content": query,
                    "timestamp": datetime.now().isoformat()
                })

                st.session_state.chat_history.append({
                    "role": "assistant",
                    "content": advice,
                    "legal_data": legal_data,
                    "fact_sheet": fact_sheet,
                    "timestamp": datetime.now().isoformat()
                })

                st.rerun()

        # ê²€ìƒ‰ í†µê³„ í‘œì‹œ
        if st.session_state.fact_sheet:
            engine = LegalAIEngine()
            display_search_statistics(st.session_state.fact_sheet, engine)

    # ê²€ìƒ‰ ê²°ê³¼ ìƒì„¸ í‘œì‹œ (íŒë¡€, ìœ ê¶Œí•´ì„ ë“±)
    if st.session_state.search_results:
        engine = LegalAIEngine()
        st.markdown("---")
        st.markdown("## ğŸ“‘ ê²€ìƒ‰ëœ ë²•ë¥  ìë£Œ")
        # fact_sheetì—ì„œ ì¿¼ë¦¬ ê°€ì ¸ì˜¤ê¸°
        current_query = st.session_state.fact_sheet.get('query', '') if st.session_state.fact_sheet else ''
        display_search_results_detail(st.session_state.search_results, engine, query=current_query)

    # ê²€ìƒ‰ í†µê³„ í‘œì‹œ
    if st.session_state.fact_sheet:
        engine = LegalAIEngine()
        display_search_statistics(st.session_state.fact_sheet, engine)

# ===== ì•± ì‹¤í–‰ =====
if __name__ == "__main__":
    main()
